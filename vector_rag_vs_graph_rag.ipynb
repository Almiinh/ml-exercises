{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vector RAG vs Graph RAG: a comparison of RAG Workflow w/ Langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.1. Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade --quiet  langchain langchain-community langchain-openai langchain-chroma neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv('../.env') # Load environment variables from .env file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.2. Setup the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup with OpenAI's `gpt-3.5-turbo-0125` model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.3. Prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are two prompts to test the classification of the document, and to test the summarization capabilities of the chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = [\"What is this document?\",\"What are the two genetic variations studied in this research and how do they affect the LDL receptor protein?\", \"How can these findings help improve diagnosis and treatment for Familial Hypercholesterolemia?\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Indexing: Load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use `DocumentLoaders` to load a list of `Documents`.  \n",
    "A `Document` is an object with some `page_content` (str) and `metadata` (dict)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "from langchain_community.document_loaders import TextLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='# TITLE\\n\\n Characterization of Two Variants at Met 1 of the Human LDLR Gene Encoding the Same Amino Acid but Causing Different Functional Phenotypes\\n', metadata={'source': '..\\\\PMC8467959\\\\chunks\\\\0.TITLE.txt'}),\n",
       " Document(page_content='# ABSTRACT\\n\\n Familial hypercholesterolemia (FH) is the most common genetic disorder of lipid metabolism, characterized by increased levels of total and LDL plasma cholesterol, which leads to premature atherosclerosis and coronary heart disease. FH phenotype has considerable genetic heterogeneity and phenotypic variability, depending on LDL receptor activity and lifestyle. To improve diagnosis and patient management, here, we characterized two single nucleotide missense substitutions at Methionine 1 of the human LDLR gene (c.1A>T/p.(Met1Leu) and c.1A>C/p.(Met1Leu)). We used a combination of Western blot, flow cytometry, and luciferase assays to determine the effects of both variants on the expression, activity, and synthesis of LDLR. Our data show that both variants can mediate translation initiation, although the expression of variant c.1A>T is very low. Both variants are in the translation initiation codon and codify for the same amino acid p.(Met1Leu), yet they lead to different levels of impairment on LDLR expression and activity, corroborating different efficiencies of the translation initiation at these non-canonical initiation codons. The functional data of these variants allowed for an improved American College of Medical Genetics (ACMG) classification for both variants, which can allow a more personalized choice of the lipid-lowering treatment and dyslipidemia management, ultimately improving patients’ prognosis.\\n', metadata={'source': '..\\\\PMC8467959\\\\chunks\\\\1.ABSTRACT.txt'}),\n",
       " Document(page_content='# COMP_INT\\n\\n Conflicts of Interest\\n\\n The authors declare no conflict of interest.\\n', metadata={'source': '..\\\\PMC8467959\\\\chunks\\\\10.COMP_INT.txt'}),\n",
       " Document(page_content='# REF\\n\\n References\\n\\n A receptor-mediated pathway for cholesterol homeostasis\\n\\n Estimating the prevalence of heterozygous familial hypercholesterolaemia: A systematic review and meta-analysis\\n\\n The complex molecular genetics of familial hypercholesterolaemia\\n\\n Low-density lipoprotein receptor mutational analysis in diagnosis of familial hypercholesterolemia\\n\\n The familial hypercholesterolaemia phenotype: Monogenic familial hypercholesterolaemia, polygenic hypercholesterolaemia and other causes\\n\\n Use of low-density lipoprotein cholesterol gene score to distinguish patients with polygenic and monogenic familial hypercholesterolaemia: A case-control study\\n\\n ClinVar database of global familial hypercholesterolemia-associated DNA variants\\n\\n Familial hypercholesterolemia: A complex genetic disease with variable phenotypes\\n\\n Genetic identification of familial hypercholesterolemia within a single U.S. Health care system\\n\\n Mutational analysis and genotype-phenotype relation in familial hypercholesterolemia: The SAFEHEART registry\\n\\n Diagnostic Yield of Sequencing Familial Hypercholesterolemia Genes in Severe Hypercholesterolemia\\n\\n Attainment of LDL-cholesterol treatment goals in patients with familial hypercholesterolemia: 5-year SAFEHEART registry follow-up\\n\\n Presence and type of low density lipoprotein receptor (LDLR) mutation influences the lipid profile and response to lipid-lowering therapy in Brazilian patients with heterozygous familial hypercholesterolemia\\n\\n Molecular genetics of the LDL receptor gene in familial hypercholesterolemia\\n\\n Update of the Portuguese Familial Hypercholesterolaemia Study\\n\\n Mutational analysis of a cohort with clinical diagnosis of familial hypercholesterolemia: Considerations for genetic diagnosis improvement\\n\\n Estudo Português de hipercolesterolemia familiar: Apresentação do estudo e resultados preliminares\\n\\n Title: The Clinical Genome Resource (ClinGen) Familial Hypercholesterolemia Variant Curation Expert Panel consensus guidelines for LDLR variant classification\\n\\n Predicting the Functional Effect of Amino Acid Substitutions and Indels\\n\\n Predicting the effects of coding non-synonymous variants on protein function using the SIFT algorithm\\n\\n A method and server for predicting damaging missense mutations\\n\\n MutationTaster evaluates disease-causing potential of sequence alterations\\n\\n REVEL: An Ensemble Method for Predicting the Pathogenicity of Rare Missense Variants\\n\\n Genome-Wide Analysis in Vivo of Resolution Using Ribosome Profiling\\n\\n Non-AUG translation: A new start for protein synthesis in eukaryotes\\n\\n Constitutive display of cryptic translation products by MHC class I molecules\\n\\n Ribosome Profiling of Mouse Embryonic Stem Cells Reveals the Complexity and Dynamics of Mammalian Proteomes\\n\\n Leucine-tRNA initiates at CUG start codons for protein synthesis and presentation by MHC class I\\n\\n Translation from the 5’ untranslated region shapes the integrated stress response\\n\\n Downstream secondary structure facilitates recognition of initiator codons by eukaryotic ribosomes\\n\\n The helicase Ded1p controls use of near-cognate translation initiation codons in 5′ UTRs\\n\\n Phenotypical, clinical, and molecular aspects of adults and children with homozygous familial hypercholesterolemia in iberoamerica\\n\\n Two novel point mutations causing receptor-negative familial hypercholesterolemia in a South African Indian homozygote\\n\\n Genetic diagnosis of familial hypercholesterolemia in a South European outbreed population: Influence of low-density lipoprotein (LDL) receptor gene mutations on treatment response to simvastatin in total, LDL, and high-density lipoprotein cholesterol\\n\\n 2019 ESC/EAS guidelines for the management of dyslipidaemias: Lipid modification to reduce cardiovascular risk\\n', metadata={'source': '..\\\\PMC8467959\\\\chunks\\\\11.REF.txt'}),\n",
       " Document(page_content='# FIG\\n\\n## Figure. 1\\n Expression and activity of LDLR in CHO-ldlA7 cells transfected with wild-type (WT), c.1A>T, p.(Met1Leu), or c.1A>C, p.(Met1Leu) variants. After 24 h of overexpression, cells were lysed, and protein extracts were analyzed (A) by Western blot, as previously described in Methods. (B) The relative band intensities of both mature (black bars) and precursor (grey bars) LDLR forms were calculated, respectively, as the ratio of 160 kDa or 120 kDa LDLR band intensity to that of α-tubulin. (C) Black bars—LDLR expression; Dark grey bars—LDL(FITC)-LDLR binding after 3 h incubation at 4 °C; Light grey bars—LDL(FITC) internalization after 3 h incubation at 37 °C. Geometric fluorescence intensity of 15,000 events was acquired in a Facscalibur Flow cytometer, as mentioned above. All values represent the mean of triplicate independent determinations (n = 3); error bars represent ± SD. * p < 0.001 compared to LDLR WT using a two-tailed Student’s t-test.\\n\\n## Figure. 2\\n Relative luciferase activity of LDLR_pGL4 constructs with c.1A>T, p.(Met1Leu) or c.1A>C, p.(Met1Leu) variants. CHO-ldlA7 cells were transiently co-transfected with each one of the LDLR_pGL4 constructs (containing Firefly Luciferase—FLuc) and with the pRL-TK plasmid encoding the Renilla Luciferase (RLuc). Cells were lysed 24 h later, and the luciferase activity was measured by luminometry assays. FLuc activity values were normalized to RLuc activity to control for transfection efficiency. Relative luciferase activity of the LDLR_pGL4-WT (WT) construct was defined as one. All values represent the mean of triplicate independent determinations (n = 3); error bars represent ± SD. * p < 0.001 compared to LDLR WT using a two-tailed Student’s t-test.\\n', metadata={'source': '..\\\\PMC8467959\\\\chunks\\\\12.FIG.txt'}),\n",
       " Document(page_content='# TABLE\\n\\n## Table. 1\\n In silico results obtained by the different bioinformatics tools.\\n\\n| Variant | PROVEAN | SIFT | Polyphen-2 | Mutation Tester 2 | REVEL |\\n|--|--|--|--|--|--|\\n| c.1A>T, p.(Met1Leu) | Neutral | Damaging | Benign | disease causing | 0.638 |\\n| c.1A>C, p.(Met1Leu) | Neutral | Damaging | Benign | disease causing | 0.638 |\\n\\n\\n## Table. 2\\n ACMG/AMP classification with and without the functional data.\\n\\n| Variant | ACMG Classification without FS | Points without FS | ACMG Classification after FS * |\\n|--|--|--|--|\\n| c.1A>T, p.(Met1Leu) | VUS | PM2, PVS1_Moderate and PP4 | Likely pathogenic |\\n| c.1A>C, p.(Met1Leu) | Likely pathogenic | PM2, PVS1_Moderate PP1_Moderate, PP4, PS4_Supporting | Pathogenic |\\n\\n\\n FS—Functional study; VUS—variant of uncertain significance; * Classification with additional PS3 point.\\n\\n## Table. 3\\n Carriers of variant c.1A>C, p.(Met1Leu) found in the Portuguese FH Study.\\n\\n| Family | Age at Referral | Sex | Total-C * [mg/dL] | LDL-C * [mg/dL] | HDL-C * [mg/dL] | TG * [mg/dL] | BMI (Kg/m | LLT |\\n|--|--|--|--|--|--|--|--|--|\\n| 1—Index | 22 | F | 439 | 297 | 115 | 135 | NK | No |\\n| 2—Index | 38 | M | 288 | 222 | 48 | 90 | NK | No |\\n| 2 | 9 | F | 174 | 108 | 52 | 53 | NK | No |\\n| 3—Index | 2 | M | 281 | 226 | 47 | 93 | 16.8 | No |\\n| 3 | 3 | M | 284 | 220 | 51 | 95 | NK | No |\\n| 3 | 32 | F | 491 | 392 | 77 | 110 | NK | No |\\n| 4—Index | 12 | M | 257 | 174 | 68 | 32 | 22.6 | Atorvastatin |\\n| 4 | 41 | F | 227 | 149 | 63 | 50 | NK | Atorvastatin |\\n\\n\\n * Values at referral for a genetic test. TG—triglycerides; BMI—body mass index; LLT—lipid-lowering therapy; NK—not known.\\n', metadata={'source': '..\\\\PMC8467959\\\\chunks\\\\13.TABLE.txt'}),\n",
       " Document(page_content='# INTRO\\n\\n 1. Introduction\\n\\n Familial hypercholesterolemia (FH) (OMIM 143890) is an autosomal disorder of lipid metabolism characterized by increased plasma cholesterol levels and lipid accumulation in arteries and tendons, promoting premature atherosclerosis and coronary heart disease (CHD). FH is one of the most common genetic disorders with a frequency of around 1:250 in most populations, according to a recent meta-analysis. The FH phenotype can be caused by pathogenic variants in the three FH-associated genes (APOB, LDLR, and PCSK9) or by pathogenic variants in several phenocopies or alternative molecular etiologies (ABCG5/8, APOE, LDLRAP1, and LIPA), or it can even be due to a polygenic cause. Although the underlying genetics of the FH phenotype is complex, more than 90% of FH cases result from LDLR defects associated with an autosomal dominant inheritance pattern. Up to date, there are more than 2300 LDLR variants exclusively identified in FH patients. Another key feature of FH genetics is the phenotypic variability; there is a diversity of phenotypes between groups sorted by causative gene and mutation type, and it is not uncommon to observe a wide range of lipid levels among carriers of an identical FH-causing mutation. Moreover, the mutation type and the percentage of activity of LDLR variants can modulate the patients’ phenotype and response to lipid therapy. LDLR variants can be primarily divided into null variants and defective variants, with complete or partial loss of function, respectively. Several studies showed an association between higher levels of LDL cholesterol and null variants compared with defective variants. Additionally, the type of mutation can modulate response to statin therapy, as shown in Brazilian and Spanish cohorts, where null variants were associated with the lowest decrease of LDL levels upon treatment. LDLR mutations can be functionally classified into five groups: class I—no protein synthesis (null variants); class II—partial or complete retention of the protein at the endoplasmic reticulum; class III—defective binding; class IV—defective internalization or endocytosis; class V—defective recycling. Although the functional characterization is important for a correct patient diagnosis and management, less than 10% of all variants described in the LDLR gene have been functionally characterized. To improve diagnosis and patient management, here, we report two different missense variants (c.1A>T, p.(Met1Leu) and c.1A>C, p.(Met1Leu)) in the LDLR initiation codon, exhibiting distinct functional phenotypes.\\n', metadata={'source': '..\\\\PMC8467959\\\\chunks\\\\2.INTRO.txt'}),\n",
       " Document(page_content='# METHODS\\n\\n 2. Materials and Methods\\n\\n 2.1. Clinical Study\\n\\n The Portuguese FH Study is a research project continuously running since 1999 with the aim of identifying the genetic cause of hypercholesterolemia in individuals with a clinical diagnosis of FH. The study protocol and database have been approved by the National Institute of Health Ethics Committee and the National Data Protection Commission, respectively. Written informed consent was obtained from all participants before their inclusion in the study. Fasting blood samples were collected from all individuals at the time of their inclusion in the study. The biochemical characterization of lipids and lipoproteins was performed in a Cobas Integra 400 plus (Roche, Risch-Rotkreuz, Switzerland) by enzymatic colorimetric and immunoturbidimetric methods. All healthy individuals from whom the LDL used in the experiments was extracted followed the same exact procedure as any participant of the Portuguese FH Study.\\n\\n 2.2. Plasmid Constructs\\n\\n For Western blot and cytometry assays, the two missense variants under study, NM_000527.5:c.1A>T and NM_000527.5:c.1A>C, were individually introduced into the human LDLR cDNA (NM_000527.5) in the mammalian expression vector pcDNA3 under control of an SV40 promoter and enhancer. For luminometry assays, the promoter and the 5′ untranslated region (5′UTR) of LDLR (−319 bp upstream from ATG) were cloned upstream the Firefly Luciferase (FLuc) coding region in the pGL4.10 reporter plasmid (Promega, Madison, WI, USA), obtaining the LDLR_pGL4-WT construct. Both plasmids were subjected to oligonucleotide site-directed mutagenesis using the NZYMutagenesis kit (NZYTech, Lisbon, Portugal), according to the manufacturer’s instructions. For every variant, the presence of the correct variant and the integrity of the region was confirmed by direct Sanger sequencing.\\n\\n 2.3. Cell Culture and Transfection\\n\\n LDLR-deficient CHO-ldlA7 cells (Chinese hamster ovary cell line ldlA7), kindly provided by Dr. Monty Krieger, Massachusetts Institute of Technology, Cambridge, MA, were cultured in F-12 Nut Mix medium supplemented with 10% (v/v) fetal bovine serum (FBS, Invitrogen, Waltham, MA, USA), 100 units/mL penicillin, and 100 μg/mL streptomycin, and cells were grown at 37 °C in a humidified incubator containing 5% CO2.\\n\\n For Western blot and cytometry assays, cells were seeded in 6- or 24-well culture plates at 80% confluence (48 h) and were transfected with plasmids containing wild-type or mutant LDLR variants using Lipofectamine 2000 Transfection reagent (Invitrogen, Waltham, MA, USA) following manufacturer’s instructions. LDLR expression and LDL binding and internalization were assessed 24 h after transfection.\\n\\n For luminometry assays, transient transfections were performed using Lipofectamine 2000 Transfection Reagent (Invitrogen, Waltham, MA, USA) following the manufacturer’s instructions in 35-mm plates. Cells were co-transfected with 750 ng of the test DNA construct corresponding to the LDLR_pGL4-WT or its derivative plasmids and 500 ng of the pRL-TK plasmid (Promega, Madison, WI, USA), which encodes Renilla luciferase (RLuc) as an internal control, and then harvested after 24 h.\\n\\n 2.4. Western Blot Analysis\\n\\n Protein expression was determined for whole-cell extracts and fractionated by electrophoresis using NuPAGE™ 4%–12% Bis-Tris gel (Invitrogen, Waltham, MA, USA) and NuPAGE™ MOPS SDS Running Buffer (Invitrogen, Waltham, MA, USA) for semi-quantitative immunoblotting. PVDF membranes were immunostained overnight at 4 °C with a specific rabbit polyclonal antibody to the human LDL receptor (Progen Biotechnik, Heidelberg, Germany) and a monoclonal anti-α-tubulin antibody (Boster Biological Technology, Pleasanton, CA, USA) for protein loading control. After incubation with appropriate secondary antibodies, proteins were detected by chemiluminescence using Pierce™ ECL Plus Western Blotting Substrate (Thermo Scientific, Waltham, MA, USA) on a ChemiDoc (BioRad, Hercules, CA, USA). Relative band intensities of mature (≈160 kDa) and precursor (≈120 kDa) forms of LDLR protein were quantified by densitometric analysis using Image Lab Software (BioRad, Hercules, CA, USA) and normalized to levels of α-tubulin.\\n\\n 2.5. LDL Isolation and Labeling\\n\\n Plasma used for lipoprotein purification was collected from healthy individuals’ blood after 30 min centrifugation at 2465× g at room temperature (5810R, Eppendorf, Hamburg, Germany). For all samples, plasma density was adjusted to 1.21 g/mL with potassium bromide (KBr), and PBS buffer was added to obtain a clear separation between lipid fractions. LDL was isolated through ultracentrifugation carried out in a TST 41–14 rotor at 225,000× g for 19 h at 4 °C (Centrikon T-21X0, Kronton, Munich, Germany). The intermediate orange band corresponding to LDL was collected and stored at 4 °C.\\n\\n LDL was fluorescently labeled with fluorescein isothiocyanate (FITC). LDL was loaded in a 0.1 M NaHCO3 (pH 9.0) pre-equilibrated Sephadex G-25 column and then mixed under constant agitation with 10 μL FITC (2 mg/mL in DMSO) per lipoprotein milliliter at room temperature for 2 h. After incubation, free FITC was removed by gel filtration on a Sephadex G-25 column equilibrated with PBS EDTA-free buffer. Lipoprotein quantification was determined by the Pierce BCA protein assay.\\n\\n 2.6. LDLR Expression and Activity (Lipoprotein Binding and Internalization) by FACS\\n\\n LDLR cell surface expression was measured by FACS using mouse anti-human-LDLR (1:100; Progen Biotechnik, Heidelberg, Germany) as primary antibody and Alexa Fluor 488-conjugated goat anti-mouse IgG (1:200; Molecular Probes, Eugene, OR, USA) as the secondary antibody. Briefly, cells were incubated at 4 °C, overnight with the primary antibody after fixing (10 min in 4% paraformaldehyde) and blocking (1 h with PBS-5% FBS) steps. Next, cells were incubated for 1 h at room temperature with the secondary antibody. For each sample, the fluorescence of 15,000 events was acquired for data analysis, and measurements were performed in triplicate. All washes were done with PBS-1% BSA.\\n\\n For quantification of LDLR activity, cells were seeded in 24-well culture plates and transfected, as previously described. Briefly, 24 h after transfection, cells were incubated for 3 h at 37 °C or 4 °C with 20 μg/mL FITC-LDL to determine LDL internalization or LDL-LDLR binding, respectively. After incubation, cells were washed three times, fixed for 10 min in 4% paraformaldehyde, and washed again three times. The amount of internalized LDL was determined by adding Trypan blue solution to a 0.2% final concentration (Sigma-Aldrich, Steinheim, Germany) to the samples. This dye quenches external fluorescence, eliminating the signal of non-internalized LDLR-LDL complexes, allowing the determination of the intensity of the remaining fluorescent particles inside the cells. Fluorescence intensities were measured by flow cytometry in a Facscalibur Flow cytometer. For each sample, the fluorescence of 15,000 events was acquired for data analysis, and measurements were performed in triplicate. All washes were done with PBS-1% BSA.\\n\\n 2.7. Luminometry Assay \\n\\n Cell lysis was performed with Passive Lysis Buffer (Promega). The cell lysates were used to determine relative FLuc and RLuc activities using the Dual-Luciferase® Reporter Assay System (Promega), according to the manufacturer’s instructions, on a GloMax® 96 Microplate Luminometer (Promega). The collected data was expressed in arbitrary light units. Luciferase activity was obtained by normalizing FLuc to RLuc luminescence for each sample, and each value was derived from three independent experiments.\\n\\n 2.8. American College of Medical Genetics (ACMG) Classification and In Silico Analysis\\n\\n Both variants were classified according to the Clinical Genome resource FH variant curation expert panel specifications for the ACMG/AMP Variant Interpretation Guidelines. Additionally, the potential effects of the two variants were evaluated by 5 software tools: PROVEAN, SIFT, PolyPhen2, MutationTaster, and REVEL.\\n\\n 2.9. Statistical Analysis\\n\\n Results are expressed as mean ± standard deviation. The Student’s t-test was used for the estimation of statistical significance. Significance for statistical analysis was defined as a p < 0.001.\\n', metadata={'source': '..\\\\PMC8467959\\\\chunks\\\\3.METHODS.txt'}),\n",
       " Document(page_content='# RESULTS\\n\\n 3. Results\\n\\n 3.1. In Silico and ACMG Classification\\n\\n The bioinformatics prediction for the pathogenicity of the two variants displays conflicting classification between the different software but not among themselves (Table 1).\\n\\n Initially, variants c.1A>T, p.(Met1Leu), and c.1A>C, p.(Met1Leu) were classified as VUS (variant of uncertain significance) and Likely Pathogenic, respectively. Once the functional data were integrated into the algorithm, the classification has improved to Likely Pathogenic and Pathogenic (Table 2).\\n\\n 3.2. Functional Profiling of Variants c.1A>T and c.1A>C\\n\\n Aiming to understand the functional consequences of both variants, protein levels from each variant were analyzed by Western blot (Figure 1A), and relative levels of LDLR expression were determined by quantitative densitometry, using α-tubulin protein expression as an internal control (Figure 1B). This analysis revealed different mature and precursor LDLR expression levels between the two variants (Figure 1A). LDLR variant c.1A>T produces almost no protein, showing a similar protein profile to the mock control. Whereas in LDLR variant c.1A>C, both mature and precursor forms of LDLR were detected, being the expression lower compared to the wild-type (WT) receptor (Figure 1B).\\n\\n To quantify the expression and activity of both LDLR variants, CHO-ldlA7 cells were transiently transfected with WT LDLR, c.1A>T, p.(Met1Leu), or c.1A>C, p.(Met1Leu) constructs to determine the ability of the receptor to bind and internalize labeled LDL. Results for cell surface LDLR expression, LDL (FITC)-LDLR binding, and internalization are illustrated in Figure 1C. WT transfection was used for normalization of results, and it represents 100% of expression and activity. Both variants exhibit expression and activity levels below 70% of the WT LDLR; therefore, they are considered to affect LDLR function. Cut-offs for this limit were used from Chora et al. (2021). The two variants exhibit cell surface expression lower than WT LDLR, and consequently, binding and internalization levels are also diminished. Variant c.1A>T shows expression and activity levels below 10%, whereas variant c.1A>C has expression and activity levels around 60%.\\n\\n Additionally, luminometry assays were performed to check the effect of the two variants in protein synthesis (Figure 2). Relative luciferase activity of constructs pGL4-c.1A>T and pGL4-c.1A>C is 0.5% and 5% of the normal control, respectively. Thus, both c.1A>T and c.1A>C LDLR variants repress protein expression of the downstream reporter gene, although with different intensities.\\n\\n 3.3. Phenotype of Patients with Variant c.1A>C, p(Met1Leu)\\n\\n Only the variant c.1A>C is identified in the Portuguese FH Study in four different families exhibiting an autosomal dominant inheritance pattern. A total of eight individuals carries this variant—four index cases and four relatives (Table 3). The eight carriers present untreated values of total and LDL cholesterol (LDL-C) ranging from 288 to 491 mg/dL and from 222 to 392 mg/dL, respectively, in adults. In children, total cholesterol and LDL-C range from 174 to 284 mg/dL and from 108 to 226 mg/dL, respectively.\\n', metadata={'source': '..\\\\PMC8467959\\\\chunks\\\\4.RESULTS.txt'}),\n",
       " Document(page_content='# DISCUSS\\n\\n 4. Discussion\\n\\n Both LDLR variants (c.1A>T and c.1A>C) are predicted to change Methionine (AUG) to Leucine [UUG or CUG, respectively; p.(Met1Leu)]. Here, we investigated the functional consequences of these two LDLR variants. Our data show that both variants are able to mediate translation initiation, although the expression of variant c.1A>T is very low. Translation has been traditionally considered to initiate at the universal AUG start codon. However, due to the advent of the ribosome profiling technique, it is now clear that many non-AUG codons can function as non-canonical start codons. Accordingly, here we show that the UUG and CUG Leucine codons are able to function as translation initiation codons for the LDLR protein. Our data also show that these two Leucine codons mediate translation initiation with different efficiencies, being the UUG codon a much less efficient initiator. Indeed, these results are in accordance with what has been described, showing that, in eukaryotes, the substitution of the initiating codon CUG for an alternate Leucine-encoding UUG codon drastically reduces protein expression. Moreover, the CUG codon is the most prevalent non-AUG start codon found in upstream open reading frames. Although the key eukaryotic initiation factor (eIF), eIF2, does not significantly bind other tRNAs besides Met-tRNAiMet, it is known that other eIFs can substitute eIF2 for initiation at non-AUG codons. eIF2A, for instance, can deliver Leu-tRNACUG and even Met-tRNAiMet to initiate translation at non-AUG start codons in a GTP-independent manner. Accordingly, depletion of eIF2A does not significantly impair global protein synthesis, neither affects translation initiation at AUGs, but has a negative impact on initiation at CUG or UUG codons. These pieces of evidence well support the contrasting in vitro phenotypes observed between the two variants regarding LDLR expression. As shown, the construct with the variant c.1A>T has residual LDLR expression and consequently very low LDL binding and internalization abilities. Nonetheless, the construct with the variant c.1A>C partially expresses LDLR, and the binding and internalization activities are coherently affected. Moreover, our results from the FLuc-based reporter constructs also support these data. However, the expression of these constructs is significantly lower than the one from the constructs with the LDLR open reading frame (ORF) (5% versus 60% and 0.5% versus 10% for c.1A>C and c.1A>T, respectively; Figure 1C and Figure 2). One possible explanation for this discrepancy could be the existence of RNA secondary structures downstream the start codons that could favor recognition of the non-canonical, UUG and CUG, codons on the pcDNA3 constructs (LDLR ORF) when compared to the pGL4 constructs (Luciferase ORF). This idea is supported by previous reports showing that recognition of non-canonical codons by the scanning ribosomes is favored by GC-rich downstream regions that potentiate the formation of hairpin-like structures. These secondary structures are thought to slow down the ribosomal scanning process, giving time for translation initiation to occur on sub-optimal codons. Accordingly, the mRNA secondary structure obtained from mFOLD (; accessed on 7 February 2021) using the first 100 nucleotides of the LDLR coding sequence is more stable than the one corresponding to the first 100 nucleotides of the Luciferase ORF.\\n\\n Considering the functional data gathered on the two variants, variant c.1A>T is classified as an LDLR class I mutation, with no protein synthesis (null variant), whereas variant c.1A>C phenotype is similar to LDLR class II mutations, with partial retention of the immature protein at the endoplasmic reticulum. These distinct phenotypes, a null and a defective allele type variant, highlight the importance of functionally characterizing and classifying LDLR variants. Carriers of a null allele variant present higher LDL values and higher rates of premature CHD than a defective allele carrier. As such, functional characterization is important for cardiovascular risk stratification. Considering our in vitro results, a distinctive severity of FH phenotype in carriers of these variants is expected, with carriers of the variant c.1A>C exhibiting a milder phenotype compared to c.1A>T carriers.\\n\\n According to ACMG/AMP guidelines for the classification of genetic variants, c.1A>T and c.1A>C are classified, respectively, as likely pathogenic and pathogenic variants, taking into consideration the functional study results. However, functionally, they have different performances, as described above. ACMG classification classifies a variant as likely pathogenic or pathogenic or likely benign or benign but does not characterize the level to which the variant affects the protein, which can be determined only with functional studies.\\n\\n Whereas the variant c.1A>T was first described in 1996 in a compound heterozygous (CH) patient from South Africa, variant c.1A>C was first identified in 2001 in a heterozygous patient from Spain (no lipid information provided). As expected for an FH homozygous or compound heterozygous individual, the CH patient carrying the variant c.1A>T exhibits extremely high levels of total and LDL cholesterol (LDL-C), 719 mg/dL and 669 mg/dL, respectively. Additionally, the variant c.1A>T is also identified in two first degree relatives of the CH patient with ages of 36 and 18 years old, presenting values of total and LDL-C of 363 mg/dL and 305 mg/dL and 305 mg/dL and 232 mg/dL, respectively. Unfortunately, no data on lipid-lowering treatment is provided for any of these individuals. To date, only the variant c.1A>C is identified in the Portuguese FH Study in four different families exhibiting an autosomal dominant inheritance pattern. As reported in the results, the eight carriers present a wide range of untreated values of total and LDL-C, showing the already mentioned heterogeneity in phenotypes presented by carriers of the same variant. There are several cholesterol modulators from age, body mass index, diet, physical exercise, and co-occurrence of other disorders and treatments that can account for this phenotypical heterogeneity. In this case, since the variants under study are in the LDLR translation initiation codon and originate a non-canonical initiator, we can speculate that some factors involved in non-canonical translation initiation may also be modulating it with different efficiencies among patients, leading to distinct phenotypes.\\n\\n It is known that the type of mutation can modulate the response to statin therapy, where null variants have the lowest decrease of LDL levels upon treatment. In adults, the lowest observed values of total and LDL-C (227 mg/dL and 149 mg/dL) correspond to an individual undergoing statin therapy, who before treatment had 400 mg/dL of total cholesterol (LDL-C values before treatment not known). The child of this individual also undergoing statin therapy shows a reduction of 23% and 30% of total and LDL-C, i.e., from 335 mg/dL and 250 mg/dL to 257 mg/dL and 174 mg/dL, respectively. This good response to treatment goes to the encounter of our results, to the extent that considering the mechanism of action of statins, theoretically, carriers of putative null variants should not greatly benefit from this therapy. However, from carriers of a variant with partial activity, such as c.1A>C, a good response to statin treatment is expected, as observed in these individuals. Both c.1A>C and c.1A>T variants exert their pathogenicity by means of low expression of LDLR; the second one is close to null expression. Although the expression is reduced, the activity of the synthesized receptors is normal, and so they play their role in the clearance of LDL from circulation. This way, the effect of statin therapy, which blocks cholesterol biosynthesis and promotes the hepatic expression of LDLR, should have a more beneficial impact on carriers of variant c.1A>C compared to c.1A>T carriers. \\n', metadata={'source': '..\\\\PMC8467959\\\\chunks\\\\5.DISCUSS.txt'}),\n",
       " Document(page_content='# CONCL\\n\\n 5. Conclusions\\n\\n In conclusion, we have characterized 2 different LDLR missense variants in the translation initiation codon, which codify for the same amino acid p.(Met1Leu) but have a distinct impact on LDLR expression and activity. The two variants exhibit different functional behaviors: cytometry and luciferase assays show that variant c.1A>T/p.(Met1Leu) acts like a null variant with extremely low levels of protein expression and consequent null activity; conversely, variant c.1A>C/p.(Met1Leu) is able to initiate translation with a higher efficiency, which renders a significant LDLR activity to this variant. Our data gives new functional insight into these two variants, leading to an improved ACMG classification, which can be used in the choice of the lipid-lowering treatment and dyslipidemia management for a more personalized approach, which, in the end, can lead to a better patient prognosis. With this work, we have also contributed with evidence to the function of non-canonical initiation codons in translation initiation. However, additional experiments are required to fully unveil the underlying mechanism through which mRNA translation initiation is affected.\\n\\n Publisher’s Note: MDPI stays neutral with regard to jurisdictional claims in published maps and institutional affiliations.\\n', metadata={'source': '..\\\\PMC8467959\\\\chunks\\\\6.CONCL.txt'}),\n",
       " Document(page_content='# AUTH_CONT\\n\\n Author Contributions\\n\\n Conceptualization, L.R. and M.B.; methodology, R.G., R.F., A.C.A. and J.M.; validation, A.C.A. and J.M.; formal analysis, R.G. and R.F.; writing—original draft preparation, R.G. and R.F.; writing—review and editing, R.G., L.R. and M.B., supervision, L.R. and M.B. All authors have read and agreed to the published version of the manuscript.\\n', metadata={'source': '..\\\\PMC8467959\\\\chunks\\\\7.AUTH_CONT.txt'}),\n",
       " Document(page_content='# ACK_FUND\\n\\n Funding\\n\\n This research received no external funding.\\n\\n Institutional Review Board Statement\\n\\n The study was conducted according to the guidelines of the Declaration of Helsinki, and the Portuguese FH Study was approved by the National Institute of Health Ethics Committee and the National Data Protection Commission on 21 September 2009, protocol code 3962/2009.\\n\\n Informed Consent Statement\\n\\n Informed consent was obtained from all subjects involved in the study.\\n', metadata={'source': '..\\\\PMC8467959\\\\chunks\\\\8.ACK_FUND.txt'}),\n",
       " Document(page_content='# SUPPL\\n\\n Data Availability Statement\\n\\n The data that support the findings of this study are available from the corresponding author upon reasonable request.\\n', metadata={'source': '..\\\\PMC8467959\\\\chunks\\\\9.SUPPL.txt'})]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = DirectoryLoader(\"../PMC8467959/chunks/\", glob=\"**/*.txt\", loader_cls=TextLoader)\n",
    "docs = loader.load()\n",
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Indexing: Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our loaded document is too long to fit in the context window of many models, and models can struggle to find information in very long inputs. \n",
    "\n",
    "To handle this we'll **split the document** into chunks for embedding and vector storage. This should help us retrieve only the most relevant bits of the blog post at run time. In this case we'll split our documents into chunks of 1000 characters with 200 characters of overlap between chunks.\n",
    "\n",
    "The **overlap** helps mitigate the possibility of separating a statement from important context related to it. We use the `RecursiveCharacterTextSplitter`, which will recursively split the document using common separators like new lines until each chunk is the appropriate size. This is the recommended text splitter for generic text use cases.\n",
    "\n",
    "We set `add_start_index=True` so that the character index at which each split Document starts within the initial Document is preserved as metadata attribute `start_index`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    "    add_start_index=True \n",
    ")\n",
    "\n",
    "all_splits = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54 splits\n",
      "992 characters\n",
      "Familial hypercholesterolemia (FH) is the most common genetic disorder of lipid metabolism, characterized by increased levels of total and LDL plasma cholesterol, which leads to premature atherosclerosis and coronary heart disease. FH phenotype has considerable genetic heterogeneity and phenotypic variability, depending on LDL receptor activity and lifestyle. To improve diagnosis and patient management, here, we characterized two single nucleotide missense substitutions at Methionine 1 of the human LDLR gene (c.1A>T/p.(Met1Leu) and c.1A>C/p.(Met1Leu)). We used a combination of Western blot, flow cytometry, and luciferase assays to determine the effects of both variants on the expression, activity, and synthesis of LDLR. Our data show that both variants can mediate translation initiation, although the expression of variant c.1A>T is very low. Both variants are in the translation initiation codon and codify for the same amino acid p.(Met1Leu), yet they lead to different levels of\n",
      "{'source': '..\\\\PMC8467959\\\\chunks\\\\1.ABSTRACT.txt', 'start_index': 13}\n"
     ]
    }
   ],
   "source": [
    "print(len(all_splits),\"splits\")\n",
    "print(len(all_splits[2].page_content),\"characters\")\n",
    "print(all_splits[2].page_content)\n",
    "print(all_splits[2].metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Vector RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableParallel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Indexing: Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = Chroma.from_documents(documents=all_splits, embedding=OpenAIEmbeddings())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Retrieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 6})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='# ABSTRACT', metadata={'source': '..\\\\PMC8467959\\\\chunks\\\\1.ABSTRACT.txt', 'start_index': 0}),\n",
       " Document(page_content='# ACK_FUND\\n\\n Funding\\n\\n This research received no external funding.\\n\\n Institutional Review Board Statement\\n\\n The study was conducted according to the guidelines of the Declaration of Helsinki, and the Portuguese FH Study was approved by the National Institute of Health Ethics Committee and the National Data Protection Commission on 21 September 2009, protocol code 3962/2009.\\n\\n Informed Consent Statement\\n\\n Informed consent was obtained from all subjects involved in the study.', metadata={'source': '..\\\\PMC8467959\\\\chunks\\\\8.ACK_FUND.txt', 'start_index': 0}),\n",
       " Document(page_content='# INTRO\\n\\n 1. Introduction', metadata={'source': '..\\\\PMC8467959\\\\chunks\\\\2.INTRO.txt', 'start_index': 0}),\n",
       " Document(page_content='Publisher’s Note: MDPI stays neutral with regard to jurisdictional claims in published maps and institutional affiliations.', metadata={'source': '..\\\\PMC8467959\\\\chunks\\\\6.CONCL.txt', 'start_index': 1198}),\n",
       " Document(page_content='# AUTH_CONT\\n\\n Author Contributions\\n\\n Conceptualization, L.R. and M.B.; methodology, R.G., R.F., A.C.A. and J.M.; validation, A.C.A. and J.M.; formal analysis, R.G. and R.F.; writing—original draft preparation, R.G. and R.F.; writing—review and editing, R.G., L.R. and M.B., supervision, L.R. and M.B. All authors have read and agreed to the published version of the manuscript.', metadata={'source': '..\\\\PMC8467959\\\\chunks\\\\7.AUTH_CONT.txt', 'start_index': 0}),\n",
       " Document(page_content='# COMP_INT\\n\\n Conflicts of Interest\\n\\n The authors declare no conflict of interest.', metadata={'source': '..\\\\PMC8467959\\\\chunks\\\\10.COMP_INT.txt', 'start_index': 0})]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# EXAMPLE\n",
    "retrieved_docs = retriever.invoke(prompts[0])\n",
    "retrieved_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"You are an assistant for question-answering tasks on a scientific paper, including classification and summarization of this paper.\n",
    "Use the following pieces of context to answer the question.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "\n",
    "CONTEXT: {context}\n",
    "\n",
    "QUESTION: {question}\n",
    "\n",
    "ANSWER:\"\"\"\n",
    "\n",
    "prompt_vector_rag = PromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We’ll use the LCEL Runnable protocol to define the chain, allowing us to - pipe together components and functions in a transparent way - automatically trace our chain in LangSmith - get streaming, async, and batched calling out of the box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "rag_chain_from_docs = (\n",
    "    RunnablePassthrough.assign(context=(lambda x: format_docs(x[\"context\"])))\n",
    "    | prompt_vector_rag\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "rag_chain_with_source = RunnableParallel(\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    ").assign(answer=rag_chain_from_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context': [Document(page_content='Familial hypercholesterolemia: A complex genetic disease with variable phenotypes\\n\\n Genetic identification of familial hypercholesterolemia within a single U.S. Health care system\\n\\n Mutational analysis and genotype-phenotype relation in familial hypercholesterolemia: The SAFEHEART registry\\n\\n Diagnostic Yield of Sequencing Familial Hypercholesterolemia Genes in Severe Hypercholesterolemia\\n\\n Attainment of LDL-cholesterol treatment goals in patients with familial hypercholesterolemia: 5-year SAFEHEART registry follow-up\\n\\n Presence and type of low density lipoprotein receptor (LDLR) mutation influences the lipid profile and response to lipid-lowering therapy in Brazilian patients with heterozygous familial hypercholesterolemia\\n\\n Molecular genetics of the LDL receptor gene in familial hypercholesterolemia\\n\\n Update of the Portuguese Familial Hypercholesterolaemia Study', metadata={'source': '..\\\\PMC8467959\\\\chunks\\\\11.REF.txt', 'start_index': 745}),\n",
       "  Document(page_content='Familial hypercholesterolemia (FH) is the most common genetic disorder of lipid metabolism, characterized by increased levels of total and LDL plasma cholesterol, which leads to premature atherosclerosis and coronary heart disease. FH phenotype has considerable genetic heterogeneity and phenotypic variability, depending on LDL receptor activity and lifestyle. To improve diagnosis and patient management, here, we characterized two single nucleotide missense substitutions at Methionine 1 of the human LDLR gene (c.1A>T/p.(Met1Leu) and c.1A>C/p.(Met1Leu)). We used a combination of Western blot, flow cytometry, and luciferase assays to determine the effects of both variants on the expression, activity, and synthesis of LDLR. Our data show that both variants can mediate translation initiation, although the expression of variant c.1A>T is very low. Both variants are in the translation initiation codon and codify for the same amino acid p.(Met1Leu), yet they lead to different levels of', metadata={'source': '..\\\\PMC8467959\\\\chunks\\\\1.ABSTRACT.txt', 'start_index': 13}),\n",
       "  Document(page_content='Familial hypercholesterolemia (FH) (OMIM 143890) is an autosomal disorder of lipid metabolism characterized by increased plasma cholesterol levels and lipid accumulation in arteries and tendons, promoting premature atherosclerosis and coronary heart disease (CHD). FH is one of the most common genetic disorders with a frequency of around 1:250 in most populations, according to a recent meta-analysis. The FH phenotype can be caused by pathogenic variants in the three FH-associated genes (APOB, LDLR, and PCSK9) or by pathogenic variants in several phenocopies or alternative molecular etiologies (ABCG5/8, APOE, LDLRAP1, and LIPA), or it can even be due to a polygenic cause. Although the underlying genetics of the FH phenotype is complex, more than 90% of FH cases result from LDLR defects associated with an autosomal dominant inheritance pattern. Up to date, there are more than 2300 LDLR variants exclusively identified in FH patients. Another key feature of FH genetics is the phenotypic', metadata={'source': '..\\\\PMC8467959\\\\chunks\\\\2.INTRO.txt', 'start_index': 28}),\n",
       "  Document(page_content='Molecular genetics of the LDL receptor gene in familial hypercholesterolemia\\n\\n Update of the Portuguese Familial Hypercholesterolaemia Study\\n\\n Mutational analysis of a cohort with clinical diagnosis of familial hypercholesterolemia: Considerations for genetic diagnosis improvement\\n\\n Estudo Português de hipercolesterolemia familiar: Apresentação do estudo e resultados preliminares\\n\\n Title: The Clinical Genome Resource (ClinGen) Familial Hypercholesterolemia Variant Curation Expert Panel consensus guidelines for LDLR variant classification\\n\\n Predicting the Functional Effect of Amino Acid Substitutions and Indels\\n\\n Predicting the effects of coding non-synonymous variants on protein function using the SIFT algorithm\\n\\n A method and server for predicting damaging missense mutations\\n\\n MutationTaster evaluates disease-causing potential of sequence alterations\\n\\n REVEL: An Ensemble Method for Predicting the Pathogenicity of Rare Missense Variants', metadata={'source': '..\\\\PMC8467959\\\\chunks\\\\11.REF.txt', 'start_index': 1480}),\n",
       "  Document(page_content='# METHODS\\n\\n 2. Materials and Methods\\n\\n 2.1. Clinical Study\\n\\n The Portuguese FH Study is a research project continuously running since 1999 with the aim of identifying the genetic cause of hypercholesterolemia in individuals with a clinical diagnosis of FH. The study protocol and database have been approved by the National Institute of Health Ethics Committee and the National Data Protection Commission, respectively. Written informed consent was obtained from all participants before their inclusion in the study. Fasting blood samples were collected from all individuals at the time of their inclusion in the study. The biochemical characterization of lipids and lipoproteins was performed in a Cobas Integra 400 plus (Roche, Risch-Rotkreuz, Switzerland) by enzymatic colorimetric and immunoturbidimetric methods. All healthy individuals from whom the LDL used in the experiments was extracted followed the same exact procedure as any participant of the Portuguese FH Study.', metadata={'source': '..\\\\PMC8467959\\\\chunks\\\\3.METHODS.txt', 'start_index': 0}),\n",
       "  Document(page_content='the variant c.1A>C is identified in the Portuguese FH Study in four different families exhibiting an autosomal dominant inheritance pattern. As reported in the results, the eight carriers present a wide range of untreated values of total and LDL-C, showing the already mentioned heterogeneity in phenotypes presented by carriers of the same variant. There are several cholesterol modulators from age, body mass index, diet, physical exercise, and co-occurrence of other disorders and treatments that can account for this phenotypical heterogeneity. In this case, since the variants under study are in the LDLR translation initiation codon and originate a non-canonical initiator, we can speculate that some factors involved in non-canonical translation initiation may also be modulating it with different efficiencies among patients, leading to distinct phenotypes.', metadata={'source': '..\\\\PMC8467959\\\\chunks\\\\5.DISCUSS.txt', 'start_index': 5688})],\n",
       " 'question': 'How can these findings help improve diagnosis and treatment for Familial Hypercholesterolemia?',\n",
       " 'answer': 'These findings can help improve diagnosis and treatment for Familial Hypercholesterolemia by providing insights into the genetic factors influencing the phenotype variability in patients with FH. Understanding how specific LDLR gene variants affect expression, activity, and synthesis of LDLR can aid in the development of personalized treatment strategies. Additionally, identifying different factors involved in non-canonical translation initiation may lead to a better understanding of the mechanisms underlying FH and potentially guide the development of targeted therapies for individuals with specific genetic variations.'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_vec = rag_chain_with_source.invoke(prompts[2])\n",
    "\n",
    "with open('result_vector_rag.txt', 'w') as file:\n",
    "    file.write(str(result_vec))\n",
    "\n",
    "result_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Graph RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.graphs import Neo4jGraph\n",
    "from neo4j.exceptions import ClientError\n",
    "from langchain_experimental.graph_transformers import LLMGraphTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.0. Setup Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = Neo4jGraph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Graph has been reset.\n"
     ]
    }
   ],
   "source": [
    "# Function to reset the graph\n",
    "def reset_graph(graph):\n",
    "    try:\n",
    "        # Cypher query to delete all nodes and relationships\n",
    "        graph.query(\"MATCH (n) DETACH DELETE n\")\n",
    "        print(\"The Graph has been reset.\")\n",
    "    except ClientError as e:\n",
    "        print(f\"Client error during graph reset: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during graph reset: {e}\")\n",
    "\n",
    "# Reset the graph\n",
    "reset_graph(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='# TITLE\\n\\n Characterization of Two Variants at Met 1 of the Human LDLR Gene Encoding the Same Amino Acid but Causing Different Functional Phenotypes', metadata={'source': '..\\\\PMC8467959\\\\chunks\\\\0.TITLE.txt', 'start_index': 0, 'id': '23ad1f11370f46bf251982cd2b3e24d6'}),\n",
       " Document(page_content='# ABSTRACT', metadata={'source': '..\\\\PMC8467959\\\\chunks\\\\1.ABSTRACT.txt', 'start_index': 0, 'id': '156810d7cc8a2fcb362480ad3d2eed39'}),\n",
       " Document(page_content='Familial hypercholesterolemia (FH) is the most common genetic disorder of lipid metabolism, characterized by increased levels of total and LDL plasma cholesterol, which leads to premature atherosclerosis and coronary heart disease. FH phenotype has considerable genetic heterogeneity and phenotypic variability, depending on LDL receptor activity and lifestyle. To improve diagnosis and patient management, here, we characterized two single nucleotide missense substitutions at Methionine 1 of the human LDLR gene (c.1A>T/p.(Met1Leu) and c.1A>C/p.(Met1Leu)). We used a combination of Western blot, flow cytometry, and luciferase assays to determine the effects of both variants on the expression, activity, and synthesis of LDLR. Our data show that both variants can mediate translation initiation, although the expression of variant c.1A>T is very low. Both variants are in the translation initiation codon and codify for the same amino acid p.(Met1Leu), yet they lead to different levels of', metadata={'source': '..\\\\PMC8467959\\\\chunks\\\\1.ABSTRACT.txt', 'start_index': 13, 'id': 'a1dcad8ffa18cf2553088e895770df4a'}),\n",
       " Document(page_content='although the expression of variant c.1A>T is very low. Both variants are in the translation initiation codon and codify for the same amino acid p.(Met1Leu), yet they lead to different levels of impairment on LDLR expression and activity, corroborating different efficiencies of the translation initiation at these non-canonical initiation codons. The functional data of these variants allowed for an improved American College of Medical Genetics (ACMG) classification for both variants, which can allow a more personalized choice of the lipid-lowering treatment and dyslipidemia management, ultimately improving patients’ prognosis.', metadata={'source': '..\\\\PMC8467959\\\\chunks\\\\1.ABSTRACT.txt', 'start_index': 812, 'id': 'c17d0982109945b667d1b772d1a13327'}),\n",
       " Document(page_content='# COMP_INT\\n\\n Conflicts of Interest\\n\\n The authors declare no conflict of interest.', metadata={'source': '..\\\\PMC8467959\\\\chunks\\\\10.COMP_INT.txt', 'start_index': 0, 'id': '16f8d2f2a6cb90d8d2b1d2e0d374f65c'}),\n",
       " Document(page_content='# REF\\n\\n References\\n\\n A receptor-mediated pathway for cholesterol homeostasis\\n\\n Estimating the prevalence of heterozygous familial hypercholesterolaemia: A systematic review and meta-analysis\\n\\n The complex molecular genetics of familial hypercholesterolaemia\\n\\n Low-density lipoprotein receptor mutational analysis in diagnosis of familial hypercholesterolemia\\n\\n The familial hypercholesterolaemia phenotype: Monogenic familial hypercholesterolaemia, polygenic hypercholesterolaemia and other causes\\n\\n Use of low-density lipoprotein cholesterol gene score to distinguish patients with polygenic and monogenic familial hypercholesterolaemia: A case-control study\\n\\n ClinVar database of global familial hypercholesterolemia-associated DNA variants\\n\\n Familial hypercholesterolemia: A complex genetic disease with variable phenotypes\\n\\n Genetic identification of familial hypercholesterolemia within a single U.S. Health care system', metadata={'source': '..\\\\PMC8467959\\\\chunks\\\\11.REF.txt', 'start_index': 0, 'id': '61aed8a0fba49f411b5eeb1f18071890'}),\n",
       " Document(page_content='Familial hypercholesterolemia: A complex genetic disease with variable phenotypes\\n\\n Genetic identification of familial hypercholesterolemia within a single U.S. Health care system\\n\\n Mutational analysis and genotype-phenotype relation in familial hypercholesterolemia: The SAFEHEART registry\\n\\n Diagnostic Yield of Sequencing Familial Hypercholesterolemia Genes in Severe Hypercholesterolemia\\n\\n Attainment of LDL-cholesterol treatment goals in patients with familial hypercholesterolemia: 5-year SAFEHEART registry follow-up\\n\\n Presence and type of low density lipoprotein receptor (LDLR) mutation influences the lipid profile and response to lipid-lowering therapy in Brazilian patients with heterozygous familial hypercholesterolemia\\n\\n Molecular genetics of the LDL receptor gene in familial hypercholesterolemia\\n\\n Update of the Portuguese Familial Hypercholesterolaemia Study', metadata={'source': '..\\\\PMC8467959\\\\chunks\\\\11.REF.txt', 'start_index': 745, 'id': '5fd1d7bdc09fa760fe789ade0ddad12b'}),\n",
       " Document(page_content='Molecular genetics of the LDL receptor gene in familial hypercholesterolemia\\n\\n Update of the Portuguese Familial Hypercholesterolaemia Study\\n\\n Mutational analysis of a cohort with clinical diagnosis of familial hypercholesterolemia: Considerations for genetic diagnosis improvement\\n\\n Estudo Português de hipercolesterolemia familiar: Apresentação do estudo e resultados preliminares\\n\\n Title: The Clinical Genome Resource (ClinGen) Familial Hypercholesterolemia Variant Curation Expert Panel consensus guidelines for LDLR variant classification\\n\\n Predicting the Functional Effect of Amino Acid Substitutions and Indels\\n\\n Predicting the effects of coding non-synonymous variants on protein function using the SIFT algorithm\\n\\n A method and server for predicting damaging missense mutations\\n\\n MutationTaster evaluates disease-causing potential of sequence alterations\\n\\n REVEL: An Ensemble Method for Predicting the Pathogenicity of Rare Missense Variants', metadata={'source': '..\\\\PMC8467959\\\\chunks\\\\11.REF.txt', 'start_index': 1480, 'id': 'e36b94b70ab65d1f2d347bd8d17fd98c'}),\n",
       " Document(page_content='MutationTaster evaluates disease-causing potential of sequence alterations\\n\\n REVEL: An Ensemble Method for Predicting the Pathogenicity of Rare Missense Variants\\n\\n Genome-Wide Analysis in Vivo of Resolution Using Ribosome Profiling\\n\\n Non-AUG translation: A new start for protein synthesis in eukaryotes\\n\\n Constitutive display of cryptic translation products by MHC class I molecules\\n\\n Ribosome Profiling of Mouse Embryonic Stem Cells Reveals the Complexity and Dynamics of Mammalian Proteomes\\n\\n Leucine-tRNA initiates at CUG start codons for protein synthesis and presentation by MHC class I\\n\\n Translation from the 5’ untranslated region shapes the integrated stress response\\n\\n Downstream secondary structure facilitates recognition of initiator codons by eukaryotic ribosomes\\n\\n The helicase Ded1p controls use of near-cognate translation initiation codons in 5′ UTRs', metadata={'source': '..\\\\PMC8467959\\\\chunks\\\\11.REF.txt', 'start_index': 2269, 'id': 'b2a32c873f273cb97d625c79e5cc69b2'}),\n",
       " Document(page_content='Downstream secondary structure facilitates recognition of initiator codons by eukaryotic ribosomes\\n\\n The helicase Ded1p controls use of near-cognate translation initiation codons in 5′ UTRs\\n\\n Phenotypical, clinical, and molecular aspects of adults and children with homozygous familial hypercholesterolemia in iberoamerica\\n\\n Two novel point mutations causing receptor-negative familial hypercholesterolemia in a South African Indian homozygote\\n\\n Genetic diagnosis of familial hypercholesterolemia in a South European outbreed population: Influence of low-density lipoprotein (LDL) receptor gene mutations on treatment response to simvastatin in total, LDL, and high-density lipoprotein cholesterol\\n\\n 2019 ESC/EAS guidelines for the management of dyslipidaemias: Lipid modification to reduce cardiovascular risk', metadata={'source': '..\\\\PMC8467959\\\\chunks\\\\11.REF.txt', 'start_index': 2947, 'id': 'ceb054f1d59fd15899f8eb7a3899e317'}),\n",
       " Document(page_content='# FIG\\n\\n## Figure. 1\\n Expression and activity of LDLR in CHO-ldlA7 cells transfected with wild-type (WT), c.1A>T, p.(Met1Leu), or c.1A>C, p.(Met1Leu) variants. After 24 h of overexpression, cells were lysed, and protein extracts were analyzed (A) by Western blot, as previously described in Methods. (B) The relative band intensities of both mature (black bars) and precursor (grey bars) LDLR forms were calculated, respectively, as the ratio of 160 kDa or 120 kDa LDLR band intensity to that of α-tubulin. (C) Black bars—LDLR expression; Dark grey bars—LDL(FITC)-LDLR binding after 3 h incubation at 4 °C; Light grey bars—LDL(FITC) internalization after 3 h incubation at 37 °C. Geometric fluorescence intensity of 15,000 events was acquired in a Facscalibur Flow cytometer, as mentioned above. All values represent the mean of triplicate independent determinations (n = 3); error bars represent ± SD. * p < 0.001 compared to LDLR WT using a two-tailed Student’s t-test.', metadata={'source': '..\\\\PMC8467959\\\\chunks\\\\12.FIG.txt', 'start_index': 0, 'id': 'bae4f0d0270d6e1f09dbfe0ff2859842'}),\n",
       " Document(page_content='## Figure. 2\\n Relative luciferase activity of LDLR_pGL4 constructs with c.1A>T, p.(Met1Leu) or c.1A>C, p.(Met1Leu) variants. CHO-ldlA7 cells were transiently co-transfected with each one of the LDLR_pGL4 constructs (containing Firefly Luciferase—FLuc) and with the pRL-TK plasmid encoding the Renilla Luciferase (RLuc). Cells were lysed 24 h later, and the luciferase activity was measured by luminometry assays. FLuc activity values were normalized to RLuc activity to control for transfection efficiency. Relative luciferase activity of the LDLR_pGL4-WT (WT) construct was defined as one. All values represent the mean of triplicate independent determinations (n = 3); error bars represent ± SD. * p < 0.001 compared to LDLR WT using a two-tailed Student’s t-test.', metadata={'source': '..\\\\PMC8467959\\\\chunks\\\\12.FIG.txt', 'start_index': 972, 'id': '845081397edc1c8e5715078f77b335ce'}),\n",
       " Document(page_content='# TABLE\\n\\n## Table. 1\\n In silico results obtained by the different bioinformatics tools.\\n\\n| Variant | PROVEAN | SIFT | Polyphen-2 | Mutation Tester 2 | REVEL |\\n|--|--|--|--|--|--|\\n| c.1A>T, p.(Met1Leu) | Neutral | Damaging | Benign | disease causing | 0.638 |\\n| c.1A>C, p.(Met1Leu) | Neutral | Damaging | Benign | disease causing | 0.638 |\\n\\n\\n## Table. 2\\n ACMG/AMP classification with and without the functional data.\\n\\n| Variant | ACMG Classification without FS | Points without FS | ACMG Classification after FS * |\\n|--|--|--|--|\\n| c.1A>T, p.(Met1Leu) | VUS | PM2, PVS1_Moderate and PP4 | Likely pathogenic |\\n| c.1A>C, p.(Met1Leu) | Likely pathogenic | PM2, PVS1_Moderate PP1_Moderate, PP4, PS4_Supporting | Pathogenic |\\n\\n\\n FS—Functional study; VUS—variant of uncertain significance; * Classification with additional PS3 point.\\n\\n## Table. 3\\n Carriers of variant c.1A>C, p.(Met1Leu) found in the Portuguese FH Study.', metadata={'source': '..\\\\PMC8467959\\\\chunks\\\\13.TABLE.txt', 'start_index': 0, 'id': '586f29f0f634687f08e2c0f0d95899fd'}),\n",
       " Document(page_content='FS—Functional study; VUS—variant of uncertain significance; * Classification with additional PS3 point.\\n\\n## Table. 3\\n Carriers of variant c.1A>C, p.(Met1Leu) found in the Portuguese FH Study.\\n\\n| Family | Age at Referral | Sex | Total-C * [mg/dL] | LDL-C * [mg/dL] | HDL-C * [mg/dL] | TG * [mg/dL] | BMI (Kg/m | LLT |\\n|--|--|--|--|--|--|--|--|--|\\n| 1—Index | 22 | F | 439 | 297 | 115 | 135 | NK | No |\\n| 2—Index | 38 | M | 288 | 222 | 48 | 90 | NK | No |\\n| 2 | 9 | F | 174 | 108 | 52 | 53 | NK | No |\\n| 3—Index | 2 | M | 281 | 226 | 47 | 93 | 16.8 | No |\\n| 3 | 3 | M | 284 | 220 | 51 | 95 | NK | No |\\n| 3 | 32 | F | 491 | 392 | 77 | 110 | NK | No |\\n| 4—Index | 12 | M | 257 | 174 | 68 | 32 | 22.6 | Atorvastatin |\\n| 4 | 41 | F | 227 | 149 | 63 | 50 | NK | Atorvastatin |\\n\\n\\n * Values at referral for a genetic test. TG—triglycerides; BMI—body mass index; LLT—lipid-lowering therapy; NK—not known.', metadata={'source': '..\\\\PMC8467959\\\\chunks\\\\13.TABLE.txt', 'start_index': 723, 'id': 'f7133a6aa3ab701fd4717ef3784b312f'}),\n",
       " Document(page_content='# INTRO\\n\\n 1. Introduction', metadata={'source': '..\\\\PMC8467959\\\\chunks\\\\2.INTRO.txt', 'start_index': 0, 'id': 'e2fe612e7b3a9a281c7320f568dc06e8'}),\n",
       " Document(page_content='Familial hypercholesterolemia (FH) (OMIM 143890) is an autosomal disorder of lipid metabolism characterized by increased plasma cholesterol levels and lipid accumulation in arteries and tendons, promoting premature atherosclerosis and coronary heart disease (CHD). FH is one of the most common genetic disorders with a frequency of around 1:250 in most populations, according to a recent meta-analysis. The FH phenotype can be caused by pathogenic variants in the three FH-associated genes (APOB, LDLR, and PCSK9) or by pathogenic variants in several phenocopies or alternative molecular etiologies (ABCG5/8, APOE, LDLRAP1, and LIPA), or it can even be due to a polygenic cause. Although the underlying genetics of the FH phenotype is complex, more than 90% of FH cases result from LDLR defects associated with an autosomal dominant inheritance pattern. Up to date, there are more than 2300 LDLR variants exclusively identified in FH patients. Another key feature of FH genetics is the phenotypic', metadata={'source': '..\\\\PMC8467959\\\\chunks\\\\2.INTRO.txt', 'start_index': 28, 'id': 'f4aef05d5f826814d42369109a128d8d'}),\n",
       " Document(page_content='with an autosomal dominant inheritance pattern. Up to date, there are more than 2300 LDLR variants exclusively identified in FH patients. Another key feature of FH genetics is the phenotypic variability; there is a diversity of phenotypes between groups sorted by causative gene and mutation type, and it is not uncommon to observe a wide range of lipid levels among carriers of an identical FH-causing mutation. Moreover, the mutation type and the percentage of activity of LDLR variants can modulate the patients’ phenotype and response to lipid therapy. LDLR variants can be primarily divided into null variants and defective variants, with complete or partial loss of function, respectively. Several studies showed an association between higher levels of LDL cholesterol and null variants compared with defective variants. Additionally, the type of mutation can modulate response to statin therapy, as shown in Brazilian and Spanish cohorts, where null variants were associated with the lowest', metadata={'source': '..\\\\PMC8467959\\\\chunks\\\\2.INTRO.txt', 'start_index': 834, 'id': '5c8b1c8c60ce133614ee525a3ec3cfe8'}),\n",
       " Document(page_content='with defective variants. Additionally, the type of mutation can modulate response to statin therapy, as shown in Brazilian and Spanish cohorts, where null variants were associated with the lowest decrease of LDL levels upon treatment. LDLR mutations can be functionally classified into five groups: class I—no protein synthesis (null variants); class II—partial or complete retention of the protein at the endoplasmic reticulum; class III—defective binding; class IV—defective internalization or endocytosis; class V—defective recycling. Although the functional characterization is important for a correct patient diagnosis and management, less than 10% of all variants described in the LDLR gene have been functionally characterized. To improve diagnosis and patient management, here, we report two different missense variants (c.1A>T, p.(Met1Leu) and c.1A>C, p.(Met1Leu)) in the LDLR initiation codon, exhibiting distinct functional phenotypes.', metadata={'source': '..\\\\PMC8467959\\\\chunks\\\\2.INTRO.txt', 'start_index': 1636, 'id': '85a03eaa43f3d949b9a772506d2eb46f'}),\n",
       " Document(page_content='# METHODS\\n\\n 2. Materials and Methods\\n\\n 2.1. Clinical Study\\n\\n The Portuguese FH Study is a research project continuously running since 1999 with the aim of identifying the genetic cause of hypercholesterolemia in individuals with a clinical diagnosis of FH. The study protocol and database have been approved by the National Institute of Health Ethics Committee and the National Data Protection Commission, respectively. Written informed consent was obtained from all participants before their inclusion in the study. Fasting blood samples were collected from all individuals at the time of their inclusion in the study. The biochemical characterization of lipids and lipoproteins was performed in a Cobas Integra 400 plus (Roche, Risch-Rotkreuz, Switzerland) by enzymatic colorimetric and immunoturbidimetric methods. All healthy individuals from whom the LDL used in the experiments was extracted followed the same exact procedure as any participant of the Portuguese FH Study.', metadata={'source': '..\\\\PMC8467959\\\\chunks\\\\3.METHODS.txt', 'start_index': 0, 'id': '892b9ca4ade79dccac4eb419c381958c'}),\n",
       " Document(page_content='2.2. Plasmid Constructs\\n\\n For Western blot and cytometry assays, the two missense variants under study, NM_000527.5:c.1A>T and NM_000527.5:c.1A>C, were individually introduced into the human LDLR cDNA (NM_000527.5) in the mammalian expression vector pcDNA3 under control of an SV40 promoter and enhancer. For luminometry assays, the promoter and the 5′ untranslated region (5′UTR) of LDLR (−319 bp upstream from ATG) were cloned upstream the Firefly Luciferase (FLuc) coding region in the pGL4.10 reporter plasmid (Promega, Madison, WI, USA), obtaining the LDLR_pGL4-WT construct. Both plasmids were subjected to oligonucleotide site-directed mutagenesis using the NZYMutagenesis kit (NZYTech, Lisbon, Portugal), according to the manufacturer’s instructions. For every variant, the presence of the correct variant and the integrity of the region was confirmed by direct Sanger sequencing.\\n\\n 2.3. Cell Culture and Transfection', metadata={'source': '..\\\\PMC8467959\\\\chunks\\\\3.METHODS.txt', 'start_index': 981, 'id': '73c86f71682de603de0e37635777d6ec'}),\n",
       " Document(page_content='2.3. Cell Culture and Transfection\\n\\n LDLR-deficient CHO-ldlA7 cells (Chinese hamster ovary cell line ldlA7), kindly provided by Dr. Monty Krieger, Massachusetts Institute of Technology, Cambridge, MA, were cultured in F-12 Nut Mix medium supplemented with 10% (v/v) fetal bovine serum (FBS, Invitrogen, Waltham, MA, USA), 100 units/mL penicillin, and 100 μg/mL streptomycin, and cells were grown at 37 °C in a humidified incubator containing 5% CO2.\\n\\n For Western blot and cytometry assays, cells were seeded in 6- or 24-well culture plates at 80% confluence (48 h) and were transfected with plasmids containing wild-type or mutant LDLR variants using Lipofectamine 2000 Transfection reagent (Invitrogen, Waltham, MA, USA) following manufacturer’s instructions. LDLR expression and LDL binding and internalization were assessed 24 h after transfection.', metadata={'source': '..\\\\PMC8467959\\\\chunks\\\\3.METHODS.txt', 'start_index': 1872, 'id': 'c2537edf74cc925f5f1d7c75639f4a85'}),\n",
       " Document(page_content='For luminometry assays, transient transfections were performed using Lipofectamine 2000 Transfection Reagent (Invitrogen, Waltham, MA, USA) following the manufacturer’s instructions in 35-mm plates. Cells were co-transfected with 750 ng of the test DNA construct corresponding to the LDLR_pGL4-WT or its derivative plasmids and 500 ng of the pRL-TK plasmid (Promega, Madison, WI, USA), which encodes Renilla luciferase (RLuc) as an internal control, and then harvested after 24 h.\\n\\n 2.4. Western Blot Analysis', metadata={'source': '..\\\\PMC8467959\\\\chunks\\\\3.METHODS.txt', 'start_index': 2727, 'id': '8482058e938461e53ff7c4702d0f475d'}),\n",
       " Document(page_content='Protein expression was determined for whole-cell extracts and fractionated by electrophoresis using NuPAGE™ 4%–12% Bis-Tris gel (Invitrogen, Waltham, MA, USA) and NuPAGE™ MOPS SDS Running Buffer (Invitrogen, Waltham, MA, USA) for semi-quantitative immunoblotting. PVDF membranes were immunostained overnight at 4 °C with a specific rabbit polyclonal antibody to the human LDL receptor (Progen Biotechnik, Heidelberg, Germany) and a monoclonal anti-α-tubulin antibody (Boster Biological Technology, Pleasanton, CA, USA) for protein loading control. After incubation with appropriate secondary antibodies, proteins were detected by chemiluminescence using Pierce™ ECL Plus Western Blotting Substrate (Thermo Scientific, Waltham, MA, USA) on a ChemiDoc (BioRad, Hercules, CA, USA). Relative band intensities of mature (≈160 kDa) and precursor (≈120 kDa) forms of LDLR protein were quantified by densitometric analysis using Image Lab Software (BioRad, Hercules, CA, USA) and normalized to levels of', metadata={'source': '..\\\\PMC8467959\\\\chunks\\\\3.METHODS.txt', 'start_index': 3239, 'id': '4111af2aac898677f563a5a92eb47443'}),\n",
       " Document(page_content='of mature (≈160 kDa) and precursor (≈120 kDa) forms of LDLR protein were quantified by densitometric analysis using Image Lab Software (BioRad, Hercules, CA, USA) and normalized to levels of α-tubulin.', metadata={'source': '..\\\\PMC8467959\\\\chunks\\\\3.METHODS.txt', 'start_index': 4044, 'id': '2ffcc706b61ef48b2e22a735ec923700'}),\n",
       " Document(page_content='2.5. LDL Isolation and Labeling\\n\\n Plasma used for lipoprotein purification was collected from healthy individuals’ blood after 30 min centrifugation at 2465× g at room temperature (5810R, Eppendorf, Hamburg, Germany). For all samples, plasma density was adjusted to 1.21 g/mL with potassium bromide (KBr), and PBS buffer was added to obtain a clear separation between lipid fractions. LDL was isolated through ultracentrifugation carried out in a TST 41–14 rotor at 225,000× g for 19 h at 4 °C (Centrikon T-21X0, Kronton, Munich, Germany). The intermediate orange band corresponding to LDL was collected and stored at 4 °C.', metadata={'source': '..\\\\PMC8467959\\\\chunks\\\\3.METHODS.txt', 'start_index': 4248, 'id': '98784d70c5c0795d62cb0e24a6aa3da1'}),\n",
       " Document(page_content='LDL was fluorescently labeled with fluorescein isothiocyanate (FITC). LDL was loaded in a 0.1 M NaHCO3 (pH 9.0) pre-equilibrated Sephadex G-25 column and then mixed under constant agitation with 10 μL FITC (2 mg/mL in DMSO) per lipoprotein milliliter at room temperature for 2 h. After incubation, free FITC was removed by gel filtration on a Sephadex G-25 column equilibrated with PBS EDTA-free buffer. Lipoprotein quantification was determined by the Pierce BCA protein assay.\\n\\n 2.6. LDLR Expression and Activity (Lipoprotein Binding and Internalization) by FACS', metadata={'source': '..\\\\PMC8467959\\\\chunks\\\\3.METHODS.txt', 'start_index': 4874, 'id': '481336201e72f615e51bc1a27f819b48'}),\n",
       " Document(page_content='2.6. LDLR Expression and Activity (Lipoprotein Binding and Internalization) by FACS\\n\\n LDLR cell surface expression was measured by FACS using mouse anti-human-LDLR (1:100; Progen Biotechnik, Heidelberg, Germany) as primary antibody and Alexa Fluor 488-conjugated goat anti-mouse IgG (1:200; Molecular Probes, Eugene, OR, USA) as the secondary antibody. Briefly, cells were incubated at 4 °C, overnight with the primary antibody after fixing (10 min in 4% paraformaldehyde) and blocking (1 h with PBS-5% FBS) steps. Next, cells were incubated for 1 h at room temperature with the secondary antibody. For each sample, the fluorescence of 15,000 events was acquired for data analysis, and measurements were performed in triplicate. All washes were done with PBS-1% BSA.', metadata={'source': '..\\\\PMC8467959\\\\chunks\\\\3.METHODS.txt', 'start_index': 5355, 'id': 'd635e1f465dd257aa303c70676fbd008'}),\n",
       " Document(page_content='For quantification of LDLR activity, cells were seeded in 24-well culture plates and transfected, as previously described. Briefly, 24 h after transfection, cells were incubated for 3 h at 37 °C or 4 °C with 20 μg/mL FITC-LDL to determine LDL internalization or LDL-LDLR binding, respectively. After incubation, cells were washed three times, fixed for 10 min in 4% paraformaldehyde, and washed again three times. The amount of internalized LDL was determined by adding Trypan blue solution to a 0.2% final concentration (Sigma-Aldrich, Steinheim, Germany) to the samples. This dye quenches external fluorescence, eliminating the signal of non-internalized LDLR-LDL complexes, allowing the determination of the intensity of the remaining fluorescent particles inside the cells. Fluorescence intensities were measured by flow cytometry in a Facscalibur Flow cytometer. For each sample, the fluorescence of 15,000 events was acquired for data analysis, and measurements were performed in triplicate.', metadata={'source': '..\\\\PMC8467959\\\\chunks\\\\3.METHODS.txt', 'start_index': 6124, 'id': 'a872d402fd076700687e454d0b828dbc'}),\n",
       " Document(page_content='were measured by flow cytometry in a Facscalibur Flow cytometer. For each sample, the fluorescence of 15,000 events was acquired for data analysis, and measurements were performed in triplicate. All washes were done with PBS-1% BSA.', metadata={'source': '..\\\\PMC8467959\\\\chunks\\\\3.METHODS.txt', 'start_index': 6927, 'id': '9eba1974bcb39842f41d40507d812594'}),\n",
       " Document(page_content='2.7. Luminometry Assay \\n\\n Cell lysis was performed with Passive Lysis Buffer (Promega). The cell lysates were used to determine relative FLuc and RLuc activities using the Dual-Luciferase® Reporter Assay System (Promega), according to the manufacturer’s instructions, on a GloMax® 96 Microplate Luminometer (Promega). The collected data was expressed in arbitrary light units. Luciferase activity was obtained by normalizing FLuc to RLuc luminescence for each sample, and each value was derived from three independent experiments.\\n\\n 2.8. American College of Medical Genetics (ACMG) Classification and In Silico Analysis\\n\\n Both variants were classified according to the Clinical Genome resource FH variant curation expert panel specifications for the ACMG/AMP Variant Interpretation Guidelines. Additionally, the potential effects of the two variants were evaluated by 5 software tools: PROVEAN, SIFT, PolyPhen2, MutationTaster, and REVEL.\\n\\n 2.9. Statistical Analysis', metadata={'source': '..\\\\PMC8467959\\\\chunks\\\\3.METHODS.txt', 'start_index': 7162, 'id': 'c3f812636bda1080bdf61a940cd12f6e'}),\n",
       " Document(page_content='2.9. Statistical Analysis\\n\\n Results are expressed as mean ± standard deviation. The Student’s t-test was used for the estimation of statistical significance. Significance for statistical analysis was defined as a p < 0.001.', metadata={'source': '..\\\\PMC8467959\\\\chunks\\\\3.METHODS.txt', 'start_index': 8103, 'id': 'e9f5bdad9767b525f296746a559b430a'}),\n",
       " Document(page_content='# RESULTS\\n\\n 3. Results\\n\\n 3.1. In Silico and ACMG Classification\\n\\n The bioinformatics prediction for the pathogenicity of the two variants displays conflicting classification between the different software but not among themselves (Table 1).\\n\\n Initially, variants c.1A>T, p.(Met1Leu), and c.1A>C, p.(Met1Leu) were classified as VUS (variant of uncertain significance) and Likely Pathogenic, respectively. Once the functional data were integrated into the algorithm, the classification has improved to Likely Pathogenic and Pathogenic (Table 2).\\n\\n 3.2. Functional Profiling of Variants c.1A>T and c.1A>C', metadata={'source': '..\\\\PMC8467959\\\\chunks\\\\4.RESULTS.txt', 'start_index': 0, 'id': 'ff6441ed1d9d444c5306fb680bc625ac'}),\n",
       " Document(page_content='3.2. Functional Profiling of Variants c.1A>T and c.1A>C\\n\\n Aiming to understand the functional consequences of both variants, protein levels from each variant were analyzed by Western blot (Figure 1A), and relative levels of LDLR expression were determined by quantitative densitometry, using α-tubulin protein expression as an internal control (Figure 1B). This analysis revealed different mature and precursor LDLR expression levels between the two variants (Figure 1A). LDLR variant c.1A>T produces almost no protein, showing a similar protein profile to the mock control. Whereas in LDLR variant c.1A>C, both mature and precursor forms of LDLR were detected, being the expression lower compared to the wild-type (WT) receptor (Figure 1B).', metadata={'source': '..\\\\PMC8467959\\\\chunks\\\\4.RESULTS.txt', 'start_index': 546, 'id': '47776753d02821366870ce5688ea550e'}),\n",
       " Document(page_content='To quantify the expression and activity of both LDLR variants, CHO-ldlA7 cells were transiently transfected with WT LDLR, c.1A>T, p.(Met1Leu), or c.1A>C, p.(Met1Leu) constructs to determine the ability of the receptor to bind and internalize labeled LDL. Results for cell surface LDLR expression, LDL (FITC)-LDLR binding, and internalization are illustrated in Figure 1C. WT transfection was used for normalization of results, and it represents 100% of expression and activity. Both variants exhibit expression and activity levels below 70% of the WT LDLR; therefore, they are considered to affect LDLR function. Cut-offs for this limit were used from Chora et al. (2021). The two variants exhibit cell surface expression lower than WT LDLR, and consequently, binding and internalization levels are also diminished. Variant c.1A>T shows expression and activity levels below 10%, whereas variant c.1A>C has expression and activity levels around 60%.', metadata={'source': '..\\\\PMC8467959\\\\chunks\\\\4.RESULTS.txt', 'start_index': 1290, 'id': '502c237a1471a91095577a345232f881'}),\n",
       " Document(page_content='Additionally, luminometry assays were performed to check the effect of the two variants in protein synthesis (Figure 2). Relative luciferase activity of constructs pGL4-c.1A>T and pGL4-c.1A>C is 0.5% and 5% of the normal control, respectively. Thus, both c.1A>T and c.1A>C LDLR variants repress protein expression of the downstream reporter gene, although with different intensities.\\n\\n 3.3. Phenotype of Patients with Variant c.1A>C, p(Met1Leu)\\n\\n Only the variant c.1A>C is identified in the Portuguese FH Study in four different families exhibiting an autosomal dominant inheritance pattern. A total of eight individuals carries this variant—four index cases and four relatives (Table 3). The eight carriers present untreated values of total and LDL cholesterol (LDL-C) ranging from 288 to 491 mg/dL and from 222 to 392 mg/dL, respectively, in adults. In children, total cholesterol and LDL-C range from 174 to 284 mg/dL and from 108 to 226 mg/dL, respectively.', metadata={'source': '..\\\\PMC8467959\\\\chunks\\\\4.RESULTS.txt', 'start_index': 2241, 'id': '53d66c4c3e4d92de12d9e1b26e6fdd52'}),\n",
       " Document(page_content='# DISCUSS\\n\\n 4. Discussion', metadata={'source': '..\\\\PMC8467959\\\\chunks\\\\5.DISCUSS.txt', 'start_index': 0, 'id': '59dc8af6723814956a7f68a577bab262'}),\n",
       " Document(page_content='Both LDLR variants (c.1A>T and c.1A>C) are predicted to change Methionine (AUG) to Leucine [UUG or CUG, respectively; p.(Met1Leu)]. Here, we investigated the functional consequences of these two LDLR variants. Our data show that both variants are able to mediate translation initiation, although the expression of variant c.1A>T is very low. Translation has been traditionally considered to initiate at the universal AUG start codon. However, due to the advent of the ribosome profiling technique, it is now clear that many non-AUG codons can function as non-canonical start codons. Accordingly, here we show that the UUG and CUG Leucine codons are able to function as translation initiation codons for the LDLR protein. Our data also show that these two Leucine codons mediate translation initiation with different efficiencies, being the UUG codon a much less efficient initiator. Indeed, these results are in accordance with what has been described, showing that, in eukaryotes, the substitution', metadata={'source': '..\\\\PMC8467959\\\\chunks\\\\5.DISCUSS.txt', 'start_index': 28, 'id': '8b8aad64703e8524002e77857a2627ed'}),\n",
       " Document(page_content='with different efficiencies, being the UUG codon a much less efficient initiator. Indeed, these results are in accordance with what has been described, showing that, in eukaryotes, the substitution of the initiating codon CUG for an alternate Leucine-encoding UUG codon drastically reduces protein expression. Moreover, the CUG codon is the most prevalent non-AUG start codon found in upstream open reading frames. Although the key eukaryotic initiation factor (eIF), eIF2, does not significantly bind other tRNAs besides Met-tRNAiMet, it is known that other eIFs can substitute eIF2 for initiation at non-AUG codons. eIF2A, for instance, can deliver Leu-tRNACUG and even Met-tRNAiMet to initiate translation at non-AUG start codons in a GTP-independent manner. Accordingly, depletion of eIF2A does not significantly impair global protein synthesis, neither affects translation initiation at AUGs, but has a negative impact on initiation at CUG or UUG codons. These pieces of evidence well support', metadata={'source': '..\\\\PMC8467959\\\\chunks\\\\5.DISCUSS.txt', 'start_index': 829, 'id': '7481c75c8d432ff23260aec2a5f94323'}),\n",
       " Document(page_content='not significantly impair global protein synthesis, neither affects translation initiation at AUGs, but has a negative impact on initiation at CUG or UUG codons. These pieces of evidence well support the contrasting in vitro phenotypes observed between the two variants regarding LDLR expression. As shown, the construct with the variant c.1A>T has residual LDLR expression and consequently very low LDL binding and internalization abilities. Nonetheless, the construct with the variant c.1A>C partially expresses LDLR, and the binding and internalization activities are coherently affected. Moreover, our results from the FLuc-based reporter constructs also support these data. However, the expression of these constructs is significantly lower than the one from the constructs with the LDLR open reading frame (ORF) (5% versus 60% and 0.5% versus 10% for c.1A>C and c.1A>T, respectively; Figure 1C and Figure 2). One possible explanation for this discrepancy could be the existence of RNA secondary', metadata={'source': '..\\\\PMC8467959\\\\chunks\\\\5.DISCUSS.txt', 'start_index': 1628, 'id': '9edc2a7b840b7f6a834a5a2f0a730c8d'}),\n",
       " Document(page_content='frame (ORF) (5% versus 60% and 0.5% versus 10% for c.1A>C and c.1A>T, respectively; Figure 1C and Figure 2). One possible explanation for this discrepancy could be the existence of RNA secondary structures downstream the start codons that could favor recognition of the non-canonical, UUG and CUG, codons on the pcDNA3 constructs (LDLR ORF) when compared to the pGL4 constructs (Luciferase ORF). This idea is supported by previous reports showing that recognition of non-canonical codons by the scanning ribosomes is favored by GC-rich downstream regions that potentiate the formation of hairpin-like structures. These secondary structures are thought to slow down the ribosomal scanning process, giving time for translation initiation to occur on sub-optimal codons. Accordingly, the mRNA secondary structure obtained from mFOLD (; accessed on 7 February 2021) using the first 100 nucleotides of the LDLR coding sequence is more stable than the one corresponding to the first 100 nucleotides of the', metadata={'source': '..\\\\PMC8467959\\\\chunks\\\\5.DISCUSS.txt', 'start_index': 2433, 'id': '5199628b250ceaf301497738ee9717e3'}),\n",
       " Document(page_content='structure obtained from mFOLD (; accessed on 7 February 2021) using the first 100 nucleotides of the LDLR coding sequence is more stable than the one corresponding to the first 100 nucleotides of the Luciferase ORF.', metadata={'source': '..\\\\PMC8467959\\\\chunks\\\\5.DISCUSS.txt', 'start_index': 3233, 'id': 'c89653a769daddf92ec5d39d6691eae3'}),\n",
       " Document(page_content='Considering the functional data gathered on the two variants, variant c.1A>T is classified as an LDLR class I mutation, with no protein synthesis (null variant), whereas variant c.1A>C phenotype is similar to LDLR class II mutations, with partial retention of the immature protein at the endoplasmic reticulum. These distinct phenotypes, a null and a defective allele type variant, highlight the importance of functionally characterizing and classifying LDLR variants. Carriers of a null allele variant present higher LDL values and higher rates of premature CHD than a defective allele carrier. As such, functional characterization is important for cardiovascular risk stratification. Considering our in vitro results, a distinctive severity of FH phenotype in carriers of these variants is expected, with carriers of the variant c.1A>C exhibiting a milder phenotype compared to c.1A>T carriers.', metadata={'source': '..\\\\PMC8467959\\\\chunks\\\\5.DISCUSS.txt', 'start_index': 3451, 'id': 'af3b0a3c121a1ec0cd8c8572eb4786cd'}),\n",
       " Document(page_content='According to ACMG/AMP guidelines for the classification of genetic variants, c.1A>T and c.1A>C are classified, respectively, as likely pathogenic and pathogenic variants, taking into consideration the functional study results. However, functionally, they have different performances, as described above. ACMG classification classifies a variant as likely pathogenic or pathogenic or likely benign or benign but does not characterize the level to which the variant affects the protein, which can be determined only with functional studies.', metadata={'source': '..\\\\PMC8467959\\\\chunks\\\\5.DISCUSS.txt', 'start_index': 4350, 'id': 'e73732c20cfd896e86084731adb976f4'}),\n",
       " Document(page_content='Whereas the variant c.1A>T was first described in 1996 in a compound heterozygous (CH) patient from South Africa, variant c.1A>C was first identified in 2001 in a heterozygous patient from Spain (no lipid information provided). As expected for an FH homozygous or compound heterozygous individual, the CH patient carrying the variant c.1A>T exhibits extremely high levels of total and LDL cholesterol (LDL-C), 719 mg/dL and 669 mg/dL, respectively. Additionally, the variant c.1A>T is also identified in two first degree relatives of the CH patient with ages of 36 and 18 years old, presenting values of total and LDL-C of 363 mg/dL and 305 mg/dL and 305 mg/dL and 232 mg/dL, respectively. Unfortunately, no data on lipid-lowering treatment is provided for any of these individuals. To date, only the variant c.1A>C is identified in the Portuguese FH Study in four different families exhibiting an autosomal dominant inheritance pattern. As reported in the results, the eight carriers present a', metadata={'source': '..\\\\PMC8467959\\\\chunks\\\\5.DISCUSS.txt', 'start_index': 4891, 'id': '58e64ed6aeedaadd81241d9edde192c9'}),\n",
       " Document(page_content='the variant c.1A>C is identified in the Portuguese FH Study in four different families exhibiting an autosomal dominant inheritance pattern. As reported in the results, the eight carriers present a wide range of untreated values of total and LDL-C, showing the already mentioned heterogeneity in phenotypes presented by carriers of the same variant. There are several cholesterol modulators from age, body mass index, diet, physical exercise, and co-occurrence of other disorders and treatments that can account for this phenotypical heterogeneity. In this case, since the variants under study are in the LDLR translation initiation codon and originate a non-canonical initiator, we can speculate that some factors involved in non-canonical translation initiation may also be modulating it with different efficiencies among patients, leading to distinct phenotypes.', metadata={'source': '..\\\\PMC8467959\\\\chunks\\\\5.DISCUSS.txt', 'start_index': 5688, 'id': '3cbc08757657022c2a46f459af1bea55'}),\n",
       " Document(page_content='It is known that the type of mutation can modulate the response to statin therapy, where null variants have the lowest decrease of LDL levels upon treatment. In adults, the lowest observed values of total and LDL-C (227 mg/dL and 149 mg/dL) correspond to an individual undergoing statin therapy, who before treatment had 400 mg/dL of total cholesterol (LDL-C values before treatment not known). The child of this individual also undergoing statin therapy shows a reduction of 23% and 30% of total and LDL-C, i.e., from 335 mg/dL and 250 mg/dL to 257 mg/dL and 174 mg/dL, respectively. This good response to treatment goes to the encounter of our results, to the extent that considering the mechanism of action of statins, theoretically, carriers of putative null variants should not greatly benefit from this therapy. However, from carriers of a variant with partial activity, such as c.1A>C, a good response to statin treatment is expected, as observed in these individuals. Both c.1A>C and c.1A>T', metadata={'source': '..\\\\PMC8467959\\\\chunks\\\\5.DISCUSS.txt', 'start_index': 6556, 'id': '6526add3c0e2e304e8ed709425cd9ffc'}),\n",
       " Document(page_content='from this therapy. However, from carriers of a variant with partial activity, such as c.1A>C, a good response to statin treatment is expected, as observed in these individuals. Both c.1A>C and c.1A>T variants exert their pathogenicity by means of low expression of LDLR; the second one is close to null expression. Although the expression is reduced, the activity of the synthesized receptors is normal, and so they play their role in the clearance of LDL from circulation. This way, the effect of statin therapy, which blocks cholesterol biosynthesis and promotes the hepatic expression of LDLR, should have a more beneficial impact on carriers of variant c.1A>C compared to c.1A>T carriers.', metadata={'source': '..\\\\PMC8467959\\\\chunks\\\\5.DISCUSS.txt', 'start_index': 7355, 'id': '12762faef598a2068027946054322dbe'}),\n",
       " Document(page_content='# CONCL\\n\\n 5. Conclusions', metadata={'source': '..\\\\PMC8467959\\\\chunks\\\\6.CONCL.txt', 'start_index': 0, 'id': '7d00995b2cae59c18c2ab9e2f350479b'}),\n",
       " Document(page_content='In conclusion, we have characterized 2 different LDLR missense variants in the translation initiation codon, which codify for the same amino acid p.(Met1Leu) but have a distinct impact on LDLR expression and activity. The two variants exhibit different functional behaviors: cytometry and luciferase assays show that variant c.1A>T/p.(Met1Leu) acts like a null variant with extremely low levels of protein expression and consequent null activity; conversely, variant c.1A>C/p.(Met1Leu) is able to initiate translation with a higher efficiency, which renders a significant LDLR activity to this variant. Our data gives new functional insight into these two variants, leading to an improved ACMG classification, which can be used in the choice of the lipid-lowering treatment and dyslipidemia management for a more personalized approach, which, in the end, can lead to a better patient prognosis. With this work, we have also contributed with evidence to the function of non-canonical initiation', metadata={'source': '..\\\\PMC8467959\\\\chunks\\\\6.CONCL.txt', 'start_index': 27, 'id': 'c25030234922ed23ac5babf13f1ffe5f'}),\n",
       " Document(page_content='for a more personalized approach, which, in the end, can lead to a better patient prognosis. With this work, we have also contributed with evidence to the function of non-canonical initiation codons in translation initiation. However, additional experiments are required to fully unveil the underlying mechanism through which mRNA translation initiation is affected.', metadata={'source': '..\\\\PMC8467959\\\\chunks\\\\6.CONCL.txt', 'start_index': 829, 'id': 'b51c0bb85bcf3e832b6509af1abd75cc'}),\n",
       " Document(page_content='Publisher’s Note: MDPI stays neutral with regard to jurisdictional claims in published maps and institutional affiliations.', metadata={'source': '..\\\\PMC8467959\\\\chunks\\\\6.CONCL.txt', 'start_index': 1198, 'id': '12d2b862b46b14d53b1988546385a209'}),\n",
       " Document(page_content='# AUTH_CONT\\n\\n Author Contributions\\n\\n Conceptualization, L.R. and M.B.; methodology, R.G., R.F., A.C.A. and J.M.; validation, A.C.A. and J.M.; formal analysis, R.G. and R.F.; writing—original draft preparation, R.G. and R.F.; writing—review and editing, R.G., L.R. and M.B., supervision, L.R. and M.B. All authors have read and agreed to the published version of the manuscript.', metadata={'source': '..\\\\PMC8467959\\\\chunks\\\\7.AUTH_CONT.txt', 'start_index': 0, 'id': '72359e77a4c251f9340d32de7c5c8a82'}),\n",
       " Document(page_content='# ACK_FUND\\n\\n Funding\\n\\n This research received no external funding.\\n\\n Institutional Review Board Statement\\n\\n The study was conducted according to the guidelines of the Declaration of Helsinki, and the Portuguese FH Study was approved by the National Institute of Health Ethics Committee and the National Data Protection Commission on 21 September 2009, protocol code 3962/2009.\\n\\n Informed Consent Statement\\n\\n Informed consent was obtained from all subjects involved in the study.', metadata={'source': '..\\\\PMC8467959\\\\chunks\\\\8.ACK_FUND.txt', 'start_index': 0, 'id': '6f489a2f3867b6c2348fcc6e482ddd7f'}),\n",
       " Document(page_content='# SUPPL\\n\\n Data Availability Statement\\n\\n The data that support the findings of this study are available from the corresponding author upon reasonable request.', metadata={'source': '..\\\\PMC8467959\\\\chunks\\\\9.SUPPL.txt', 'start_index': 0, 'id': '2a3ab7fafa2b3809c9dc62b7311823b8'})]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompts\n",
      " [ChatPromptTemplate(input_variables=['input'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='# Knowledge Graph Instructions for GPT-4\\n## 1. Overview\\nYou are a top-tier algorithm designed for extracting information in structured formats to build a knowledge graph.\\nTry to capture as much information from the text as possible without sacrifing accuracy. Do not add any information that is not explicitly mentioned in the text\\n- **Nodes** represent entities and concepts.\\n- The aim is to achieve simplicity and clarity in the knowledge graph, making it\\naccessible for a vast audience.\\n## 2. Labeling Nodes\\n- **Consistency**: Ensure you use available types for node labels.\\nEnsure you use basic or elementary types for node labels.\\n- For example, when you identify an entity representing a person, always label it as **\\'person\\'**. Avoid using more specific terms like \\'mathematician\\' or \\'scientist\\'  - **Node IDs**: Never utilize integers as node IDs. Node IDs should be names or human-readable identifiers found in the text.\\n- **Relationships** represent connections between entities or concepts.\\nEnsure consistency and generality in relationship types when constructing knowledge graphs. Instead of using specific and momentary types such as \\'BECAME_PROFESSOR\\', use more general and timeless relationship types like \\'PROFESSOR\\'. Make sure to use general and timeless relationship types!\\n## 3. Coreference Resolution\\n- **Maintain Entity Consistency**: When extracting entities, it\\'s vital to ensure consistency.\\nIf an entity, such as \"John Doe\", is mentioned multiple times in the text but is referred to by different names or pronouns (e.g., \"Joe\", \"he\"),always use the most complete identifier for that entity throughout the knowledge graph. In this example, use \"John Doe\" as the entity ID.\\nRemember, the knowledge graph should be coherent and easily understandable, so maintaining consistency in entity references is crucial.\\n## 4. Strict Compliance\\nAdhere to the rules strictly. Non-compliance will result in termination.')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='Tip: Make sure to answer in the correct format and do not include any explanations. Use the given format to extract information from the following input: {input}'))])]\n",
      "\n",
      "Prompts\n",
      " <class 'pydantic.v1.main.PromptInput'>\n",
      "\n",
      "Prompts\n",
      " <class 'pydantic.v1.main.RunnableAssignOutput'>\n",
      "\n",
      "Prompts\n",
      " [ChatPromptTemplate(input_variables=['input'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='# Knowledge Graph Instructions for GPT-4\\n## 1. Overview\\nYou are a top-tier algorithm designed for extracting information in structured formats to build a knowledge graph.\\nTry to capture as much information from the text as possible without sacrifing accuracy. Do not add any information that is not explicitly mentioned in the text\\n- **Nodes** represent entities and concepts.\\n- The aim is to achieve simplicity and clarity in the knowledge graph, making it\\naccessible for a vast audience.\\n## 2. Labeling Nodes\\n- **Consistency**: Ensure you use available types for node labels.\\nEnsure you use basic or elementary types for node labels.\\n- For example, when you identify an entity representing a person, always label it as **\\'person\\'**. Avoid using more specific terms like \\'mathematician\\' or \\'scientist\\'  - **Node IDs**: Never utilize integers as node IDs. Node IDs should be names or human-readable identifiers found in the text.\\n- **Relationships** represent connections between entities or concepts.\\nEnsure consistency and generality in relationship types when constructing knowledge graphs. Instead of using specific and momentary types such as \\'BECAME_PROFESSOR\\', use more general and timeless relationship types like \\'PROFESSOR\\'. Make sure to use general and timeless relationship types!\\n## 3. Coreference Resolution\\n- **Maintain Entity Consistency**: When extracting entities, it\\'s vital to ensure consistency.\\nIf an entity, such as \"John Doe\", is mentioned multiple times in the text but is referred to by different names or pronouns (e.g., \"Joe\", \"he\"),always use the most complete identifier for that entity throughout the knowledge graph. In this example, use \"John Doe\" as the entity ID.\\nRemember, the knowledge graph should be coherent and easily understandable, so maintaining consistency in entity references is crucial.\\n## 4. Strict Compliance\\nAdhere to the rules strictly. Non-compliance will result in termination.')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='Tip: Make sure to answer in the correct format and do not include any explanations. Use the given format to extract information from the following input: {input}'))])]\n",
      "\n",
      "Prompts\n",
      " <class 'pydantic.v1.main.PromptInput'>\n",
      "\n",
      "Prompts\n",
      " <class 'pydantic.v1.main.RunnableAssignOutput'>\n",
      "\n",
      "Prompts\n",
      " [ChatPromptTemplate(input_variables=['input'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='# Knowledge Graph Instructions for GPT-4\\n## 1. Overview\\nYou are a top-tier algorithm designed for extracting information in structured formats to build a knowledge graph.\\nTry to capture as much information from the text as possible without sacrifing accuracy. Do not add any information that is not explicitly mentioned in the text\\n- **Nodes** represent entities and concepts.\\n- The aim is to achieve simplicity and clarity in the knowledge graph, making it\\naccessible for a vast audience.\\n## 2. Labeling Nodes\\n- **Consistency**: Ensure you use available types for node labels.\\nEnsure you use basic or elementary types for node labels.\\n- For example, when you identify an entity representing a person, always label it as **\\'person\\'**. Avoid using more specific terms like \\'mathematician\\' or \\'scientist\\'  - **Node IDs**: Never utilize integers as node IDs. Node IDs should be names or human-readable identifiers found in the text.\\n- **Relationships** represent connections between entities or concepts.\\nEnsure consistency and generality in relationship types when constructing knowledge graphs. Instead of using specific and momentary types such as \\'BECAME_PROFESSOR\\', use more general and timeless relationship types like \\'PROFESSOR\\'. Make sure to use general and timeless relationship types!\\n## 3. Coreference Resolution\\n- **Maintain Entity Consistency**: When extracting entities, it\\'s vital to ensure consistency.\\nIf an entity, such as \"John Doe\", is mentioned multiple times in the text but is referred to by different names or pronouns (e.g., \"Joe\", \"he\"),always use the most complete identifier for that entity throughout the knowledge graph. In this example, use \"John Doe\" as the entity ID.\\nRemember, the knowledge graph should be coherent and easily understandable, so maintaining consistency in entity references is crucial.\\n## 4. Strict Compliance\\nAdhere to the rules strictly. Non-compliance will result in termination.')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='Tip: Make sure to answer in the correct format and do not include any explanations. Use the given format to extract information from the following input: {input}'))])]\n",
      "\n",
      "Prompts\n",
      " <class 'pydantic.v1.main.PromptInput'>\n",
      "\n",
      "Prompts\n",
      " <class 'pydantic.v1.main.RunnableAssignOutput'>\n",
      "\n",
      "Prompts\n",
      " [ChatPromptTemplate(input_variables=['input'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='# Knowledge Graph Instructions for GPT-4\\n## 1. Overview\\nYou are a top-tier algorithm designed for extracting information in structured formats to build a knowledge graph.\\nTry to capture as much information from the text as possible without sacrifing accuracy. Do not add any information that is not explicitly mentioned in the text\\n- **Nodes** represent entities and concepts.\\n- The aim is to achieve simplicity and clarity in the knowledge graph, making it\\naccessible for a vast audience.\\n## 2. Labeling Nodes\\n- **Consistency**: Ensure you use available types for node labels.\\nEnsure you use basic or elementary types for node labels.\\n- For example, when you identify an entity representing a person, always label it as **\\'person\\'**. Avoid using more specific terms like \\'mathematician\\' or \\'scientist\\'  - **Node IDs**: Never utilize integers as node IDs. Node IDs should be names or human-readable identifiers found in the text.\\n- **Relationships** represent connections between entities or concepts.\\nEnsure consistency and generality in relationship types when constructing knowledge graphs. Instead of using specific and momentary types such as \\'BECAME_PROFESSOR\\', use more general and timeless relationship types like \\'PROFESSOR\\'. Make sure to use general and timeless relationship types!\\n## 3. Coreference Resolution\\n- **Maintain Entity Consistency**: When extracting entities, it\\'s vital to ensure consistency.\\nIf an entity, such as \"John Doe\", is mentioned multiple times in the text but is referred to by different names or pronouns (e.g., \"Joe\", \"he\"),always use the most complete identifier for that entity throughout the knowledge graph. In this example, use \"John Doe\" as the entity ID.\\nRemember, the knowledge graph should be coherent and easily understandable, so maintaining consistency in entity references is crucial.\\n## 4. Strict Compliance\\nAdhere to the rules strictly. Non-compliance will result in termination.')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='Tip: Make sure to answer in the correct format and do not include any explanations. Use the given format to extract information from the following input: {input}'))])]\n",
      "\n",
      "Prompts\n",
      " <class 'pydantic.v1.main.PromptInput'>\n",
      "\n",
      "Prompts\n",
      " <class 'pydantic.v1.main.RunnableAssignOutput'>\n",
      "\n",
      "Prompts\n",
      " [ChatPromptTemplate(input_variables=['input'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='# Knowledge Graph Instructions for GPT-4\\n## 1. Overview\\nYou are a top-tier algorithm designed for extracting information in structured formats to build a knowledge graph.\\nTry to capture as much information from the text as possible without sacrifing accuracy. Do not add any information that is not explicitly mentioned in the text\\n- **Nodes** represent entities and concepts.\\n- The aim is to achieve simplicity and clarity in the knowledge graph, making it\\naccessible for a vast audience.\\n## 2. Labeling Nodes\\n- **Consistency**: Ensure you use available types for node labels.\\nEnsure you use basic or elementary types for node labels.\\n- For example, when you identify an entity representing a person, always label it as **\\'person\\'**. Avoid using more specific terms like \\'mathematician\\' or \\'scientist\\'  - **Node IDs**: Never utilize integers as node IDs. Node IDs should be names or human-readable identifiers found in the text.\\n- **Relationships** represent connections between entities or concepts.\\nEnsure consistency and generality in relationship types when constructing knowledge graphs. Instead of using specific and momentary types such as \\'BECAME_PROFESSOR\\', use more general and timeless relationship types like \\'PROFESSOR\\'. Make sure to use general and timeless relationship types!\\n## 3. Coreference Resolution\\n- **Maintain Entity Consistency**: When extracting entities, it\\'s vital to ensure consistency.\\nIf an entity, such as \"John Doe\", is mentioned multiple times in the text but is referred to by different names or pronouns (e.g., \"Joe\", \"he\"),always use the most complete identifier for that entity throughout the knowledge graph. In this example, use \"John Doe\" as the entity ID.\\nRemember, the knowledge graph should be coherent and easily understandable, so maintaining consistency in entity references is crucial.\\n## 4. Strict Compliance\\nAdhere to the rules strictly. Non-compliance will result in termination.')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='Tip: Make sure to answer in the correct format and do not include any explanations. Use the given format to extract information from the following input: {input}'))])]\n",
      "\n",
      "Prompts\n",
      " <class 'pydantic.v1.main.PromptInput'>\n",
      "\n",
      "Prompts\n",
      " <class 'pydantic.v1.main.RunnableAssignOutput'>\n",
      "\n",
      "Prompts\n",
      " [ChatPromptTemplate(input_variables=['input'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='# Knowledge Graph Instructions for GPT-4\\n## 1. Overview\\nYou are a top-tier algorithm designed for extracting information in structured formats to build a knowledge graph.\\nTry to capture as much information from the text as possible without sacrifing accuracy. Do not add any information that is not explicitly mentioned in the text\\n- **Nodes** represent entities and concepts.\\n- The aim is to achieve simplicity and clarity in the knowledge graph, making it\\naccessible for a vast audience.\\n## 2. Labeling Nodes\\n- **Consistency**: Ensure you use available types for node labels.\\nEnsure you use basic or elementary types for node labels.\\n- For example, when you identify an entity representing a person, always label it as **\\'person\\'**. Avoid using more specific terms like \\'mathematician\\' or \\'scientist\\'  - **Node IDs**: Never utilize integers as node IDs. Node IDs should be names or human-readable identifiers found in the text.\\n- **Relationships** represent connections between entities or concepts.\\nEnsure consistency and generality in relationship types when constructing knowledge graphs. Instead of using specific and momentary types such as \\'BECAME_PROFESSOR\\', use more general and timeless relationship types like \\'PROFESSOR\\'. Make sure to use general and timeless relationship types!\\n## 3. Coreference Resolution\\n- **Maintain Entity Consistency**: When extracting entities, it\\'s vital to ensure consistency.\\nIf an entity, such as \"John Doe\", is mentioned multiple times in the text but is referred to by different names or pronouns (e.g., \"Joe\", \"he\"),always use the most complete identifier for that entity throughout the knowledge graph. In this example, use \"John Doe\" as the entity ID.\\nRemember, the knowledge graph should be coherent and easily understandable, so maintaining consistency in entity references is crucial.\\n## 4. Strict Compliance\\nAdhere to the rules strictly. Non-compliance will result in termination.')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='Tip: Make sure to answer in the correct format and do not include any explanations. Use the given format to extract information from the following input: {input}'))])]\n",
      "\n",
      "Prompts\n",
      " <class 'pydantic.v1.main.PromptInput'>\n",
      "\n",
      "Prompts\n",
      " <class 'pydantic.v1.main.RunnableAssignOutput'>\n",
      "\n",
      "Prompts\n",
      " [ChatPromptTemplate(input_variables=['input'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='# Knowledge Graph Instructions for GPT-4\\n## 1. Overview\\nYou are a top-tier algorithm designed for extracting information in structured formats to build a knowledge graph.\\nTry to capture as much information from the text as possible without sacrifing accuracy. Do not add any information that is not explicitly mentioned in the text\\n- **Nodes** represent entities and concepts.\\n- The aim is to achieve simplicity and clarity in the knowledge graph, making it\\naccessible for a vast audience.\\n## 2. Labeling Nodes\\n- **Consistency**: Ensure you use available types for node labels.\\nEnsure you use basic or elementary types for node labels.\\n- For example, when you identify an entity representing a person, always label it as **\\'person\\'**. Avoid using more specific terms like \\'mathematician\\' or \\'scientist\\'  - **Node IDs**: Never utilize integers as node IDs. Node IDs should be names or human-readable identifiers found in the text.\\n- **Relationships** represent connections between entities or concepts.\\nEnsure consistency and generality in relationship types when constructing knowledge graphs. Instead of using specific and momentary types such as \\'BECAME_PROFESSOR\\', use more general and timeless relationship types like \\'PROFESSOR\\'. Make sure to use general and timeless relationship types!\\n## 3. Coreference Resolution\\n- **Maintain Entity Consistency**: When extracting entities, it\\'s vital to ensure consistency.\\nIf an entity, such as \"John Doe\", is mentioned multiple times in the text but is referred to by different names or pronouns (e.g., \"Joe\", \"he\"),always use the most complete identifier for that entity throughout the knowledge graph. In this example, use \"John Doe\" as the entity ID.\\nRemember, the knowledge graph should be coherent and easily understandable, so maintaining consistency in entity references is crucial.\\n## 4. Strict Compliance\\nAdhere to the rules strictly. Non-compliance will result in termination.')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='Tip: Make sure to answer in the correct format and do not include any explanations. Use the given format to extract information from the following input: {input}'))])]\n",
      "\n",
      "Prompts\n",
      " <class 'pydantic.v1.main.PromptInput'>\n",
      "\n",
      "Prompts\n",
      " <class 'pydantic.v1.main.RunnableAssignOutput'>\n",
      "\n",
      "Prompts\n",
      " [ChatPromptTemplate(input_variables=['input'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='# Knowledge Graph Instructions for GPT-4\\n## 1. Overview\\nYou are a top-tier algorithm designed for extracting information in structured formats to build a knowledge graph.\\nTry to capture as much information from the text as possible without sacrifing accuracy. Do not add any information that is not explicitly mentioned in the text\\n- **Nodes** represent entities and concepts.\\n- The aim is to achieve simplicity and clarity in the knowledge graph, making it\\naccessible for a vast audience.\\n## 2. Labeling Nodes\\n- **Consistency**: Ensure you use available types for node labels.\\nEnsure you use basic or elementary types for node labels.\\n- For example, when you identify an entity representing a person, always label it as **\\'person\\'**. Avoid using more specific terms like \\'mathematician\\' or \\'scientist\\'  - **Node IDs**: Never utilize integers as node IDs. Node IDs should be names or human-readable identifiers found in the text.\\n- **Relationships** represent connections between entities or concepts.\\nEnsure consistency and generality in relationship types when constructing knowledge graphs. Instead of using specific and momentary types such as \\'BECAME_PROFESSOR\\', use more general and timeless relationship types like \\'PROFESSOR\\'. Make sure to use general and timeless relationship types!\\n## 3. Coreference Resolution\\n- **Maintain Entity Consistency**: When extracting entities, it\\'s vital to ensure consistency.\\nIf an entity, such as \"John Doe\", is mentioned multiple times in the text but is referred to by different names or pronouns (e.g., \"Joe\", \"he\"),always use the most complete identifier for that entity throughout the knowledge graph. In this example, use \"John Doe\" as the entity ID.\\nRemember, the knowledge graph should be coherent and easily understandable, so maintaining consistency in entity references is crucial.\\n## 4. Strict Compliance\\nAdhere to the rules strictly. Non-compliance will result in termination.')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='Tip: Make sure to answer in the correct format and do not include any explanations. Use the given format to extract information from the following input: {input}'))])]\n",
      "\n",
      "Prompts\n",
      " <class 'pydantic.v1.main.PromptInput'>\n",
      "\n",
      "Prompts\n",
      " <class 'pydantic.v1.main.RunnableAssignOutput'>\n",
      "\n",
      "Prompts\n",
      " [ChatPromptTemplate(input_variables=['input'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='# Knowledge Graph Instructions for GPT-4\\n## 1. Overview\\nYou are a top-tier algorithm designed for extracting information in structured formats to build a knowledge graph.\\nTry to capture as much information from the text as possible without sacrifing accuracy. Do not add any information that is not explicitly mentioned in the text\\n- **Nodes** represent entities and concepts.\\n- The aim is to achieve simplicity and clarity in the knowledge graph, making it\\naccessible for a vast audience.\\n## 2. Labeling Nodes\\n- **Consistency**: Ensure you use available types for node labels.\\nEnsure you use basic or elementary types for node labels.\\n- For example, when you identify an entity representing a person, always label it as **\\'person\\'**. Avoid using more specific terms like \\'mathematician\\' or \\'scientist\\'  - **Node IDs**: Never utilize integers as node IDs. Node IDs should be names or human-readable identifiers found in the text.\\n- **Relationships** represent connections between entities or concepts.\\nEnsure consistency and generality in relationship types when constructing knowledge graphs. Instead of using specific and momentary types such as \\'BECAME_PROFESSOR\\', use more general and timeless relationship types like \\'PROFESSOR\\'. Make sure to use general and timeless relationship types!\\n## 3. Coreference Resolution\\n- **Maintain Entity Consistency**: When extracting entities, it\\'s vital to ensure consistency.\\nIf an entity, such as \"John Doe\", is mentioned multiple times in the text but is referred to by different names or pronouns (e.g., \"Joe\", \"he\"),always use the most complete identifier for that entity throughout the knowledge graph. In this example, use \"John Doe\" as the entity ID.\\nRemember, the knowledge graph should be coherent and easily understandable, so maintaining consistency in entity references is crucial.\\n## 4. Strict Compliance\\nAdhere to the rules strictly. Non-compliance will result in termination.')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='Tip: Make sure to answer in the correct format and do not include any explanations. Use the given format to extract information from the following input: {input}'))])]\n",
      "\n",
      "Prompts\n",
      " <class 'pydantic.v1.main.PromptInput'>\n",
      "\n",
      "Prompts\n",
      " <class 'pydantic.v1.main.RunnableAssignOutput'>\n",
      "\n",
      "Prompts\n",
      " [ChatPromptTemplate(input_variables=['input'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='# Knowledge Graph Instructions for GPT-4\\n## 1. Overview\\nYou are a top-tier algorithm designed for extracting information in structured formats to build a knowledge graph.\\nTry to capture as much information from the text as possible without sacrifing accuracy. Do not add any information that is not explicitly mentioned in the text\\n- **Nodes** represent entities and concepts.\\n- The aim is to achieve simplicity and clarity in the knowledge graph, making it\\naccessible for a vast audience.\\n## 2. Labeling Nodes\\n- **Consistency**: Ensure you use available types for node labels.\\nEnsure you use basic or elementary types for node labels.\\n- For example, when you identify an entity representing a person, always label it as **\\'person\\'**. Avoid using more specific terms like \\'mathematician\\' or \\'scientist\\'  - **Node IDs**: Never utilize integers as node IDs. Node IDs should be names or human-readable identifiers found in the text.\\n- **Relationships** represent connections between entities or concepts.\\nEnsure consistency and generality in relationship types when constructing knowledge graphs. Instead of using specific and momentary types such as \\'BECAME_PROFESSOR\\', use more general and timeless relationship types like \\'PROFESSOR\\'. Make sure to use general and timeless relationship types!\\n## 3. Coreference Resolution\\n- **Maintain Entity Consistency**: When extracting entities, it\\'s vital to ensure consistency.\\nIf an entity, such as \"John Doe\", is mentioned multiple times in the text but is referred to by different names or pronouns (e.g., \"Joe\", \"he\"),always use the most complete identifier for that entity throughout the knowledge graph. In this example, use \"John Doe\" as the entity ID.\\nRemember, the knowledge graph should be coherent and easily understandable, so maintaining consistency in entity references is crucial.\\n## 4. Strict Compliance\\nAdhere to the rules strictly. Non-compliance will result in termination.')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='Tip: Make sure to answer in the correct format and do not include any explanations. Use the given format to extract information from the following input: {input}'))])]\n",
      "\n",
      "Prompts\n",
      " <class 'pydantic.v1.main.PromptInput'>\n",
      "\n",
      "Prompts\n",
      " <class 'pydantic.v1.main.RunnableAssignOutput'>\n",
      "\n",
      "Prompts\n",
      " [ChatPromptTemplate(input_variables=['input'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='# Knowledge Graph Instructions for GPT-4\\n## 1. Overview\\nYou are a top-tier algorithm designed for extracting information in structured formats to build a knowledge graph.\\nTry to capture as much information from the text as possible without sacrifing accuracy. Do not add any information that is not explicitly mentioned in the text\\n- **Nodes** represent entities and concepts.\\n- The aim is to achieve simplicity and clarity in the knowledge graph, making it\\naccessible for a vast audience.\\n## 2. Labeling Nodes\\n- **Consistency**: Ensure you use available types for node labels.\\nEnsure you use basic or elementary types for node labels.\\n- For example, when you identify an entity representing a person, always label it as **\\'person\\'**. Avoid using more specific terms like \\'mathematician\\' or \\'scientist\\'  - **Node IDs**: Never utilize integers as node IDs. Node IDs should be names or human-readable identifiers found in the text.\\n- **Relationships** represent connections between entities or concepts.\\nEnsure consistency and generality in relationship types when constructing knowledge graphs. Instead of using specific and momentary types such as \\'BECAME_PROFESSOR\\', use more general and timeless relationship types like \\'PROFESSOR\\'. Make sure to use general and timeless relationship types!\\n## 3. Coreference Resolution\\n- **Maintain Entity Consistency**: When extracting entities, it\\'s vital to ensure consistency.\\nIf an entity, such as \"John Doe\", is mentioned multiple times in the text but is referred to by different names or pronouns (e.g., \"Joe\", \"he\"),always use the most complete identifier for that entity throughout the knowledge graph. In this example, use \"John Doe\" as the entity ID.\\nRemember, the knowledge graph should be coherent and easily understandable, so maintaining consistency in entity references is crucial.\\n## 4. Strict Compliance\\nAdhere to the rules strictly. Non-compliance will result in termination.')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='Tip: Make sure to answer in the correct format and do not include any explanations. Use the given format to extract information from the following input: {input}'))])]\n",
      "\n",
      "Prompts\n",
      " <class 'pydantic.v1.main.PromptInput'>\n",
      "\n",
      "Prompts\n",
      " <class 'pydantic.v1.main.RunnableAssignOutput'>\n",
      "\n",
      "Prompts\n",
      " [ChatPromptTemplate(input_variables=['input'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='# Knowledge Graph Instructions for GPT-4\\n## 1. Overview\\nYou are a top-tier algorithm designed for extracting information in structured formats to build a knowledge graph.\\nTry to capture as much information from the text as possible without sacrifing accuracy. Do not add any information that is not explicitly mentioned in the text\\n- **Nodes** represent entities and concepts.\\n- The aim is to achieve simplicity and clarity in the knowledge graph, making it\\naccessible for a vast audience.\\n## 2. Labeling Nodes\\n- **Consistency**: Ensure you use available types for node labels.\\nEnsure you use basic or elementary types for node labels.\\n- For example, when you identify an entity representing a person, always label it as **\\'person\\'**. Avoid using more specific terms like \\'mathematician\\' or \\'scientist\\'  - **Node IDs**: Never utilize integers as node IDs. Node IDs should be names or human-readable identifiers found in the text.\\n- **Relationships** represent connections between entities or concepts.\\nEnsure consistency and generality in relationship types when constructing knowledge graphs. Instead of using specific and momentary types such as \\'BECAME_PROFESSOR\\', use more general and timeless relationship types like \\'PROFESSOR\\'. Make sure to use general and timeless relationship types!\\n## 3. Coreference Resolution\\n- **Maintain Entity Consistency**: When extracting entities, it\\'s vital to ensure consistency.\\nIf an entity, such as \"John Doe\", is mentioned multiple times in the text but is referred to by different names or pronouns (e.g., \"Joe\", \"he\"),always use the most complete identifier for that entity throughout the knowledge graph. In this example, use \"John Doe\" as the entity ID.\\nRemember, the knowledge graph should be coherent and easily understandable, so maintaining consistency in entity references is crucial.\\n## 4. Strict Compliance\\nAdhere to the rules strictly. Non-compliance will result in termination.')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='Tip: Make sure to answer in the correct format and do not include any explanations. Use the given format to extract information from the following input: {input}'))])]\n",
      "\n",
      "Prompts\n",
      " <class 'pydantic.v1.main.PromptInput'>\n",
      "\n",
      "Prompts\n",
      " <class 'pydantic.v1.main.RunnableAssignOutput'>\n",
      "\n",
      "Prompts\n",
      " [ChatPromptTemplate(input_variables=['input'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='# Knowledge Graph Instructions for GPT-4\\n## 1. Overview\\nYou are a top-tier algorithm designed for extracting information in structured formats to build a knowledge graph.\\nTry to capture as much information from the text as possible without sacrifing accuracy. Do not add any information that is not explicitly mentioned in the text\\n- **Nodes** represent entities and concepts.\\n- The aim is to achieve simplicity and clarity in the knowledge graph, making it\\naccessible for a vast audience.\\n## 2. Labeling Nodes\\n- **Consistency**: Ensure you use available types for node labels.\\nEnsure you use basic or elementary types for node labels.\\n- For example, when you identify an entity representing a person, always label it as **\\'person\\'**. Avoid using more specific terms like \\'mathematician\\' or \\'scientist\\'  - **Node IDs**: Never utilize integers as node IDs. Node IDs should be names or human-readable identifiers found in the text.\\n- **Relationships** represent connections between entities or concepts.\\nEnsure consistency and generality in relationship types when constructing knowledge graphs. Instead of using specific and momentary types such as \\'BECAME_PROFESSOR\\', use more general and timeless relationship types like \\'PROFESSOR\\'. Make sure to use general and timeless relationship types!\\n## 3. Coreference Resolution\\n- **Maintain Entity Consistency**: When extracting entities, it\\'s vital to ensure consistency.\\nIf an entity, such as \"John Doe\", is mentioned multiple times in the text but is referred to by different names or pronouns (e.g., \"Joe\", \"he\"),always use the most complete identifier for that entity throughout the knowledge graph. In this example, use \"John Doe\" as the entity ID.\\nRemember, the knowledge graph should be coherent and easily understandable, so maintaining consistency in entity references is crucial.\\n## 4. Strict Compliance\\nAdhere to the rules strictly. Non-compliance will result in termination.')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='Tip: Make sure to answer in the correct format and do not include any explanations. Use the given format to extract information from the following input: {input}'))])]\n",
      "\n",
      "Prompts\n",
      " <class 'pydantic.v1.main.PromptInput'>\n",
      "\n",
      "Prompts\n",
      " <class 'pydantic.v1.main.RunnableAssignOutput'>\n",
      "\n",
      "Prompts\n",
      " [ChatPromptTemplate(input_variables=['input'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='# Knowledge Graph Instructions for GPT-4\\n## 1. Overview\\nYou are a top-tier algorithm designed for extracting information in structured formats to build a knowledge graph.\\nTry to capture as much information from the text as possible without sacrifing accuracy. Do not add any information that is not explicitly mentioned in the text\\n- **Nodes** represent entities and concepts.\\n- The aim is to achieve simplicity and clarity in the knowledge graph, making it\\naccessible for a vast audience.\\n## 2. Labeling Nodes\\n- **Consistency**: Ensure you use available types for node labels.\\nEnsure you use basic or elementary types for node labels.\\n- For example, when you identify an entity representing a person, always label it as **\\'person\\'**. Avoid using more specific terms like \\'mathematician\\' or \\'scientist\\'  - **Node IDs**: Never utilize integers as node IDs. Node IDs should be names or human-readable identifiers found in the text.\\n- **Relationships** represent connections between entities or concepts.\\nEnsure consistency and generality in relationship types when constructing knowledge graphs. Instead of using specific and momentary types such as \\'BECAME_PROFESSOR\\', use more general and timeless relationship types like \\'PROFESSOR\\'. Make sure to use general and timeless relationship types!\\n## 3. Coreference Resolution\\n- **Maintain Entity Consistency**: When extracting entities, it\\'s vital to ensure consistency.\\nIf an entity, such as \"John Doe\", is mentioned multiple times in the text but is referred to by different names or pronouns (e.g., \"Joe\", \"he\"),always use the most complete identifier for that entity throughout the knowledge graph. In this example, use \"John Doe\" as the entity ID.\\nRemember, the knowledge graph should be coherent and easily understandable, so maintaining consistency in entity references is crucial.\\n## 4. Strict Compliance\\nAdhere to the rules strictly. Non-compliance will result in termination.')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='Tip: Make sure to answer in the correct format and do not include any explanations. Use the given format to extract information from the following input: {input}'))])]\n",
      "\n",
      "Prompts\n",
      " <class 'pydantic.v1.main.PromptInput'>\n",
      "\n",
      "Prompts\n",
      " <class 'pydantic.v1.main.RunnableAssignOutput'>\n",
      "\n",
      "Prompts\n",
      " [ChatPromptTemplate(input_variables=['input'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='# Knowledge Graph Instructions for GPT-4\\n## 1. Overview\\nYou are a top-tier algorithm designed for extracting information in structured formats to build a knowledge graph.\\nTry to capture as much information from the text as possible without sacrifing accuracy. Do not add any information that is not explicitly mentioned in the text\\n- **Nodes** represent entities and concepts.\\n- The aim is to achieve simplicity and clarity in the knowledge graph, making it\\naccessible for a vast audience.\\n## 2. Labeling Nodes\\n- **Consistency**: Ensure you use available types for node labels.\\nEnsure you use basic or elementary types for node labels.\\n- For example, when you identify an entity representing a person, always label it as **\\'person\\'**. Avoid using more specific terms like \\'mathematician\\' or \\'scientist\\'  - **Node IDs**: Never utilize integers as node IDs. Node IDs should be names or human-readable identifiers found in the text.\\n- **Relationships** represent connections between entities or concepts.\\nEnsure consistency and generality in relationship types when constructing knowledge graphs. Instead of using specific and momentary types such as \\'BECAME_PROFESSOR\\', use more general and timeless relationship types like \\'PROFESSOR\\'. Make sure to use general and timeless relationship types!\\n## 3. Coreference Resolution\\n- **Maintain Entity Consistency**: When extracting entities, it\\'s vital to ensure consistency.\\nIf an entity, such as \"John Doe\", is mentioned multiple times in the text but is referred to by different names or pronouns (e.g., \"Joe\", \"he\"),always use the most complete identifier for that entity throughout the knowledge graph. In this example, use \"John Doe\" as the entity ID.\\nRemember, the knowledge graph should be coherent and easily understandable, so maintaining consistency in entity references is crucial.\\n## 4. Strict Compliance\\nAdhere to the rules strictly. Non-compliance will result in termination.')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='Tip: Make sure to answer in the correct format and do not include any explanations. Use the given format to extract information from the following input: {input}'))])]\n",
      "\n",
      "Prompts\n",
      " <class 'pydantic.v1.main.PromptInput'>\n",
      "\n",
      "Prompts\n",
      " <class 'pydantic.v1.main.RunnableAssignOutput'>\n",
      "\n",
      "Prompts\n",
      " [ChatPromptTemplate(input_variables=['input'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='# Knowledge Graph Instructions for GPT-4\\n## 1. Overview\\nYou are a top-tier algorithm designed for extracting information in structured formats to build a knowledge graph.\\nTry to capture as much information from the text as possible without sacrifing accuracy. Do not add any information that is not explicitly mentioned in the text\\n- **Nodes** represent entities and concepts.\\n- The aim is to achieve simplicity and clarity in the knowledge graph, making it\\naccessible for a vast audience.\\n## 2. Labeling Nodes\\n- **Consistency**: Ensure you use available types for node labels.\\nEnsure you use basic or elementary types for node labels.\\n- For example, when you identify an entity representing a person, always label it as **\\'person\\'**. Avoid using more specific terms like \\'mathematician\\' or \\'scientist\\'  - **Node IDs**: Never utilize integers as node IDs. Node IDs should be names or human-readable identifiers found in the text.\\n- **Relationships** represent connections between entities or concepts.\\nEnsure consistency and generality in relationship types when constructing knowledge graphs. Instead of using specific and momentary types such as \\'BECAME_PROFESSOR\\', use more general and timeless relationship types like \\'PROFESSOR\\'. Make sure to use general and timeless relationship types!\\n## 3. Coreference Resolution\\n- **Maintain Entity Consistency**: When extracting entities, it\\'s vital to ensure consistency.\\nIf an entity, such as \"John Doe\", is mentioned multiple times in the text but is referred to by different names or pronouns (e.g., \"Joe\", \"he\"),always use the most complete identifier for that entity throughout the knowledge graph. In this example, use \"John Doe\" as the entity ID.\\nRemember, the knowledge graph should be coherent and easily understandable, so maintaining consistency in entity references is crucial.\\n## 4. Strict Compliance\\nAdhere to the rules strictly. Non-compliance will result in termination.')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='Tip: Make sure to answer in the correct format and do not include any explanations. Use the given format to extract information from the following input: {input}'))])]\n",
      "\n",
      "Prompts\n",
      " <class 'pydantic.v1.main.PromptInput'>\n",
      "\n",
      "Prompts\n",
      " <class 'pydantic.v1.main.RunnableAssignOutput'>\n",
      "\n",
      "Prompts\n",
      " [ChatPromptTemplate(input_variables=['input'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='# Knowledge Graph Instructions for GPT-4\\n## 1. Overview\\nYou are a top-tier algorithm designed for extracting information in structured formats to build a knowledge graph.\\nTry to capture as much information from the text as possible without sacrifing accuracy. Do not add any information that is not explicitly mentioned in the text\\n- **Nodes** represent entities and concepts.\\n- The aim is to achieve simplicity and clarity in the knowledge graph, making it\\naccessible for a vast audience.\\n## 2. Labeling Nodes\\n- **Consistency**: Ensure you use available types for node labels.\\nEnsure you use basic or elementary types for node labels.\\n- For example, when you identify an entity representing a person, always label it as **\\'person\\'**. Avoid using more specific terms like \\'mathematician\\' or \\'scientist\\'  - **Node IDs**: Never utilize integers as node IDs. Node IDs should be names or human-readable identifiers found in the text.\\n- **Relationships** represent connections between entities or concepts.\\nEnsure consistency and generality in relationship types when constructing knowledge graphs. Instead of using specific and momentary types such as \\'BECAME_PROFESSOR\\', use more general and timeless relationship types like \\'PROFESSOR\\'. Make sure to use general and timeless relationship types!\\n## 3. Coreference Resolution\\n- **Maintain Entity Consistency**: When extracting entities, it\\'s vital to ensure consistency.\\nIf an entity, such as \"John Doe\", is mentioned multiple times in the text but is referred to by different names or pronouns (e.g., \"Joe\", \"he\"),always use the most complete identifier for that entity throughout the knowledge graph. In this example, use \"John Doe\" as the entity ID.\\nRemember, the knowledge graph should be coherent and easily understandable, so maintaining consistency in entity references is crucial.\\n## 4. Strict Compliance\\nAdhere to the rules strictly. Non-compliance will result in termination.')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='Tip: Make sure to answer in the correct format and do not include any explanations. Use the given format to extract information from the following input: {input}'))])]\n",
      "\n",
      "Prompts\n",
      " <class 'pydantic.v1.main.PromptInput'>\n",
      "\n",
      "Prompts\n",
      " <class 'pydantic.v1.main.RunnableAssignOutput'>\n",
      "\n",
      "Prompts\n",
      " [ChatPromptTemplate(input_variables=['input'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='# Knowledge Graph Instructions for GPT-4\\n## 1. Overview\\nYou are a top-tier algorithm designed for extracting information in structured formats to build a knowledge graph.\\nTry to capture as much information from the text as possible without sacrifing accuracy. Do not add any information that is not explicitly mentioned in the text\\n- **Nodes** represent entities and concepts.\\n- The aim is to achieve simplicity and clarity in the knowledge graph, making it\\naccessible for a vast audience.\\n## 2. Labeling Nodes\\n- **Consistency**: Ensure you use available types for node labels.\\nEnsure you use basic or elementary types for node labels.\\n- For example, when you identify an entity representing a person, always label it as **\\'person\\'**. Avoid using more specific terms like \\'mathematician\\' or \\'scientist\\'  - **Node IDs**: Never utilize integers as node IDs. Node IDs should be names or human-readable identifiers found in the text.\\n- **Relationships** represent connections between entities or concepts.\\nEnsure consistency and generality in relationship types when constructing knowledge graphs. Instead of using specific and momentary types such as \\'BECAME_PROFESSOR\\', use more general and timeless relationship types like \\'PROFESSOR\\'. Make sure to use general and timeless relationship types!\\n## 3. Coreference Resolution\\n- **Maintain Entity Consistency**: When extracting entities, it\\'s vital to ensure consistency.\\nIf an entity, such as \"John Doe\", is mentioned multiple times in the text but is referred to by different names or pronouns (e.g., \"Joe\", \"he\"),always use the most complete identifier for that entity throughout the knowledge graph. In this example, use \"John Doe\" as the entity ID.\\nRemember, the knowledge graph should be coherent and easily understandable, so maintaining consistency in entity references is crucial.\\n## 4. Strict Compliance\\nAdhere to the rules strictly. Non-compliance will result in termination.')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='Tip: Make sure to answer in the correct format and do not include any explanations. Use the given format to extract information from the following input: {input}'))])]\n",
      "\n",
      "Prompts\n",
      " <class 'pydantic.v1.main.PromptInput'>\n",
      "\n",
      "Prompts\n",
      " <class 'pydantic.v1.main.RunnableAssignOutput'>\n",
      "\n",
      "Prompts\n",
      " [ChatPromptTemplate(input_variables=['input'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='# Knowledge Graph Instructions for GPT-4\\n## 1. Overview\\nYou are a top-tier algorithm designed for extracting information in structured formats to build a knowledge graph.\\nTry to capture as much information from the text as possible without sacrifing accuracy. Do not add any information that is not explicitly mentioned in the text\\n- **Nodes** represent entities and concepts.\\n- The aim is to achieve simplicity and clarity in the knowledge graph, making it\\naccessible for a vast audience.\\n## 2. Labeling Nodes\\n- **Consistency**: Ensure you use available types for node labels.\\nEnsure you use basic or elementary types for node labels.\\n- For example, when you identify an entity representing a person, always label it as **\\'person\\'**. Avoid using more specific terms like \\'mathematician\\' or \\'scientist\\'  - **Node IDs**: Never utilize integers as node IDs. Node IDs should be names or human-readable identifiers found in the text.\\n- **Relationships** represent connections between entities or concepts.\\nEnsure consistency and generality in relationship types when constructing knowledge graphs. Instead of using specific and momentary types such as \\'BECAME_PROFESSOR\\', use more general and timeless relationship types like \\'PROFESSOR\\'. Make sure to use general and timeless relationship types!\\n## 3. Coreference Resolution\\n- **Maintain Entity Consistency**: When extracting entities, it\\'s vital to ensure consistency.\\nIf an entity, such as \"John Doe\", is mentioned multiple times in the text but is referred to by different names or pronouns (e.g., \"Joe\", \"he\"),always use the most complete identifier for that entity throughout the knowledge graph. In this example, use \"John Doe\" as the entity ID.\\nRemember, the knowledge graph should be coherent and easily understandable, so maintaining consistency in entity references is crucial.\\n## 4. Strict Compliance\\nAdhere to the rules strictly. Non-compliance will result in termination.')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='Tip: Make sure to answer in the correct format and do not include any explanations. Use the given format to extract information from the following input: {input}'))])]\n",
      "\n",
      "Prompts\n",
      " <class 'pydantic.v1.main.PromptInput'>\n",
      "\n",
      "Prompts\n",
      " <class 'pydantic.v1.main.RunnableAssignOutput'>\n",
      "\n",
      "Prompts\n",
      " [ChatPromptTemplate(input_variables=['input'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='# Knowledge Graph Instructions for GPT-4\\n## 1. Overview\\nYou are a top-tier algorithm designed for extracting information in structured formats to build a knowledge graph.\\nTry to capture as much information from the text as possible without sacrifing accuracy. Do not add any information that is not explicitly mentioned in the text\\n- **Nodes** represent entities and concepts.\\n- The aim is to achieve simplicity and clarity in the knowledge graph, making it\\naccessible for a vast audience.\\n## 2. Labeling Nodes\\n- **Consistency**: Ensure you use available types for node labels.\\nEnsure you use basic or elementary types for node labels.\\n- For example, when you identify an entity representing a person, always label it as **\\'person\\'**. Avoid using more specific terms like \\'mathematician\\' or \\'scientist\\'  - **Node IDs**: Never utilize integers as node IDs. Node IDs should be names or human-readable identifiers found in the text.\\n- **Relationships** represent connections between entities or concepts.\\nEnsure consistency and generality in relationship types when constructing knowledge graphs. Instead of using specific and momentary types such as \\'BECAME_PROFESSOR\\', use more general and timeless relationship types like \\'PROFESSOR\\'. Make sure to use general and timeless relationship types!\\n## 3. Coreference Resolution\\n- **Maintain Entity Consistency**: When extracting entities, it\\'s vital to ensure consistency.\\nIf an entity, such as \"John Doe\", is mentioned multiple times in the text but is referred to by different names or pronouns (e.g., \"Joe\", \"he\"),always use the most complete identifier for that entity throughout the knowledge graph. In this example, use \"John Doe\" as the entity ID.\\nRemember, the knowledge graph should be coherent and easily understandable, so maintaining consistency in entity references is crucial.\\n## 4. Strict Compliance\\nAdhere to the rules strictly. Non-compliance will result in termination.')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='Tip: Make sure to answer in the correct format and do not include any explanations. Use the given format to extract information from the following input: {input}'))])]\n",
      "\n",
      "Prompts\n",
      " <class 'pydantic.v1.main.PromptInput'>\n",
      "\n",
      "Prompts\n",
      " <class 'pydantic.v1.main.RunnableAssignOutput'>\n",
      "\n",
      "Prompts\n",
      " [ChatPromptTemplate(input_variables=['input'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='# Knowledge Graph Instructions for GPT-4\\n## 1. Overview\\nYou are a top-tier algorithm designed for extracting information in structured formats to build a knowledge graph.\\nTry to capture as much information from the text as possible without sacrifing accuracy. Do not add any information that is not explicitly mentioned in the text\\n- **Nodes** represent entities and concepts.\\n- The aim is to achieve simplicity and clarity in the knowledge graph, making it\\naccessible for a vast audience.\\n## 2. Labeling Nodes\\n- **Consistency**: Ensure you use available types for node labels.\\nEnsure you use basic or elementary types for node labels.\\n- For example, when you identify an entity representing a person, always label it as **\\'person\\'**. Avoid using more specific terms like \\'mathematician\\' or \\'scientist\\'  - **Node IDs**: Never utilize integers as node IDs. Node IDs should be names or human-readable identifiers found in the text.\\n- **Relationships** represent connections between entities or concepts.\\nEnsure consistency and generality in relationship types when constructing knowledge graphs. Instead of using specific and momentary types such as \\'BECAME_PROFESSOR\\', use more general and timeless relationship types like \\'PROFESSOR\\'. Make sure to use general and timeless relationship types!\\n## 3. Coreference Resolution\\n- **Maintain Entity Consistency**: When extracting entities, it\\'s vital to ensure consistency.\\nIf an entity, such as \"John Doe\", is mentioned multiple times in the text but is referred to by different names or pronouns (e.g., \"Joe\", \"he\"),always use the most complete identifier for that entity throughout the knowledge graph. In this example, use \"John Doe\" as the entity ID.\\nRemember, the knowledge graph should be coherent and easily understandable, so maintaining consistency in entity references is crucial.\\n## 4. Strict Compliance\\nAdhere to the rules strictly. Non-compliance will result in termination.')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='Tip: Make sure to answer in the correct format and do not include any explanations. Use the given format to extract information from the following input: {input}'))])]\n",
      "\n",
      "Prompts\n",
      " <class 'pydantic.v1.main.PromptInput'>\n",
      "\n",
      "Prompts\n",
      " <class 'pydantic.v1.main.RunnableAssignOutput'>\n",
      "\n",
      "Prompts\n",
      " [ChatPromptTemplate(input_variables=['input'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='# Knowledge Graph Instructions for GPT-4\\n## 1. Overview\\nYou are a top-tier algorithm designed for extracting information in structured formats to build a knowledge graph.\\nTry to capture as much information from the text as possible without sacrifing accuracy. Do not add any information that is not explicitly mentioned in the text\\n- **Nodes** represent entities and concepts.\\n- The aim is to achieve simplicity and clarity in the knowledge graph, making it\\naccessible for a vast audience.\\n## 2. Labeling Nodes\\n- **Consistency**: Ensure you use available types for node labels.\\nEnsure you use basic or elementary types for node labels.\\n- For example, when you identify an entity representing a person, always label it as **\\'person\\'**. Avoid using more specific terms like \\'mathematician\\' or \\'scientist\\'  - **Node IDs**: Never utilize integers as node IDs. Node IDs should be names or human-readable identifiers found in the text.\\n- **Relationships** represent connections between entities or concepts.\\nEnsure consistency and generality in relationship types when constructing knowledge graphs. Instead of using specific and momentary types such as \\'BECAME_PROFESSOR\\', use more general and timeless relationship types like \\'PROFESSOR\\'. Make sure to use general and timeless relationship types!\\n## 3. Coreference Resolution\\n- **Maintain Entity Consistency**: When extracting entities, it\\'s vital to ensure consistency.\\nIf an entity, such as \"John Doe\", is mentioned multiple times in the text but is referred to by different names or pronouns (e.g., \"Joe\", \"he\"),always use the most complete identifier for that entity throughout the knowledge graph. In this example, use \"John Doe\" as the entity ID.\\nRemember, the knowledge graph should be coherent and easily understandable, so maintaining consistency in entity references is crucial.\\n## 4. Strict Compliance\\nAdhere to the rules strictly. Non-compliance will result in termination.')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='Tip: Make sure to answer in the correct format and do not include any explanations. Use the given format to extract information from the following input: {input}'))])]\n",
      "\n",
      "Prompts\n",
      " <class 'pydantic.v1.main.PromptInput'>\n",
      "\n",
      "Prompts\n",
      " <class 'pydantic.v1.main.RunnableAssignOutput'>\n",
      "\n",
      "Prompts\n",
      " [ChatPromptTemplate(input_variables=['input'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='# Knowledge Graph Instructions for GPT-4\\n## 1. Overview\\nYou are a top-tier algorithm designed for extracting information in structured formats to build a knowledge graph.\\nTry to capture as much information from the text as possible without sacrifing accuracy. Do not add any information that is not explicitly mentioned in the text\\n- **Nodes** represent entities and concepts.\\n- The aim is to achieve simplicity and clarity in the knowledge graph, making it\\naccessible for a vast audience.\\n## 2. Labeling Nodes\\n- **Consistency**: Ensure you use available types for node labels.\\nEnsure you use basic or elementary types for node labels.\\n- For example, when you identify an entity representing a person, always label it as **\\'person\\'**. Avoid using more specific terms like \\'mathematician\\' or \\'scientist\\'  - **Node IDs**: Never utilize integers as node IDs. Node IDs should be names or human-readable identifiers found in the text.\\n- **Relationships** represent connections between entities or concepts.\\nEnsure consistency and generality in relationship types when constructing knowledge graphs. Instead of using specific and momentary types such as \\'BECAME_PROFESSOR\\', use more general and timeless relationship types like \\'PROFESSOR\\'. Make sure to use general and timeless relationship types!\\n## 3. Coreference Resolution\\n- **Maintain Entity Consistency**: When extracting entities, it\\'s vital to ensure consistency.\\nIf an entity, such as \"John Doe\", is mentioned multiple times in the text but is referred to by different names or pronouns (e.g., \"Joe\", \"he\"),always use the most complete identifier for that entity throughout the knowledge graph. In this example, use \"John Doe\" as the entity ID.\\nRemember, the knowledge graph should be coherent and easily understandable, so maintaining consistency in entity references is crucial.\\n## 4. Strict Compliance\\nAdhere to the rules strictly. Non-compliance will result in termination.')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='Tip: Make sure to answer in the correct format and do not include any explanations. Use the given format to extract information from the following input: {input}'))])]\n",
      "\n",
      "Prompts\n",
      " <class 'pydantic.v1.main.PromptInput'>\n",
      "\n",
      "Prompts\n",
      " <class 'pydantic.v1.main.RunnableAssignOutput'>\n",
      "\n",
      "Prompts\n",
      " [ChatPromptTemplate(input_variables=['input'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='# Knowledge Graph Instructions for GPT-4\\n## 1. Overview\\nYou are a top-tier algorithm designed for extracting information in structured formats to build a knowledge graph.\\nTry to capture as much information from the text as possible without sacrifing accuracy. Do not add any information that is not explicitly mentioned in the text\\n- **Nodes** represent entities and concepts.\\n- The aim is to achieve simplicity and clarity in the knowledge graph, making it\\naccessible for a vast audience.\\n## 2. Labeling Nodes\\n- **Consistency**: Ensure you use available types for node labels.\\nEnsure you use basic or elementary types for node labels.\\n- For example, when you identify an entity representing a person, always label it as **\\'person\\'**. Avoid using more specific terms like \\'mathematician\\' or \\'scientist\\'  - **Node IDs**: Never utilize integers as node IDs. Node IDs should be names or human-readable identifiers found in the text.\\n- **Relationships** represent connections between entities or concepts.\\nEnsure consistency and generality in relationship types when constructing knowledge graphs. Instead of using specific and momentary types such as \\'BECAME_PROFESSOR\\', use more general and timeless relationship types like \\'PROFESSOR\\'. Make sure to use general and timeless relationship types!\\n## 3. Coreference Resolution\\n- **Maintain Entity Consistency**: When extracting entities, it\\'s vital to ensure consistency.\\nIf an entity, such as \"John Doe\", is mentioned multiple times in the text but is referred to by different names or pronouns (e.g., \"Joe\", \"he\"),always use the most complete identifier for that entity throughout the knowledge graph. In this example, use \"John Doe\" as the entity ID.\\nRemember, the knowledge graph should be coherent and easily understandable, so maintaining consistency in entity references is crucial.\\n## 4. Strict Compliance\\nAdhere to the rules strictly. Non-compliance will result in termination.')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='Tip: Make sure to answer in the correct format and do not include any explanations. Use the given format to extract information from the following input: {input}'))])]\n",
      "\n",
      "Prompts\n",
      " <class 'pydantic.v1.main.PromptInput'>\n",
      "\n",
      "Prompts\n",
      " <class 'pydantic.v1.main.RunnableAssignOutput'>\n",
      "\n",
      "Prompts\n",
      " [ChatPromptTemplate(input_variables=['input'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='# Knowledge Graph Instructions for GPT-4\\n## 1. Overview\\nYou are a top-tier algorithm designed for extracting information in structured formats to build a knowledge graph.\\nTry to capture as much information from the text as possible without sacrifing accuracy. Do not add any information that is not explicitly mentioned in the text\\n- **Nodes** represent entities and concepts.\\n- The aim is to achieve simplicity and clarity in the knowledge graph, making it\\naccessible for a vast audience.\\n## 2. Labeling Nodes\\n- **Consistency**: Ensure you use available types for node labels.\\nEnsure you use basic or elementary types for node labels.\\n- For example, when you identify an entity representing a person, always label it as **\\'person\\'**. Avoid using more specific terms like \\'mathematician\\' or \\'scientist\\'  - **Node IDs**: Never utilize integers as node IDs. Node IDs should be names or human-readable identifiers found in the text.\\n- **Relationships** represent connections between entities or concepts.\\nEnsure consistency and generality in relationship types when constructing knowledge graphs. Instead of using specific and momentary types such as \\'BECAME_PROFESSOR\\', use more general and timeless relationship types like \\'PROFESSOR\\'. Make sure to use general and timeless relationship types!\\n## 3. Coreference Resolution\\n- **Maintain Entity Consistency**: When extracting entities, it\\'s vital to ensure consistency.\\nIf an entity, such as \"John Doe\", is mentioned multiple times in the text but is referred to by different names or pronouns (e.g., \"Joe\", \"he\"),always use the most complete identifier for that entity throughout the knowledge graph. In this example, use \"John Doe\" as the entity ID.\\nRemember, the knowledge graph should be coherent and easily understandable, so maintaining consistency in entity references is crucial.\\n## 4. Strict Compliance\\nAdhere to the rules strictly. Non-compliance will result in termination.')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='Tip: Make sure to answer in the correct format and do not include any explanations. Use the given format to extract information from the following input: {input}'))])]\n",
      "\n",
      "Prompts\n",
      " <class 'pydantic.v1.main.PromptInput'>\n",
      "\n",
      "Prompts\n",
      " <class 'pydantic.v1.main.RunnableAssignOutput'>\n",
      "\n",
      "Prompts\n",
      " [ChatPromptTemplate(input_variables=['input'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='# Knowledge Graph Instructions for GPT-4\\n## 1. Overview\\nYou are a top-tier algorithm designed for extracting information in structured formats to build a knowledge graph.\\nTry to capture as much information from the text as possible without sacrifing accuracy. Do not add any information that is not explicitly mentioned in the text\\n- **Nodes** represent entities and concepts.\\n- The aim is to achieve simplicity and clarity in the knowledge graph, making it\\naccessible for a vast audience.\\n## 2. Labeling Nodes\\n- **Consistency**: Ensure you use available types for node labels.\\nEnsure you use basic or elementary types for node labels.\\n- For example, when you identify an entity representing a person, always label it as **\\'person\\'**. Avoid using more specific terms like \\'mathematician\\' or \\'scientist\\'  - **Node IDs**: Never utilize integers as node IDs. Node IDs should be names or human-readable identifiers found in the text.\\n- **Relationships** represent connections between entities or concepts.\\nEnsure consistency and generality in relationship types when constructing knowledge graphs. Instead of using specific and momentary types such as \\'BECAME_PROFESSOR\\', use more general and timeless relationship types like \\'PROFESSOR\\'. Make sure to use general and timeless relationship types!\\n## 3. Coreference Resolution\\n- **Maintain Entity Consistency**: When extracting entities, it\\'s vital to ensure consistency.\\nIf an entity, such as \"John Doe\", is mentioned multiple times in the text but is referred to by different names or pronouns (e.g., \"Joe\", \"he\"),always use the most complete identifier for that entity throughout the knowledge graph. In this example, use \"John Doe\" as the entity ID.\\nRemember, the knowledge graph should be coherent and easily understandable, so maintaining consistency in entity references is crucial.\\n## 4. Strict Compliance\\nAdhere to the rules strictly. Non-compliance will result in termination.')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='Tip: Make sure to answer in the correct format and do not include any explanations. Use the given format to extract information from the following input: {input}'))])]\n",
      "\n",
      "Prompts\n",
      " <class 'pydantic.v1.main.PromptInput'>\n",
      "\n",
      "Prompts\n",
      " <class 'pydantic.v1.main.RunnableAssignOutput'>\n",
      "\n",
      "Prompts\n",
      " [ChatPromptTemplate(input_variables=['input'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='# Knowledge Graph Instructions for GPT-4\\n## 1. Overview\\nYou are a top-tier algorithm designed for extracting information in structured formats to build a knowledge graph.\\nTry to capture as much information from the text as possible without sacrifing accuracy. Do not add any information that is not explicitly mentioned in the text\\n- **Nodes** represent entities and concepts.\\n- The aim is to achieve simplicity and clarity in the knowledge graph, making it\\naccessible for a vast audience.\\n## 2. Labeling Nodes\\n- **Consistency**: Ensure you use available types for node labels.\\nEnsure you use basic or elementary types for node labels.\\n- For example, when you identify an entity representing a person, always label it as **\\'person\\'**. Avoid using more specific terms like \\'mathematician\\' or \\'scientist\\'  - **Node IDs**: Never utilize integers as node IDs. Node IDs should be names or human-readable identifiers found in the text.\\n- **Relationships** represent connections between entities or concepts.\\nEnsure consistency and generality in relationship types when constructing knowledge graphs. Instead of using specific and momentary types such as \\'BECAME_PROFESSOR\\', use more general and timeless relationship types like \\'PROFESSOR\\'. Make sure to use general and timeless relationship types!\\n## 3. Coreference Resolution\\n- **Maintain Entity Consistency**: When extracting entities, it\\'s vital to ensure consistency.\\nIf an entity, such as \"John Doe\", is mentioned multiple times in the text but is referred to by different names or pronouns (e.g., \"Joe\", \"he\"),always use the most complete identifier for that entity throughout the knowledge graph. In this example, use \"John Doe\" as the entity ID.\\nRemember, the knowledge graph should be coherent and easily understandable, so maintaining consistency in entity references is crucial.\\n## 4. Strict Compliance\\nAdhere to the rules strictly. Non-compliance will result in termination.')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='Tip: Make sure to answer in the correct format and do not include any explanations. Use the given format to extract information from the following input: {input}'))])]\n",
      "\n",
      "Prompts\n",
      " <class 'pydantic.v1.main.PromptInput'>\n",
      "\n",
      "Prompts\n",
      " <class 'pydantic.v1.main.RunnableAssignOutput'>\n",
      "\n",
      "Prompts\n",
      " [ChatPromptTemplate(input_variables=['input'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='# Knowledge Graph Instructions for GPT-4\\n## 1. Overview\\nYou are a top-tier algorithm designed for extracting information in structured formats to build a knowledge graph.\\nTry to capture as much information from the text as possible without sacrifing accuracy. Do not add any information that is not explicitly mentioned in the text\\n- **Nodes** represent entities and concepts.\\n- The aim is to achieve simplicity and clarity in the knowledge graph, making it\\naccessible for a vast audience.\\n## 2. Labeling Nodes\\n- **Consistency**: Ensure you use available types for node labels.\\nEnsure you use basic or elementary types for node labels.\\n- For example, when you identify an entity representing a person, always label it as **\\'person\\'**. Avoid using more specific terms like \\'mathematician\\' or \\'scientist\\'  - **Node IDs**: Never utilize integers as node IDs. Node IDs should be names or human-readable identifiers found in the text.\\n- **Relationships** represent connections between entities or concepts.\\nEnsure consistency and generality in relationship types when constructing knowledge graphs. Instead of using specific and momentary types such as \\'BECAME_PROFESSOR\\', use more general and timeless relationship types like \\'PROFESSOR\\'. Make sure to use general and timeless relationship types!\\n## 3. Coreference Resolution\\n- **Maintain Entity Consistency**: When extracting entities, it\\'s vital to ensure consistency.\\nIf an entity, such as \"John Doe\", is mentioned multiple times in the text but is referred to by different names or pronouns (e.g., \"Joe\", \"he\"),always use the most complete identifier for that entity throughout the knowledge graph. In this example, use \"John Doe\" as the entity ID.\\nRemember, the knowledge graph should be coherent and easily understandable, so maintaining consistency in entity references is crucial.\\n## 4. Strict Compliance\\nAdhere to the rules strictly. Non-compliance will result in termination.')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='Tip: Make sure to answer in the correct format and do not include any explanations. Use the given format to extract information from the following input: {input}'))])]\n",
      "\n",
      "Prompts\n",
      " <class 'pydantic.v1.main.PromptInput'>\n",
      "\n",
      "Prompts\n",
      " <class 'pydantic.v1.main.RunnableAssignOutput'>\n",
      "\n",
      "Prompts\n",
      " [ChatPromptTemplate(input_variables=['input'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='# Knowledge Graph Instructions for GPT-4\\n## 1. Overview\\nYou are a top-tier algorithm designed for extracting information in structured formats to build a knowledge graph.\\nTry to capture as much information from the text as possible without sacrifing accuracy. Do not add any information that is not explicitly mentioned in the text\\n- **Nodes** represent entities and concepts.\\n- The aim is to achieve simplicity and clarity in the knowledge graph, making it\\naccessible for a vast audience.\\n## 2. Labeling Nodes\\n- **Consistency**: Ensure you use available types for node labels.\\nEnsure you use basic or elementary types for node labels.\\n- For example, when you identify an entity representing a person, always label it as **\\'person\\'**. Avoid using more specific terms like \\'mathematician\\' or \\'scientist\\'  - **Node IDs**: Never utilize integers as node IDs. Node IDs should be names or human-readable identifiers found in the text.\\n- **Relationships** represent connections between entities or concepts.\\nEnsure consistency and generality in relationship types when constructing knowledge graphs. Instead of using specific and momentary types such as \\'BECAME_PROFESSOR\\', use more general and timeless relationship types like \\'PROFESSOR\\'. Make sure to use general and timeless relationship types!\\n## 3. Coreference Resolution\\n- **Maintain Entity Consistency**: When extracting entities, it\\'s vital to ensure consistency.\\nIf an entity, such as \"John Doe\", is mentioned multiple times in the text but is referred to by different names or pronouns (e.g., \"Joe\", \"he\"),always use the most complete identifier for that entity throughout the knowledge graph. In this example, use \"John Doe\" as the entity ID.\\nRemember, the knowledge graph should be coherent and easily understandable, so maintaining consistency in entity references is crucial.\\n## 4. Strict Compliance\\nAdhere to the rules strictly. Non-compliance will result in termination.')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='Tip: Make sure to answer in the correct format and do not include any explanations. Use the given format to extract information from the following input: {input}'))])]\n",
      "\n",
      "Prompts\n",
      " <class 'pydantic.v1.main.PromptInput'>\n",
      "\n",
      "Prompts\n",
      " <class 'pydantic.v1.main.RunnableAssignOutput'>\n",
      "\n",
      "Prompts\n",
      " [ChatPromptTemplate(input_variables=['input'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='# Knowledge Graph Instructions for GPT-4\\n## 1. Overview\\nYou are a top-tier algorithm designed for extracting information in structured formats to build a knowledge graph.\\nTry to capture as much information from the text as possible without sacrifing accuracy. Do not add any information that is not explicitly mentioned in the text\\n- **Nodes** represent entities and concepts.\\n- The aim is to achieve simplicity and clarity in the knowledge graph, making it\\naccessible for a vast audience.\\n## 2. Labeling Nodes\\n- **Consistency**: Ensure you use available types for node labels.\\nEnsure you use basic or elementary types for node labels.\\n- For example, when you identify an entity representing a person, always label it as **\\'person\\'**. Avoid using more specific terms like \\'mathematician\\' or \\'scientist\\'  - **Node IDs**: Never utilize integers as node IDs. Node IDs should be names or human-readable identifiers found in the text.\\n- **Relationships** represent connections between entities or concepts.\\nEnsure consistency and generality in relationship types when constructing knowledge graphs. Instead of using specific and momentary types such as \\'BECAME_PROFESSOR\\', use more general and timeless relationship types like \\'PROFESSOR\\'. Make sure to use general and timeless relationship types!\\n## 3. Coreference Resolution\\n- **Maintain Entity Consistency**: When extracting entities, it\\'s vital to ensure consistency.\\nIf an entity, such as \"John Doe\", is mentioned multiple times in the text but is referred to by different names or pronouns (e.g., \"Joe\", \"he\"),always use the most complete identifier for that entity throughout the knowledge graph. In this example, use \"John Doe\" as the entity ID.\\nRemember, the knowledge graph should be coherent and easily understandable, so maintaining consistency in entity references is crucial.\\n## 4. Strict Compliance\\nAdhere to the rules strictly. Non-compliance will result in termination.')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='Tip: Make sure to answer in the correct format and do not include any explanations. Use the given format to extract information from the following input: {input}'))])]\n",
      "\n",
      "Prompts\n",
      " <class 'pydantic.v1.main.PromptInput'>\n",
      "\n",
      "Prompts\n",
      " <class 'pydantic.v1.main.RunnableAssignOutput'>\n",
      "\n",
      "Prompts\n",
      " [ChatPromptTemplate(input_variables=['input'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='# Knowledge Graph Instructions for GPT-4\\n## 1. Overview\\nYou are a top-tier algorithm designed for extracting information in structured formats to build a knowledge graph.\\nTry to capture as much information from the text as possible without sacrifing accuracy. Do not add any information that is not explicitly mentioned in the text\\n- **Nodes** represent entities and concepts.\\n- The aim is to achieve simplicity and clarity in the knowledge graph, making it\\naccessible for a vast audience.\\n## 2. Labeling Nodes\\n- **Consistency**: Ensure you use available types for node labels.\\nEnsure you use basic or elementary types for node labels.\\n- For example, when you identify an entity representing a person, always label it as **\\'person\\'**. Avoid using more specific terms like \\'mathematician\\' or \\'scientist\\'  - **Node IDs**: Never utilize integers as node IDs. Node IDs should be names or human-readable identifiers found in the text.\\n- **Relationships** represent connections between entities or concepts.\\nEnsure consistency and generality in relationship types when constructing knowledge graphs. Instead of using specific and momentary types such as \\'BECAME_PROFESSOR\\', use more general and timeless relationship types like \\'PROFESSOR\\'. Make sure to use general and timeless relationship types!\\n## 3. Coreference Resolution\\n- **Maintain Entity Consistency**: When extracting entities, it\\'s vital to ensure consistency.\\nIf an entity, such as \"John Doe\", is mentioned multiple times in the text but is referred to by different names or pronouns (e.g., \"Joe\", \"he\"),always use the most complete identifier for that entity throughout the knowledge graph. In this example, use \"John Doe\" as the entity ID.\\nRemember, the knowledge graph should be coherent and easily understandable, so maintaining consistency in entity references is crucial.\\n## 4. Strict Compliance\\nAdhere to the rules strictly. Non-compliance will result in termination.')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='Tip: Make sure to answer in the correct format and do not include any explanations. Use the given format to extract information from the following input: {input}'))])]\n",
      "\n",
      "Prompts\n",
      " <class 'pydantic.v1.main.PromptInput'>\n",
      "\n",
      "Prompts\n",
      " <class 'pydantic.v1.main.RunnableAssignOutput'>\n",
      "\n",
      "Prompts\n",
      " [ChatPromptTemplate(input_variables=['input'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='# Knowledge Graph Instructions for GPT-4\\n## 1. Overview\\nYou are a top-tier algorithm designed for extracting information in structured formats to build a knowledge graph.\\nTry to capture as much information from the text as possible without sacrifing accuracy. Do not add any information that is not explicitly mentioned in the text\\n- **Nodes** represent entities and concepts.\\n- The aim is to achieve simplicity and clarity in the knowledge graph, making it\\naccessible for a vast audience.\\n## 2. Labeling Nodes\\n- **Consistency**: Ensure you use available types for node labels.\\nEnsure you use basic or elementary types for node labels.\\n- For example, when you identify an entity representing a person, always label it as **\\'person\\'**. Avoid using more specific terms like \\'mathematician\\' or \\'scientist\\'  - **Node IDs**: Never utilize integers as node IDs. Node IDs should be names or human-readable identifiers found in the text.\\n- **Relationships** represent connections between entities or concepts.\\nEnsure consistency and generality in relationship types when constructing knowledge graphs. Instead of using specific and momentary types such as \\'BECAME_PROFESSOR\\', use more general and timeless relationship types like \\'PROFESSOR\\'. Make sure to use general and timeless relationship types!\\n## 3. Coreference Resolution\\n- **Maintain Entity Consistency**: When extracting entities, it\\'s vital to ensure consistency.\\nIf an entity, such as \"John Doe\", is mentioned multiple times in the text but is referred to by different names or pronouns (e.g., \"Joe\", \"he\"),always use the most complete identifier for that entity throughout the knowledge graph. In this example, use \"John Doe\" as the entity ID.\\nRemember, the knowledge graph should be coherent and easily understandable, so maintaining consistency in entity references is crucial.\\n## 4. Strict Compliance\\nAdhere to the rules strictly. Non-compliance will result in termination.')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='Tip: Make sure to answer in the correct format and do not include any explanations. Use the given format to extract information from the following input: {input}'))])]\n",
      "\n",
      "Prompts\n",
      " <class 'pydantic.v1.main.PromptInput'>\n",
      "\n",
      "Prompts\n",
      " <class 'pydantic.v1.main.RunnableAssignOutput'>\n",
      "\n",
      "Prompts\n",
      " [ChatPromptTemplate(input_variables=['input'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='# Knowledge Graph Instructions for GPT-4\\n## 1. Overview\\nYou are a top-tier algorithm designed for extracting information in structured formats to build a knowledge graph.\\nTry to capture as much information from the text as possible without sacrifing accuracy. Do not add any information that is not explicitly mentioned in the text\\n- **Nodes** represent entities and concepts.\\n- The aim is to achieve simplicity and clarity in the knowledge graph, making it\\naccessible for a vast audience.\\n## 2. Labeling Nodes\\n- **Consistency**: Ensure you use available types for node labels.\\nEnsure you use basic or elementary types for node labels.\\n- For example, when you identify an entity representing a person, always label it as **\\'person\\'**. Avoid using more specific terms like \\'mathematician\\' or \\'scientist\\'  - **Node IDs**: Never utilize integers as node IDs. Node IDs should be names or human-readable identifiers found in the text.\\n- **Relationships** represent connections between entities or concepts.\\nEnsure consistency and generality in relationship types when constructing knowledge graphs. Instead of using specific and momentary types such as \\'BECAME_PROFESSOR\\', use more general and timeless relationship types like \\'PROFESSOR\\'. Make sure to use general and timeless relationship types!\\n## 3. Coreference Resolution\\n- **Maintain Entity Consistency**: When extracting entities, it\\'s vital to ensure consistency.\\nIf an entity, such as \"John Doe\", is mentioned multiple times in the text but is referred to by different names or pronouns (e.g., \"Joe\", \"he\"),always use the most complete identifier for that entity throughout the knowledge graph. In this example, use \"John Doe\" as the entity ID.\\nRemember, the knowledge graph should be coherent and easily understandable, so maintaining consistency in entity references is crucial.\\n## 4. Strict Compliance\\nAdhere to the rules strictly. Non-compliance will result in termination.')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='Tip: Make sure to answer in the correct format and do not include any explanations. Use the given format to extract information from the following input: {input}'))])]\n",
      "\n",
      "Prompts\n",
      " <class 'pydantic.v1.main.PromptInput'>\n",
      "\n",
      "Prompts\n",
      " <class 'pydantic.v1.main.RunnableAssignOutput'>\n",
      "\n",
      "Prompts\n",
      " [ChatPromptTemplate(input_variables=['input'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='# Knowledge Graph Instructions for GPT-4\\n## 1. Overview\\nYou are a top-tier algorithm designed for extracting information in structured formats to build a knowledge graph.\\nTry to capture as much information from the text as possible without sacrifing accuracy. Do not add any information that is not explicitly mentioned in the text\\n- **Nodes** represent entities and concepts.\\n- The aim is to achieve simplicity and clarity in the knowledge graph, making it\\naccessible for a vast audience.\\n## 2. Labeling Nodes\\n- **Consistency**: Ensure you use available types for node labels.\\nEnsure you use basic or elementary types for node labels.\\n- For example, when you identify an entity representing a person, always label it as **\\'person\\'**. Avoid using more specific terms like \\'mathematician\\' or \\'scientist\\'  - **Node IDs**: Never utilize integers as node IDs. Node IDs should be names or human-readable identifiers found in the text.\\n- **Relationships** represent connections between entities or concepts.\\nEnsure consistency and generality in relationship types when constructing knowledge graphs. Instead of using specific and momentary types such as \\'BECAME_PROFESSOR\\', use more general and timeless relationship types like \\'PROFESSOR\\'. Make sure to use general and timeless relationship types!\\n## 3. Coreference Resolution\\n- **Maintain Entity Consistency**: When extracting entities, it\\'s vital to ensure consistency.\\nIf an entity, such as \"John Doe\", is mentioned multiple times in the text but is referred to by different names or pronouns (e.g., \"Joe\", \"he\"),always use the most complete identifier for that entity throughout the knowledge graph. In this example, use \"John Doe\" as the entity ID.\\nRemember, the knowledge graph should be coherent and easily understandable, so maintaining consistency in entity references is crucial.\\n## 4. Strict Compliance\\nAdhere to the rules strictly. Non-compliance will result in termination.')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='Tip: Make sure to answer in the correct format and do not include any explanations. Use the given format to extract information from the following input: {input}'))])]\n",
      "\n",
      "Prompts\n",
      " <class 'pydantic.v1.main.PromptInput'>\n",
      "\n",
      "Prompts\n",
      " <class 'pydantic.v1.main.RunnableAssignOutput'>\n",
      "\n",
      "Prompts\n",
      " [ChatPromptTemplate(input_variables=['input'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='# Knowledge Graph Instructions for GPT-4\\n## 1. Overview\\nYou are a top-tier algorithm designed for extracting information in structured formats to build a knowledge graph.\\nTry to capture as much information from the text as possible without sacrifing accuracy. Do not add any information that is not explicitly mentioned in the text\\n- **Nodes** represent entities and concepts.\\n- The aim is to achieve simplicity and clarity in the knowledge graph, making it\\naccessible for a vast audience.\\n## 2. Labeling Nodes\\n- **Consistency**: Ensure you use available types for node labels.\\nEnsure you use basic or elementary types for node labels.\\n- For example, when you identify an entity representing a person, always label it as **\\'person\\'**. Avoid using more specific terms like \\'mathematician\\' or \\'scientist\\'  - **Node IDs**: Never utilize integers as node IDs. Node IDs should be names or human-readable identifiers found in the text.\\n- **Relationships** represent connections between entities or concepts.\\nEnsure consistency and generality in relationship types when constructing knowledge graphs. Instead of using specific and momentary types such as \\'BECAME_PROFESSOR\\', use more general and timeless relationship types like \\'PROFESSOR\\'. Make sure to use general and timeless relationship types!\\n## 3. Coreference Resolution\\n- **Maintain Entity Consistency**: When extracting entities, it\\'s vital to ensure consistency.\\nIf an entity, such as \"John Doe\", is mentioned multiple times in the text but is referred to by different names or pronouns (e.g., \"Joe\", \"he\"),always use the most complete identifier for that entity throughout the knowledge graph. In this example, use \"John Doe\" as the entity ID.\\nRemember, the knowledge graph should be coherent and easily understandable, so maintaining consistency in entity references is crucial.\\n## 4. Strict Compliance\\nAdhere to the rules strictly. Non-compliance will result in termination.')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='Tip: Make sure to answer in the correct format and do not include any explanations. Use the given format to extract information from the following input: {input}'))])]\n",
      "\n",
      "Prompts\n",
      " <class 'pydantic.v1.main.PromptInput'>\n",
      "\n",
      "Prompts\n",
      " <class 'pydantic.v1.main.RunnableAssignOutput'>\n",
      "\n",
      "Prompts\n",
      " [ChatPromptTemplate(input_variables=['input'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='# Knowledge Graph Instructions for GPT-4\\n## 1. Overview\\nYou are a top-tier algorithm designed for extracting information in structured formats to build a knowledge graph.\\nTry to capture as much information from the text as possible without sacrifing accuracy. Do not add any information that is not explicitly mentioned in the text\\n- **Nodes** represent entities and concepts.\\n- The aim is to achieve simplicity and clarity in the knowledge graph, making it\\naccessible for a vast audience.\\n## 2. Labeling Nodes\\n- **Consistency**: Ensure you use available types for node labels.\\nEnsure you use basic or elementary types for node labels.\\n- For example, when you identify an entity representing a person, always label it as **\\'person\\'**. Avoid using more specific terms like \\'mathematician\\' or \\'scientist\\'  - **Node IDs**: Never utilize integers as node IDs. Node IDs should be names or human-readable identifiers found in the text.\\n- **Relationships** represent connections between entities or concepts.\\nEnsure consistency and generality in relationship types when constructing knowledge graphs. Instead of using specific and momentary types such as \\'BECAME_PROFESSOR\\', use more general and timeless relationship types like \\'PROFESSOR\\'. Make sure to use general and timeless relationship types!\\n## 3. Coreference Resolution\\n- **Maintain Entity Consistency**: When extracting entities, it\\'s vital to ensure consistency.\\nIf an entity, such as \"John Doe\", is mentioned multiple times in the text but is referred to by different names or pronouns (e.g., \"Joe\", \"he\"),always use the most complete identifier for that entity throughout the knowledge graph. In this example, use \"John Doe\" as the entity ID.\\nRemember, the knowledge graph should be coherent and easily understandable, so maintaining consistency in entity references is crucial.\\n## 4. Strict Compliance\\nAdhere to the rules strictly. Non-compliance will result in termination.')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='Tip: Make sure to answer in the correct format and do not include any explanations. Use the given format to extract information from the following input: {input}'))])]\n",
      "\n",
      "Prompts\n",
      " <class 'pydantic.v1.main.PromptInput'>\n",
      "\n",
      "Prompts\n",
      " <class 'pydantic.v1.main.RunnableAssignOutput'>\n",
      "\n",
      "Prompts\n",
      " [ChatPromptTemplate(input_variables=['input'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='# Knowledge Graph Instructions for GPT-4\\n## 1. Overview\\nYou are a top-tier algorithm designed for extracting information in structured formats to build a knowledge graph.\\nTry to capture as much information from the text as possible without sacrifing accuracy. Do not add any information that is not explicitly mentioned in the text\\n- **Nodes** represent entities and concepts.\\n- The aim is to achieve simplicity and clarity in the knowledge graph, making it\\naccessible for a vast audience.\\n## 2. Labeling Nodes\\n- **Consistency**: Ensure you use available types for node labels.\\nEnsure you use basic or elementary types for node labels.\\n- For example, when you identify an entity representing a person, always label it as **\\'person\\'**. Avoid using more specific terms like \\'mathematician\\' or \\'scientist\\'  - **Node IDs**: Never utilize integers as node IDs. Node IDs should be names or human-readable identifiers found in the text.\\n- **Relationships** represent connections between entities or concepts.\\nEnsure consistency and generality in relationship types when constructing knowledge graphs. Instead of using specific and momentary types such as \\'BECAME_PROFESSOR\\', use more general and timeless relationship types like \\'PROFESSOR\\'. Make sure to use general and timeless relationship types!\\n## 3. Coreference Resolution\\n- **Maintain Entity Consistency**: When extracting entities, it\\'s vital to ensure consistency.\\nIf an entity, such as \"John Doe\", is mentioned multiple times in the text but is referred to by different names or pronouns (e.g., \"Joe\", \"he\"),always use the most complete identifier for that entity throughout the knowledge graph. In this example, use \"John Doe\" as the entity ID.\\nRemember, the knowledge graph should be coherent and easily understandable, so maintaining consistency in entity references is crucial.\\n## 4. Strict Compliance\\nAdhere to the rules strictly. Non-compliance will result in termination.')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='Tip: Make sure to answer in the correct format and do not include any explanations. Use the given format to extract information from the following input: {input}'))])]\n",
      "\n",
      "Prompts\n",
      " <class 'pydantic.v1.main.PromptInput'>\n",
      "\n",
      "Prompts\n",
      " <class 'pydantic.v1.main.RunnableAssignOutput'>\n",
      "\n",
      "Prompts\n",
      " [ChatPromptTemplate(input_variables=['input'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='# Knowledge Graph Instructions for GPT-4\\n## 1. Overview\\nYou are a top-tier algorithm designed for extracting information in structured formats to build a knowledge graph.\\nTry to capture as much information from the text as possible without sacrifing accuracy. Do not add any information that is not explicitly mentioned in the text\\n- **Nodes** represent entities and concepts.\\n- The aim is to achieve simplicity and clarity in the knowledge graph, making it\\naccessible for a vast audience.\\n## 2. Labeling Nodes\\n- **Consistency**: Ensure you use available types for node labels.\\nEnsure you use basic or elementary types for node labels.\\n- For example, when you identify an entity representing a person, always label it as **\\'person\\'**. Avoid using more specific terms like \\'mathematician\\' or \\'scientist\\'  - **Node IDs**: Never utilize integers as node IDs. Node IDs should be names or human-readable identifiers found in the text.\\n- **Relationships** represent connections between entities or concepts.\\nEnsure consistency and generality in relationship types when constructing knowledge graphs. Instead of using specific and momentary types such as \\'BECAME_PROFESSOR\\', use more general and timeless relationship types like \\'PROFESSOR\\'. Make sure to use general and timeless relationship types!\\n## 3. Coreference Resolution\\n- **Maintain Entity Consistency**: When extracting entities, it\\'s vital to ensure consistency.\\nIf an entity, such as \"John Doe\", is mentioned multiple times in the text but is referred to by different names or pronouns (e.g., \"Joe\", \"he\"),always use the most complete identifier for that entity throughout the knowledge graph. In this example, use \"John Doe\" as the entity ID.\\nRemember, the knowledge graph should be coherent and easily understandable, so maintaining consistency in entity references is crucial.\\n## 4. Strict Compliance\\nAdhere to the rules strictly. Non-compliance will result in termination.')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='Tip: Make sure to answer in the correct format and do not include any explanations. Use the given format to extract information from the following input: {input}'))])]\n",
      "\n",
      "Prompts\n",
      " <class 'pydantic.v1.main.PromptInput'>\n",
      "\n",
      "Prompts\n",
      " <class 'pydantic.v1.main.RunnableAssignOutput'>\n",
      "\n",
      "Prompts\n",
      " [ChatPromptTemplate(input_variables=['input'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='# Knowledge Graph Instructions for GPT-4\\n## 1. Overview\\nYou are a top-tier algorithm designed for extracting information in structured formats to build a knowledge graph.\\nTry to capture as much information from the text as possible without sacrifing accuracy. Do not add any information that is not explicitly mentioned in the text\\n- **Nodes** represent entities and concepts.\\n- The aim is to achieve simplicity and clarity in the knowledge graph, making it\\naccessible for a vast audience.\\n## 2. Labeling Nodes\\n- **Consistency**: Ensure you use available types for node labels.\\nEnsure you use basic or elementary types for node labels.\\n- For example, when you identify an entity representing a person, always label it as **\\'person\\'**. Avoid using more specific terms like \\'mathematician\\' or \\'scientist\\'  - **Node IDs**: Never utilize integers as node IDs. Node IDs should be names or human-readable identifiers found in the text.\\n- **Relationships** represent connections between entities or concepts.\\nEnsure consistency and generality in relationship types when constructing knowledge graphs. Instead of using specific and momentary types such as \\'BECAME_PROFESSOR\\', use more general and timeless relationship types like \\'PROFESSOR\\'. Make sure to use general and timeless relationship types!\\n## 3. Coreference Resolution\\n- **Maintain Entity Consistency**: When extracting entities, it\\'s vital to ensure consistency.\\nIf an entity, such as \"John Doe\", is mentioned multiple times in the text but is referred to by different names or pronouns (e.g., \"Joe\", \"he\"),always use the most complete identifier for that entity throughout the knowledge graph. In this example, use \"John Doe\" as the entity ID.\\nRemember, the knowledge graph should be coherent and easily understandable, so maintaining consistency in entity references is crucial.\\n## 4. Strict Compliance\\nAdhere to the rules strictly. Non-compliance will result in termination.')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='Tip: Make sure to answer in the correct format and do not include any explanations. Use the given format to extract information from the following input: {input}'))])]\n",
      "\n",
      "Prompts\n",
      " <class 'pydantic.v1.main.PromptInput'>\n",
      "\n",
      "Prompts\n",
      " <class 'pydantic.v1.main.RunnableAssignOutput'>\n",
      "\n",
      "Prompts\n",
      " [ChatPromptTemplate(input_variables=['input'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='# Knowledge Graph Instructions for GPT-4\\n## 1. Overview\\nYou are a top-tier algorithm designed for extracting information in structured formats to build a knowledge graph.\\nTry to capture as much information from the text as possible without sacrifing accuracy. Do not add any information that is not explicitly mentioned in the text\\n- **Nodes** represent entities and concepts.\\n- The aim is to achieve simplicity and clarity in the knowledge graph, making it\\naccessible for a vast audience.\\n## 2. Labeling Nodes\\n- **Consistency**: Ensure you use available types for node labels.\\nEnsure you use basic or elementary types for node labels.\\n- For example, when you identify an entity representing a person, always label it as **\\'person\\'**. Avoid using more specific terms like \\'mathematician\\' or \\'scientist\\'  - **Node IDs**: Never utilize integers as node IDs. Node IDs should be names or human-readable identifiers found in the text.\\n- **Relationships** represent connections between entities or concepts.\\nEnsure consistency and generality in relationship types when constructing knowledge graphs. Instead of using specific and momentary types such as \\'BECAME_PROFESSOR\\', use more general and timeless relationship types like \\'PROFESSOR\\'. Make sure to use general and timeless relationship types!\\n## 3. Coreference Resolution\\n- **Maintain Entity Consistency**: When extracting entities, it\\'s vital to ensure consistency.\\nIf an entity, such as \"John Doe\", is mentioned multiple times in the text but is referred to by different names or pronouns (e.g., \"Joe\", \"he\"),always use the most complete identifier for that entity throughout the knowledge graph. In this example, use \"John Doe\" as the entity ID.\\nRemember, the knowledge graph should be coherent and easily understandable, so maintaining consistency in entity references is crucial.\\n## 4. Strict Compliance\\nAdhere to the rules strictly. Non-compliance will result in termination.')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='Tip: Make sure to answer in the correct format and do not include any explanations. Use the given format to extract information from the following input: {input}'))])]\n",
      "\n",
      "Prompts\n",
      " <class 'pydantic.v1.main.PromptInput'>\n",
      "\n",
      "Prompts\n",
      " <class 'pydantic.v1.main.RunnableAssignOutput'>\n",
      "\n",
      "Prompts\n",
      " [ChatPromptTemplate(input_variables=['input'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='# Knowledge Graph Instructions for GPT-4\\n## 1. Overview\\nYou are a top-tier algorithm designed for extracting information in structured formats to build a knowledge graph.\\nTry to capture as much information from the text as possible without sacrifing accuracy. Do not add any information that is not explicitly mentioned in the text\\n- **Nodes** represent entities and concepts.\\n- The aim is to achieve simplicity and clarity in the knowledge graph, making it\\naccessible for a vast audience.\\n## 2. Labeling Nodes\\n- **Consistency**: Ensure you use available types for node labels.\\nEnsure you use basic or elementary types for node labels.\\n- For example, when you identify an entity representing a person, always label it as **\\'person\\'**. Avoid using more specific terms like \\'mathematician\\' or \\'scientist\\'  - **Node IDs**: Never utilize integers as node IDs. Node IDs should be names or human-readable identifiers found in the text.\\n- **Relationships** represent connections between entities or concepts.\\nEnsure consistency and generality in relationship types when constructing knowledge graphs. Instead of using specific and momentary types such as \\'BECAME_PROFESSOR\\', use more general and timeless relationship types like \\'PROFESSOR\\'. Make sure to use general and timeless relationship types!\\n## 3. Coreference Resolution\\n- **Maintain Entity Consistency**: When extracting entities, it\\'s vital to ensure consistency.\\nIf an entity, such as \"John Doe\", is mentioned multiple times in the text but is referred to by different names or pronouns (e.g., \"Joe\", \"he\"),always use the most complete identifier for that entity throughout the knowledge graph. In this example, use \"John Doe\" as the entity ID.\\nRemember, the knowledge graph should be coherent and easily understandable, so maintaining consistency in entity references is crucial.\\n## 4. Strict Compliance\\nAdhere to the rules strictly. Non-compliance will result in termination.')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='Tip: Make sure to answer in the correct format and do not include any explanations. Use the given format to extract information from the following input: {input}'))])]\n",
      "\n",
      "Prompts\n",
      " <class 'pydantic.v1.main.PromptInput'>\n",
      "\n",
      "Prompts\n",
      " <class 'pydantic.v1.main.RunnableAssignOutput'>\n",
      "\n",
      "Prompts\n",
      " [ChatPromptTemplate(input_variables=['input'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='# Knowledge Graph Instructions for GPT-4\\n## 1. Overview\\nYou are a top-tier algorithm designed for extracting information in structured formats to build a knowledge graph.\\nTry to capture as much information from the text as possible without sacrifing accuracy. Do not add any information that is not explicitly mentioned in the text\\n- **Nodes** represent entities and concepts.\\n- The aim is to achieve simplicity and clarity in the knowledge graph, making it\\naccessible for a vast audience.\\n## 2. Labeling Nodes\\n- **Consistency**: Ensure you use available types for node labels.\\nEnsure you use basic or elementary types for node labels.\\n- For example, when you identify an entity representing a person, always label it as **\\'person\\'**. Avoid using more specific terms like \\'mathematician\\' or \\'scientist\\'  - **Node IDs**: Never utilize integers as node IDs. Node IDs should be names or human-readable identifiers found in the text.\\n- **Relationships** represent connections between entities or concepts.\\nEnsure consistency and generality in relationship types when constructing knowledge graphs. Instead of using specific and momentary types such as \\'BECAME_PROFESSOR\\', use more general and timeless relationship types like \\'PROFESSOR\\'. Make sure to use general and timeless relationship types!\\n## 3. Coreference Resolution\\n- **Maintain Entity Consistency**: When extracting entities, it\\'s vital to ensure consistency.\\nIf an entity, such as \"John Doe\", is mentioned multiple times in the text but is referred to by different names or pronouns (e.g., \"Joe\", \"he\"),always use the most complete identifier for that entity throughout the knowledge graph. In this example, use \"John Doe\" as the entity ID.\\nRemember, the knowledge graph should be coherent and easily understandable, so maintaining consistency in entity references is crucial.\\n## 4. Strict Compliance\\nAdhere to the rules strictly. Non-compliance will result in termination.')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='Tip: Make sure to answer in the correct format and do not include any explanations. Use the given format to extract information from the following input: {input}'))])]\n",
      "\n",
      "Prompts\n",
      " <class 'pydantic.v1.main.PromptInput'>\n",
      "\n",
      "Prompts\n",
      " <class 'pydantic.v1.main.RunnableAssignOutput'>\n",
      "\n",
      "Prompts\n",
      " [ChatPromptTemplate(input_variables=['input'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='# Knowledge Graph Instructions for GPT-4\\n## 1. Overview\\nYou are a top-tier algorithm designed for extracting information in structured formats to build a knowledge graph.\\nTry to capture as much information from the text as possible without sacrifing accuracy. Do not add any information that is not explicitly mentioned in the text\\n- **Nodes** represent entities and concepts.\\n- The aim is to achieve simplicity and clarity in the knowledge graph, making it\\naccessible for a vast audience.\\n## 2. Labeling Nodes\\n- **Consistency**: Ensure you use available types for node labels.\\nEnsure you use basic or elementary types for node labels.\\n- For example, when you identify an entity representing a person, always label it as **\\'person\\'**. Avoid using more specific terms like \\'mathematician\\' or \\'scientist\\'  - **Node IDs**: Never utilize integers as node IDs. Node IDs should be names or human-readable identifiers found in the text.\\n- **Relationships** represent connections between entities or concepts.\\nEnsure consistency and generality in relationship types when constructing knowledge graphs. Instead of using specific and momentary types such as \\'BECAME_PROFESSOR\\', use more general and timeless relationship types like \\'PROFESSOR\\'. Make sure to use general and timeless relationship types!\\n## 3. Coreference Resolution\\n- **Maintain Entity Consistency**: When extracting entities, it\\'s vital to ensure consistency.\\nIf an entity, such as \"John Doe\", is mentioned multiple times in the text but is referred to by different names or pronouns (e.g., \"Joe\", \"he\"),always use the most complete identifier for that entity throughout the knowledge graph. In this example, use \"John Doe\" as the entity ID.\\nRemember, the knowledge graph should be coherent and easily understandable, so maintaining consistency in entity references is crucial.\\n## 4. Strict Compliance\\nAdhere to the rules strictly. Non-compliance will result in termination.')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='Tip: Make sure to answer in the correct format and do not include any explanations. Use the given format to extract information from the following input: {input}'))])]\n",
      "\n",
      "Prompts\n",
      " <class 'pydantic.v1.main.PromptInput'>\n",
      "\n",
      "Prompts\n",
      " <class 'pydantic.v1.main.RunnableAssignOutput'>\n",
      "\n",
      "Prompts\n",
      " [ChatPromptTemplate(input_variables=['input'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='# Knowledge Graph Instructions for GPT-4\\n## 1. Overview\\nYou are a top-tier algorithm designed for extracting information in structured formats to build a knowledge graph.\\nTry to capture as much information from the text as possible without sacrifing accuracy. Do not add any information that is not explicitly mentioned in the text\\n- **Nodes** represent entities and concepts.\\n- The aim is to achieve simplicity and clarity in the knowledge graph, making it\\naccessible for a vast audience.\\n## 2. Labeling Nodes\\n- **Consistency**: Ensure you use available types for node labels.\\nEnsure you use basic or elementary types for node labels.\\n- For example, when you identify an entity representing a person, always label it as **\\'person\\'**. Avoid using more specific terms like \\'mathematician\\' or \\'scientist\\'  - **Node IDs**: Never utilize integers as node IDs. Node IDs should be names or human-readable identifiers found in the text.\\n- **Relationships** represent connections between entities or concepts.\\nEnsure consistency and generality in relationship types when constructing knowledge graphs. Instead of using specific and momentary types such as \\'BECAME_PROFESSOR\\', use more general and timeless relationship types like \\'PROFESSOR\\'. Make sure to use general and timeless relationship types!\\n## 3. Coreference Resolution\\n- **Maintain Entity Consistency**: When extracting entities, it\\'s vital to ensure consistency.\\nIf an entity, such as \"John Doe\", is mentioned multiple times in the text but is referred to by different names or pronouns (e.g., \"Joe\", \"he\"),always use the most complete identifier for that entity throughout the knowledge graph. In this example, use \"John Doe\" as the entity ID.\\nRemember, the knowledge graph should be coherent and easily understandable, so maintaining consistency in entity references is crucial.\\n## 4. Strict Compliance\\nAdhere to the rules strictly. Non-compliance will result in termination.')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='Tip: Make sure to answer in the correct format and do not include any explanations. Use the given format to extract information from the following input: {input}'))])]\n",
      "\n",
      "Prompts\n",
      " <class 'pydantic.v1.main.PromptInput'>\n",
      "\n",
      "Prompts\n",
      " <class 'pydantic.v1.main.RunnableAssignOutput'>\n",
      "\n",
      "Prompts\n",
      " [ChatPromptTemplate(input_variables=['input'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='# Knowledge Graph Instructions for GPT-4\\n## 1. Overview\\nYou are a top-tier algorithm designed for extracting information in structured formats to build a knowledge graph.\\nTry to capture as much information from the text as possible without sacrifing accuracy. Do not add any information that is not explicitly mentioned in the text\\n- **Nodes** represent entities and concepts.\\n- The aim is to achieve simplicity and clarity in the knowledge graph, making it\\naccessible for a vast audience.\\n## 2. Labeling Nodes\\n- **Consistency**: Ensure you use available types for node labels.\\nEnsure you use basic or elementary types for node labels.\\n- For example, when you identify an entity representing a person, always label it as **\\'person\\'**. Avoid using more specific terms like \\'mathematician\\' or \\'scientist\\'  - **Node IDs**: Never utilize integers as node IDs. Node IDs should be names or human-readable identifiers found in the text.\\n- **Relationships** represent connections between entities or concepts.\\nEnsure consistency and generality in relationship types when constructing knowledge graphs. Instead of using specific and momentary types such as \\'BECAME_PROFESSOR\\', use more general and timeless relationship types like \\'PROFESSOR\\'. Make sure to use general and timeless relationship types!\\n## 3. Coreference Resolution\\n- **Maintain Entity Consistency**: When extracting entities, it\\'s vital to ensure consistency.\\nIf an entity, such as \"John Doe\", is mentioned multiple times in the text but is referred to by different names or pronouns (e.g., \"Joe\", \"he\"),always use the most complete identifier for that entity throughout the knowledge graph. In this example, use \"John Doe\" as the entity ID.\\nRemember, the knowledge graph should be coherent and easily understandable, so maintaining consistency in entity references is crucial.\\n## 4. Strict Compliance\\nAdhere to the rules strictly. Non-compliance will result in termination.')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='Tip: Make sure to answer in the correct format and do not include any explanations. Use the given format to extract information from the following input: {input}'))])]\n",
      "\n",
      "Prompts\n",
      " <class 'pydantic.v1.main.PromptInput'>\n",
      "\n",
      "Prompts\n",
      " <class 'pydantic.v1.main.RunnableAssignOutput'>\n",
      "\n",
      "Prompts\n",
      " [ChatPromptTemplate(input_variables=['input'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='# Knowledge Graph Instructions for GPT-4\\n## 1. Overview\\nYou are a top-tier algorithm designed for extracting information in structured formats to build a knowledge graph.\\nTry to capture as much information from the text as possible without sacrifing accuracy. Do not add any information that is not explicitly mentioned in the text\\n- **Nodes** represent entities and concepts.\\n- The aim is to achieve simplicity and clarity in the knowledge graph, making it\\naccessible for a vast audience.\\n## 2. Labeling Nodes\\n- **Consistency**: Ensure you use available types for node labels.\\nEnsure you use basic or elementary types for node labels.\\n- For example, when you identify an entity representing a person, always label it as **\\'person\\'**. Avoid using more specific terms like \\'mathematician\\' or \\'scientist\\'  - **Node IDs**: Never utilize integers as node IDs. Node IDs should be names or human-readable identifiers found in the text.\\n- **Relationships** represent connections between entities or concepts.\\nEnsure consistency and generality in relationship types when constructing knowledge graphs. Instead of using specific and momentary types such as \\'BECAME_PROFESSOR\\', use more general and timeless relationship types like \\'PROFESSOR\\'. Make sure to use general and timeless relationship types!\\n## 3. Coreference Resolution\\n- **Maintain Entity Consistency**: When extracting entities, it\\'s vital to ensure consistency.\\nIf an entity, such as \"John Doe\", is mentioned multiple times in the text but is referred to by different names or pronouns (e.g., \"Joe\", \"he\"),always use the most complete identifier for that entity throughout the knowledge graph. In this example, use \"John Doe\" as the entity ID.\\nRemember, the knowledge graph should be coherent and easily understandable, so maintaining consistency in entity references is crucial.\\n## 4. Strict Compliance\\nAdhere to the rules strictly. Non-compliance will result in termination.')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='Tip: Make sure to answer in the correct format and do not include any explanations. Use the given format to extract information from the following input: {input}'))])]\n",
      "\n",
      "Prompts\n",
      " <class 'pydantic.v1.main.PromptInput'>\n",
      "\n",
      "Prompts\n",
      " <class 'pydantic.v1.main.RunnableAssignOutput'>\n",
      "\n",
      "Prompts\n",
      " [ChatPromptTemplate(input_variables=['input'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='# Knowledge Graph Instructions for GPT-4\\n## 1. Overview\\nYou are a top-tier algorithm designed for extracting information in structured formats to build a knowledge graph.\\nTry to capture as much information from the text as possible without sacrifing accuracy. Do not add any information that is not explicitly mentioned in the text\\n- **Nodes** represent entities and concepts.\\n- The aim is to achieve simplicity and clarity in the knowledge graph, making it\\naccessible for a vast audience.\\n## 2. Labeling Nodes\\n- **Consistency**: Ensure you use available types for node labels.\\nEnsure you use basic or elementary types for node labels.\\n- For example, when you identify an entity representing a person, always label it as **\\'person\\'**. Avoid using more specific terms like \\'mathematician\\' or \\'scientist\\'  - **Node IDs**: Never utilize integers as node IDs. Node IDs should be names or human-readable identifiers found in the text.\\n- **Relationships** represent connections between entities or concepts.\\nEnsure consistency and generality in relationship types when constructing knowledge graphs. Instead of using specific and momentary types such as \\'BECAME_PROFESSOR\\', use more general and timeless relationship types like \\'PROFESSOR\\'. Make sure to use general and timeless relationship types!\\n## 3. Coreference Resolution\\n- **Maintain Entity Consistency**: When extracting entities, it\\'s vital to ensure consistency.\\nIf an entity, such as \"John Doe\", is mentioned multiple times in the text but is referred to by different names or pronouns (e.g., \"Joe\", \"he\"),always use the most complete identifier for that entity throughout the knowledge graph. In this example, use \"John Doe\" as the entity ID.\\nRemember, the knowledge graph should be coherent and easily understandable, so maintaining consistency in entity references is crucial.\\n## 4. Strict Compliance\\nAdhere to the rules strictly. Non-compliance will result in termination.')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='Tip: Make sure to answer in the correct format and do not include any explanations. Use the given format to extract information from the following input: {input}'))])]\n",
      "\n",
      "Prompts\n",
      " <class 'pydantic.v1.main.PromptInput'>\n",
      "\n",
      "Prompts\n",
      " <class 'pydantic.v1.main.RunnableAssignOutput'>\n",
      "\n",
      "Prompts\n",
      " [ChatPromptTemplate(input_variables=['input'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='# Knowledge Graph Instructions for GPT-4\\n## 1. Overview\\nYou are a top-tier algorithm designed for extracting information in structured formats to build a knowledge graph.\\nTry to capture as much information from the text as possible without sacrifing accuracy. Do not add any information that is not explicitly mentioned in the text\\n- **Nodes** represent entities and concepts.\\n- The aim is to achieve simplicity and clarity in the knowledge graph, making it\\naccessible for a vast audience.\\n## 2. Labeling Nodes\\n- **Consistency**: Ensure you use available types for node labels.\\nEnsure you use basic or elementary types for node labels.\\n- For example, when you identify an entity representing a person, always label it as **\\'person\\'**. Avoid using more specific terms like \\'mathematician\\' or \\'scientist\\'  - **Node IDs**: Never utilize integers as node IDs. Node IDs should be names or human-readable identifiers found in the text.\\n- **Relationships** represent connections between entities or concepts.\\nEnsure consistency and generality in relationship types when constructing knowledge graphs. Instead of using specific and momentary types such as \\'BECAME_PROFESSOR\\', use more general and timeless relationship types like \\'PROFESSOR\\'. Make sure to use general and timeless relationship types!\\n## 3. Coreference Resolution\\n- **Maintain Entity Consistency**: When extracting entities, it\\'s vital to ensure consistency.\\nIf an entity, such as \"John Doe\", is mentioned multiple times in the text but is referred to by different names or pronouns (e.g., \"Joe\", \"he\"),always use the most complete identifier for that entity throughout the knowledge graph. In this example, use \"John Doe\" as the entity ID.\\nRemember, the knowledge graph should be coherent and easily understandable, so maintaining consistency in entity references is crucial.\\n## 4. Strict Compliance\\nAdhere to the rules strictly. Non-compliance will result in termination.')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='Tip: Make sure to answer in the correct format and do not include any explanations. Use the given format to extract information from the following input: {input}'))])]\n",
      "\n",
      "Prompts\n",
      " <class 'pydantic.v1.main.PromptInput'>\n",
      "\n",
      "Prompts\n",
      " <class 'pydantic.v1.main.RunnableAssignOutput'>\n",
      "\n",
      "Prompts\n",
      " [ChatPromptTemplate(input_variables=['input'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='# Knowledge Graph Instructions for GPT-4\\n## 1. Overview\\nYou are a top-tier algorithm designed for extracting information in structured formats to build a knowledge graph.\\nTry to capture as much information from the text as possible without sacrifing accuracy. Do not add any information that is not explicitly mentioned in the text\\n- **Nodes** represent entities and concepts.\\n- The aim is to achieve simplicity and clarity in the knowledge graph, making it\\naccessible for a vast audience.\\n## 2. Labeling Nodes\\n- **Consistency**: Ensure you use available types for node labels.\\nEnsure you use basic or elementary types for node labels.\\n- For example, when you identify an entity representing a person, always label it as **\\'person\\'**. Avoid using more specific terms like \\'mathematician\\' or \\'scientist\\'  - **Node IDs**: Never utilize integers as node IDs. Node IDs should be names or human-readable identifiers found in the text.\\n- **Relationships** represent connections between entities or concepts.\\nEnsure consistency and generality in relationship types when constructing knowledge graphs. Instead of using specific and momentary types such as \\'BECAME_PROFESSOR\\', use more general and timeless relationship types like \\'PROFESSOR\\'. Make sure to use general and timeless relationship types!\\n## 3. Coreference Resolution\\n- **Maintain Entity Consistency**: When extracting entities, it\\'s vital to ensure consistency.\\nIf an entity, such as \"John Doe\", is mentioned multiple times in the text but is referred to by different names or pronouns (e.g., \"Joe\", \"he\"),always use the most complete identifier for that entity throughout the knowledge graph. In this example, use \"John Doe\" as the entity ID.\\nRemember, the knowledge graph should be coherent and easily understandable, so maintaining consistency in entity references is crucial.\\n## 4. Strict Compliance\\nAdhere to the rules strictly. Non-compliance will result in termination.')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='Tip: Make sure to answer in the correct format and do not include any explanations. Use the given format to extract information from the following input: {input}'))])]\n",
      "\n",
      "Prompts\n",
      " <class 'pydantic.v1.main.PromptInput'>\n",
      "\n",
      "Prompts\n",
      " <class 'pydantic.v1.main.RunnableAssignOutput'>\n",
      "\n",
      "Prompts\n",
      " [ChatPromptTemplate(input_variables=['input'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='# Knowledge Graph Instructions for GPT-4\\n## 1. Overview\\nYou are a top-tier algorithm designed for extracting information in structured formats to build a knowledge graph.\\nTry to capture as much information from the text as possible without sacrifing accuracy. Do not add any information that is not explicitly mentioned in the text\\n- **Nodes** represent entities and concepts.\\n- The aim is to achieve simplicity and clarity in the knowledge graph, making it\\naccessible for a vast audience.\\n## 2. Labeling Nodes\\n- **Consistency**: Ensure you use available types for node labels.\\nEnsure you use basic or elementary types for node labels.\\n- For example, when you identify an entity representing a person, always label it as **\\'person\\'**. Avoid using more specific terms like \\'mathematician\\' or \\'scientist\\'  - **Node IDs**: Never utilize integers as node IDs. Node IDs should be names or human-readable identifiers found in the text.\\n- **Relationships** represent connections between entities or concepts.\\nEnsure consistency and generality in relationship types when constructing knowledge graphs. Instead of using specific and momentary types such as \\'BECAME_PROFESSOR\\', use more general and timeless relationship types like \\'PROFESSOR\\'. Make sure to use general and timeless relationship types!\\n## 3. Coreference Resolution\\n- **Maintain Entity Consistency**: When extracting entities, it\\'s vital to ensure consistency.\\nIf an entity, such as \"John Doe\", is mentioned multiple times in the text but is referred to by different names or pronouns (e.g., \"Joe\", \"he\"),always use the most complete identifier for that entity throughout the knowledge graph. In this example, use \"John Doe\" as the entity ID.\\nRemember, the knowledge graph should be coherent and easily understandable, so maintaining consistency in entity references is crucial.\\n## 4. Strict Compliance\\nAdhere to the rules strictly. Non-compliance will result in termination.')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='Tip: Make sure to answer in the correct format and do not include any explanations. Use the given format to extract information from the following input: {input}'))])]\n",
      "\n",
      "Prompts\n",
      " <class 'pydantic.v1.main.PromptInput'>\n",
      "\n",
      "Prompts\n",
      " <class 'pydantic.v1.main.RunnableAssignOutput'>\n",
      "\n",
      "Prompts\n",
      " [ChatPromptTemplate(input_variables=['input'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='# Knowledge Graph Instructions for GPT-4\\n## 1. Overview\\nYou are a top-tier algorithm designed for extracting information in structured formats to build a knowledge graph.\\nTry to capture as much information from the text as possible without sacrifing accuracy. Do not add any information that is not explicitly mentioned in the text\\n- **Nodes** represent entities and concepts.\\n- The aim is to achieve simplicity and clarity in the knowledge graph, making it\\naccessible for a vast audience.\\n## 2. Labeling Nodes\\n- **Consistency**: Ensure you use available types for node labels.\\nEnsure you use basic or elementary types for node labels.\\n- For example, when you identify an entity representing a person, always label it as **\\'person\\'**. Avoid using more specific terms like \\'mathematician\\' or \\'scientist\\'  - **Node IDs**: Never utilize integers as node IDs. Node IDs should be names or human-readable identifiers found in the text.\\n- **Relationships** represent connections between entities or concepts.\\nEnsure consistency and generality in relationship types when constructing knowledge graphs. Instead of using specific and momentary types such as \\'BECAME_PROFESSOR\\', use more general and timeless relationship types like \\'PROFESSOR\\'. Make sure to use general and timeless relationship types!\\n## 3. Coreference Resolution\\n- **Maintain Entity Consistency**: When extracting entities, it\\'s vital to ensure consistency.\\nIf an entity, such as \"John Doe\", is mentioned multiple times in the text but is referred to by different names or pronouns (e.g., \"Joe\", \"he\"),always use the most complete identifier for that entity throughout the knowledge graph. In this example, use \"John Doe\" as the entity ID.\\nRemember, the knowledge graph should be coherent and easily understandable, so maintaining consistency in entity references is crucial.\\n## 4. Strict Compliance\\nAdhere to the rules strictly. Non-compliance will result in termination.')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='Tip: Make sure to answer in the correct format and do not include any explanations. Use the given format to extract information from the following input: {input}'))])]\n",
      "\n",
      "Prompts\n",
      " <class 'pydantic.v1.main.PromptInput'>\n",
      "\n",
      "Prompts\n",
      " <class 'pydantic.v1.main.RunnableAssignOutput'>\n",
      "\n",
      "Prompts\n",
      " [ChatPromptTemplate(input_variables=['input'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='# Knowledge Graph Instructions for GPT-4\\n## 1. Overview\\nYou are a top-tier algorithm designed for extracting information in structured formats to build a knowledge graph.\\nTry to capture as much information from the text as possible without sacrifing accuracy. Do not add any information that is not explicitly mentioned in the text\\n- **Nodes** represent entities and concepts.\\n- The aim is to achieve simplicity and clarity in the knowledge graph, making it\\naccessible for a vast audience.\\n## 2. Labeling Nodes\\n- **Consistency**: Ensure you use available types for node labels.\\nEnsure you use basic or elementary types for node labels.\\n- For example, when you identify an entity representing a person, always label it as **\\'person\\'**. Avoid using more specific terms like \\'mathematician\\' or \\'scientist\\'  - **Node IDs**: Never utilize integers as node IDs. Node IDs should be names or human-readable identifiers found in the text.\\n- **Relationships** represent connections between entities or concepts.\\nEnsure consistency and generality in relationship types when constructing knowledge graphs. Instead of using specific and momentary types such as \\'BECAME_PROFESSOR\\', use more general and timeless relationship types like \\'PROFESSOR\\'. Make sure to use general and timeless relationship types!\\n## 3. Coreference Resolution\\n- **Maintain Entity Consistency**: When extracting entities, it\\'s vital to ensure consistency.\\nIf an entity, such as \"John Doe\", is mentioned multiple times in the text but is referred to by different names or pronouns (e.g., \"Joe\", \"he\"),always use the most complete identifier for that entity throughout the knowledge graph. In this example, use \"John Doe\" as the entity ID.\\nRemember, the knowledge graph should be coherent and easily understandable, so maintaining consistency in entity references is crucial.\\n## 4. Strict Compliance\\nAdhere to the rules strictly. Non-compliance will result in termination.')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='Tip: Make sure to answer in the correct format and do not include any explanations. Use the given format to extract information from the following input: {input}'))])]\n",
      "\n",
      "Prompts\n",
      " <class 'pydantic.v1.main.PromptInput'>\n",
      "\n",
      "Prompts\n",
      " <class 'pydantic.v1.main.RunnableAssignOutput'>\n",
      "\n",
      "Prompts\n",
      " [ChatPromptTemplate(input_variables=['input'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='# Knowledge Graph Instructions for GPT-4\\n## 1. Overview\\nYou are a top-tier algorithm designed for extracting information in structured formats to build a knowledge graph.\\nTry to capture as much information from the text as possible without sacrifing accuracy. Do not add any information that is not explicitly mentioned in the text\\n- **Nodes** represent entities and concepts.\\n- The aim is to achieve simplicity and clarity in the knowledge graph, making it\\naccessible for a vast audience.\\n## 2. Labeling Nodes\\n- **Consistency**: Ensure you use available types for node labels.\\nEnsure you use basic or elementary types for node labels.\\n- For example, when you identify an entity representing a person, always label it as **\\'person\\'**. Avoid using more specific terms like \\'mathematician\\' or \\'scientist\\'  - **Node IDs**: Never utilize integers as node IDs. Node IDs should be names or human-readable identifiers found in the text.\\n- **Relationships** represent connections between entities or concepts.\\nEnsure consistency and generality in relationship types when constructing knowledge graphs. Instead of using specific and momentary types such as \\'BECAME_PROFESSOR\\', use more general and timeless relationship types like \\'PROFESSOR\\'. Make sure to use general and timeless relationship types!\\n## 3. Coreference Resolution\\n- **Maintain Entity Consistency**: When extracting entities, it\\'s vital to ensure consistency.\\nIf an entity, such as \"John Doe\", is mentioned multiple times in the text but is referred to by different names or pronouns (e.g., \"Joe\", \"he\"),always use the most complete identifier for that entity throughout the knowledge graph. In this example, use \"John Doe\" as the entity ID.\\nRemember, the knowledge graph should be coherent and easily understandable, so maintaining consistency in entity references is crucial.\\n## 4. Strict Compliance\\nAdhere to the rules strictly. Non-compliance will result in termination.')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='Tip: Make sure to answer in the correct format and do not include any explanations. Use the given format to extract information from the following input: {input}'))])]\n",
      "\n",
      "Prompts\n",
      " <class 'pydantic.v1.main.PromptInput'>\n",
      "\n",
      "Prompts\n",
      " <class 'pydantic.v1.main.RunnableAssignOutput'>\n",
      "\n",
      "Prompts\n",
      " [ChatPromptTemplate(input_variables=['input'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='# Knowledge Graph Instructions for GPT-4\\n## 1. Overview\\nYou are a top-tier algorithm designed for extracting information in structured formats to build a knowledge graph.\\nTry to capture as much information from the text as possible without sacrifing accuracy. Do not add any information that is not explicitly mentioned in the text\\n- **Nodes** represent entities and concepts.\\n- The aim is to achieve simplicity and clarity in the knowledge graph, making it\\naccessible for a vast audience.\\n## 2. Labeling Nodes\\n- **Consistency**: Ensure you use available types for node labels.\\nEnsure you use basic or elementary types for node labels.\\n- For example, when you identify an entity representing a person, always label it as **\\'person\\'**. Avoid using more specific terms like \\'mathematician\\' or \\'scientist\\'  - **Node IDs**: Never utilize integers as node IDs. Node IDs should be names or human-readable identifiers found in the text.\\n- **Relationships** represent connections between entities or concepts.\\nEnsure consistency and generality in relationship types when constructing knowledge graphs. Instead of using specific and momentary types such as \\'BECAME_PROFESSOR\\', use more general and timeless relationship types like \\'PROFESSOR\\'. Make sure to use general and timeless relationship types!\\n## 3. Coreference Resolution\\n- **Maintain Entity Consistency**: When extracting entities, it\\'s vital to ensure consistency.\\nIf an entity, such as \"John Doe\", is mentioned multiple times in the text but is referred to by different names or pronouns (e.g., \"Joe\", \"he\"),always use the most complete identifier for that entity throughout the knowledge graph. In this example, use \"John Doe\" as the entity ID.\\nRemember, the knowledge graph should be coherent and easily understandable, so maintaining consistency in entity references is crucial.\\n## 4. Strict Compliance\\nAdhere to the rules strictly. Non-compliance will result in termination.')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='Tip: Make sure to answer in the correct format and do not include any explanations. Use the given format to extract information from the following input: {input}'))])]\n",
      "\n",
      "Prompts\n",
      " <class 'pydantic.v1.main.PromptInput'>\n",
      "\n",
      "Prompts\n",
      " <class 'pydantic.v1.main.RunnableAssignOutput'>\n"
     ]
    }
   ],
   "source": [
    "llm_transformer = LLMGraphTransformer(llm=llm)\n",
    "graph_documents = llm_transformer.convert_to_graph_documents(all_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in graph_documents:\n",
    "    for node in doc.nodes:\n",
    "        if '_' in node.id:\n",
    "            node.id = node.id.replace('_',' ')\n",
    "        if '_' in node.type:\n",
    "            node.type = node.type.replace('_',' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.add_graph_documents(graph_documents, baseEntityLabel=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Retrieve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.1 Detect entities in the user input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 'Human Ldlr Gene', 'types': ['__Entity__', 'Gene']},\n",
       " {'id': 'Met 1', 'types': ['__Entity__', 'Amino acid']},\n",
       " {'id': 'Machine Learning', 'types': ['__Entity__', 'Concept']},\n",
       " {'id': 'Deep Learning', 'types': ['__Entity__', 'Concept']},\n",
       " {'id': 'Neural Networks', 'types': ['__Entity__', 'Concept']},\n",
       " {'id': 'Familial Hypercholesterolemia',\n",
       "  'types': ['__Entity__',\n",
       "   'Genetic disorder',\n",
       "   'Disease',\n",
       "   'Condition',\n",
       "   'Disorder']},\n",
       " {'id': 'Ldl Plasma Cholesterol', 'types': ['__Entity__', 'Metabolite']},\n",
       " {'id': 'Atherosclerosis', 'types': ['__Entity__', 'Disease', 'Condition']},\n",
       " {'id': 'Coronary Heart Disease',\n",
       "  'types': ['__Entity__', 'Disease', 'Condition']},\n",
       " {'id': 'Ldlr Gene', 'types': ['__Entity__', 'Gene']},\n",
       " {'id': 'C.1A>T',\n",
       "  'types': ['__Entity__',\n",
       "   'Genetic variant',\n",
       "   'Variant',\n",
       "   'Entity',\n",
       "   'Mutation',\n",
       "   'Genetic variation']},\n",
       " {'id': 'C.1A>C',\n",
       "  'types': ['__Entity__',\n",
       "   'Genetic variant',\n",
       "   'Variant',\n",
       "   'Entity',\n",
       "   'Mutation',\n",
       "   'Genetic variation']},\n",
       " {'id': 'Met1Leu', 'types': ['__Entity__', 'Amino acid', 'Variant']},\n",
       " {'id': 'Variant C.1A>T', 'types': ['__Entity__', 'Variant', 'Ldlr variant']},\n",
       " {'id': 'Translation Initiation Codon',\n",
       "  'types': ['__Entity__', 'Codon', 'Genetic sequence']},\n",
       " {'id': 'Amino Acid P.(Met1Leu)', 'types': ['__Entity__', 'Amino acid']},\n",
       " {'id': 'Ldlr Expression', 'types': ['__Entity__', 'Expression', 'Phenotype']},\n",
       " {'id': 'Activity', 'types': ['__Entity__', 'Activity']},\n",
       " {'id': 'Efficiencies Of Translation Initiation',\n",
       "  'types': ['__Entity__', 'Efficiency']},\n",
       " {'id': 'Non-Canonical Initiation Codons',\n",
       "  'types': ['__Entity__', 'Codon', 'Codons']},\n",
       " {'id': 'Functional Data', 'types': ['__Entity__', 'Data']},\n",
       " {'id': 'American College Of Medical Genetics (Acmg)',\n",
       "  'types': ['Organization', '__Entity__']},\n",
       " {'id': 'Lipid-Lowering Treatment',\n",
       "  'types': ['__Entity__', 'Treatment', 'Medical treatment']},\n",
       " {'id': 'Dyslipidemia Management',\n",
       "  'types': ['__Entity__', 'Management', 'Medical management']},\n",
       " {'id': \"Patients' Prognosis\", 'types': ['__Entity__', 'Prognosis']},\n",
       " {'id': 'Conflicts Of Interest', 'types': ['__Entity__', 'Concept']},\n",
       " {'id': 'Authors', 'types': ['Person', '__Entity__']},\n",
       " {'id': 'Receptor-Mediated Pathway', 'types': ['__Entity__', 'Pathway']},\n",
       " {'id': 'Estimating Prevalence', 'types': ['__Entity__', 'Review']},\n",
       " {'id': 'Genetics Of Hypercholesterolaemia',\n",
       "  'types': ['__Entity__', 'Genetics']},\n",
       " {'id': 'Ldl Receptor Mutational Analysis',\n",
       "  'types': ['__Entity__', 'Analysis']},\n",
       " {'id': 'Familial Hypercholesterolaemia Phenotype',\n",
       "  'types': ['__Entity__', 'Phenotype']},\n",
       " {'id': 'Ldl Cholesterol Gene Score', 'types': ['__Entity__', 'Score']},\n",
       " {'id': 'Clinvar Database', 'types': ['__Entity__', 'Database']},\n",
       " {'id': 'Genetic Disease', 'types': ['__Entity__', 'Disease']},\n",
       " {'id': 'Genetic Identification', 'types': ['__Entity__', 'Identification']},\n",
       " {'id': 'U.S. Health Care System',\n",
       "  'types': ['__Entity__', 'Healthcare system']},\n",
       " {'id': 'Safeheart Registry', 'types': ['__Entity__', 'Registry']},\n",
       " {'id': 'Ldl Receptor Gene', 'types': ['__Entity__', 'Gene']},\n",
       " {'id': 'Portuguese Familial Hypercholesterolaemia Study',\n",
       "  'types': ['__Entity__', 'Study']},\n",
       " {'id': 'Brazilian Patients', 'types': ['__Entity__', 'Patients']},\n",
       " {'id': 'Molecular Genetics Of The Ldl Receptor Gene',\n",
       "  'types': ['__Entity__', 'Study']},\n",
       " {'id': 'Mutational Analysis Cohort', 'types': ['__Entity__', 'Analysis']},\n",
       " {'id': 'Genetic Diagnosis Improvement',\n",
       "  'types': ['__Entity__', 'Consideration']},\n",
       " {'id': 'Estudo Português De Hipercolesterolemia Familiar',\n",
       "  'types': ['__Entity__', 'Study']},\n",
       " {'id': 'The Clinical Genome Resource (Clingen) Familial Hypercholesterolemia Variant Curation Expert Panel Consensus Guidelines',\n",
       "  'types': ['__Entity__', 'Guidelines']},\n",
       " {'id': 'Predicting The Functional Effect Of Amino Acid Substitutions And Indels',\n",
       "  'types': ['__Entity__', 'Method']},\n",
       " {'id': 'Sift Algorithm', 'types': ['__Entity__', 'Algorithm']},\n",
       " {'id': 'Prediction Server For Damaging Missense Mutations',\n",
       "  'types': ['__Entity__', 'Server']},\n",
       " {'id': 'Mutationtaster', 'types': ['__Entity__', 'Tool', 'Software']},\n",
       " {'id': 'Revel',\n",
       "  'types': ['__Entity__',\n",
       "   'Tool',\n",
       "   'Method',\n",
       "   'Bioinformatics tool',\n",
       "   'Software']},\n",
       " {'id': 'Genome-Wide Analysis', 'types': ['__Entity__', 'Method']},\n",
       " {'id': 'Ribosome Profiling', 'types': ['__Entity__', 'Method']},\n",
       " {'id': 'Non-Aug Translation', 'types': ['__Entity__', 'Method']},\n",
       " {'id': 'Cryptic Translation Products', 'types': ['__Entity__', 'Concept']},\n",
       " {'id': 'Leucine-Trna', 'types': ['__Entity__', 'Concept']},\n",
       " {'id': 'Integrated Stress Response', 'types': ['__Entity__', 'Concept']},\n",
       " {'id': 'Initiator Codons', 'types': ['__Entity__', 'Concept', 'Codon']},\n",
       " {'id': 'Ded1P', 'types': ['__Entity__', 'Protein']},\n",
       " {'id': 'Disease-Causing Potential', 'types': ['__Entity__']},\n",
       " {'id': 'Rare Missense Variants', 'types': ['__Entity__']},\n",
       " {'id': 'Protein Synthesis', 'types': ['__Entity__', 'Biological process']},\n",
       " {'id': 'Mhc Class I Molecules', 'types': ['__Entity__']},\n",
       " {'id': 'Mouse Embryonic Stem Cells', 'types': ['__Entity__']},\n",
       " {'id': 'Cug Start Codons', 'types': ['__Entity__']},\n",
       " {'id': 'Mhc Class I', 'types': ['__Entity__']},\n",
       " {'id': '5’ Untranslated Region', 'types': ['__Entity__']},\n",
       " {'id': 'Eukaryotic Ribosomes', 'types': ['__Entity__', 'Ribosome']},\n",
       " {'id': 'Near-Cognate Translation Initiation Codons',\n",
       "  'types': ['__Entity__', 'Codon']},\n",
       " {'id': 'Downstream Secondary Structure',\n",
       "  'types': ['__Entity__', 'Structure']},\n",
       " {'id': 'Helicase Ded1P', 'types': ['__Entity__', 'Helicase']},\n",
       " {'id': '5′ Utrs', 'types': ['__Entity__', 'Utr']},\n",
       " {'id': 'Phenotypical, Clinical, And Molecular Aspects',\n",
       "  'types': ['__Entity__', 'Aspects']},\n",
       " {'id': 'Adults And Children', 'types': ['__Entity__', 'Individuals']},\n",
       " {'id': 'Homozygous Familial Hypercholesterolemia',\n",
       "  'types': ['__Entity__', 'Hypercholesterolemia']},\n",
       " {'id': 'Iberoamerica', 'types': ['Region', '__Entity__']},\n",
       " {'id': 'Point Mutations', 'types': ['__Entity__', 'Mutation']},\n",
       " {'id': 'Receptor-Negative Familial Hypercholesterolemia',\n",
       "  'types': ['__Entity__', 'Hypercholesterolemia']},\n",
       " {'id': 'South African Indian Homozygote',\n",
       "  'types': ['__Entity__', 'Individuals']},\n",
       " {'id': 'Genetic Diagnosis', 'types': ['__Entity__', 'Diagnosis']},\n",
       " {'id': 'South European Outbreed Population',\n",
       "  'types': ['__Entity__', 'Population']},\n",
       " {'id': 'Low-Density Lipoprotein (Ldl) Receptor Gene Mutations',\n",
       "  'types': ['__Entity__', 'Mutation']},\n",
       " {'id': 'Simvastatin', 'types': ['__Entity__', 'Medication']},\n",
       " {'id': 'Total, Ldl, And High-Density Lipoprotein Cholesterol',\n",
       "  'types': ['__Entity__', 'Cholesterol']},\n",
       " {'id': '2019 Esc/Eas Guidelines', 'types': ['__Entity__', 'Guidelines']},\n",
       " {'id': 'Dyslipidaemias', 'types': ['__Entity__', 'Condition']},\n",
       " {'id': 'Lipid Modification', 'types': ['__Entity__', 'Modification']},\n",
       " {'id': 'Cardiovascular Risk', 'types': ['__Entity__', 'Risk']},\n",
       " {'id': 'Ldlr', 'types': ['__Entity__', 'Gene', 'Protein', 'Sequence']},\n",
       " {'id': 'Cho-Ldla7 Cells', 'types': ['__Entity__', 'Cell', 'Cell line']},\n",
       " {'id': 'Α-Tubulin', 'types': ['__Entity__', 'Protein']},\n",
       " {'id': 'Ldl(Fitc)', 'types': ['__Entity__', 'Protein']},\n",
       " {'id': 'Ldlr Pgl4 Constructs', 'types': ['__Entity__', 'Entity']},\n",
       " {'id': 'C.1A>T, P.(Met1Leu)', 'types': ['__Entity__', 'Variant']},\n",
       " {'id': 'C.1A>C, P.(Met1Leu)', 'types': ['__Entity__', 'Variant']},\n",
       " {'id': 'Firefly Luciferase', 'types': ['__Entity__', 'Protein', 'Enzyme']},\n",
       " {'id': 'Renilla Luciferase', 'types': ['__Entity__', 'Enzyme']},\n",
       " {'id': 'Ldlr_Pgl4 Constructs', 'types': ['__Entity__']},\n",
       " {'id': 'Provean', 'types': ['__Entity__', 'Bioinformatics tool', 'Software']},\n",
       " {'id': 'Sift', 'types': ['__Entity__', 'Bioinformatics tool', 'Software']},\n",
       " {'id': 'Polyphen-2', 'types': ['__Entity__', 'Bioinformatics tool']},\n",
       " {'id': 'Mutation Tester 2', 'types': ['__Entity__', 'Bioinformatics tool']},\n",
       " {'id': 'Neutral', 'types': ['__Entity__', 'Classification']},\n",
       " {'id': 'Damaging', 'types': ['__Entity__', 'Classification']},\n",
       " {'id': 'Benign', 'types': ['__Entity__', 'Classification']},\n",
       " {'id': 'Disease Causing', 'types': ['__Entity__', 'Classification']},\n",
       " {'id': '0.638', 'types': ['__Entity__', 'Revel score']},\n",
       " {'id': 'Acmg Classification Without Fs',\n",
       "  'types': ['__Entity__', 'Acmg classification']},\n",
       " {'id': 'Points Without Fs', 'types': ['__Entity__', 'Acmg points']},\n",
       " {'id': 'Acmg Classification After Fs',\n",
       "  'types': ['__Entity__', 'Acmg classification']},\n",
       " {'id': 'Vus',\n",
       "  'types': ['__Entity__',\n",
       "   'Classification',\n",
       "   'Variant of uncertain significance',\n",
       "   'Variant classification']},\n",
       " {'id': 'Likely Pathogenic',\n",
       "  'types': ['__Entity__', 'Classification', 'Variant classification']},\n",
       " {'id': 'Pathogenic',\n",
       "  'types': ['__Entity__', 'Classification', 'Variant classification']},\n",
       " {'id': 'Pm2', 'types': ['__Entity__', 'Acmg point']},\n",
       " {'id': 'Pvs1 Moderate', 'types': ['__Entity__', 'Acmg point']},\n",
       " {'id': 'Pp4', 'types': ['__Entity__', 'Acmg point']},\n",
       " {'id': 'Pp1 Moderate', 'types': ['__Entity__', 'Acmg point']},\n",
       " {'id': 'Ps4 Supporting', 'types': ['__Entity__', 'Acmg point']},\n",
       " {'id': 'Portuguese Fh Study',\n",
       "  'types': ['__Entity__', 'Study', 'Research project']},\n",
       " {'id': 'Fs', 'types': ['__Entity__', 'Functional study']},\n",
       " {'id': 'Family', 'types': ['__Entity__', 'Group']},\n",
       " {'id': 'Index', 'types': ['Person', '__Entity__']},\n",
       " {'id': '1', 'types': ['Person', '__Entity__']},\n",
       " {'id': '2', 'types': ['Person', '__Entity__']},\n",
       " {'id': '3', 'types': ['Person', '__Entity__']},\n",
       " {'id': '4', 'types': ['Person', '__Entity__']},\n",
       " {'id': 'Atorvastatin', 'types': ['__Entity__', 'Medication']},\n",
       " {'id': 'Introduction', 'types': ['__Entity__', 'Section']},\n",
       " {'id': 'Fh', 'types': ['__Entity__', 'Disorder']},\n",
       " {'id': 'Lipid Metabolism', 'types': ['__Entity__', 'Process']},\n",
       " {'id': 'Plasma Cholesterol Levels', 'types': ['__Entity__', 'Process']},\n",
       " {'id': 'Lipid Accumulation', 'types': ['__Entity__', 'Process']},\n",
       " {'id': 'Genetic Disorders', 'types': ['__Entity__', 'Condition']},\n",
       " {'id': 'Apob', 'types': ['__Entity__', 'Gene']},\n",
       " {'id': 'Pcsk9', 'types': ['__Entity__', 'Gene']},\n",
       " {'id': 'Abcg5/8', 'types': ['__Entity__', 'Gene']},\n",
       " {'id': 'Apoe', 'types': ['__Entity__', 'Gene']},\n",
       " {'id': 'Ldlrap1', 'types': ['__Entity__', 'Gene']},\n",
       " {'id': 'Lipa', 'types': ['__Entity__', 'Gene']},\n",
       " {'id': 'Omim 143890', 'types': ['__Entity__']},\n",
       " {'id': 'Autosomal Dominant Inheritance Pattern',\n",
       "  'types': ['__Entity__', 'Genetics']},\n",
       " {'id': 'Ldlr Variants',\n",
       "  'types': ['__Entity__', 'Gene', 'Genetic variant', 'Genetics']},\n",
       " {'id': 'Fh Patients', 'types': ['__Entity__', 'Patients']},\n",
       " {'id': 'Phenotypic Variability', 'types': ['__Entity__', 'Genetics']},\n",
       " {'id': 'Groups', 'types': ['__Entity__', 'Groups']},\n",
       " {'id': 'Causative Gene', 'types': ['__Entity__', 'Genetics']},\n",
       " {'id': 'Mutation Type', 'types': ['__Entity__', 'Genetics']},\n",
       " {'id': 'Lipid Levels', 'types': ['__Entity__', 'Health indicators']},\n",
       " {'id': 'Carriers', 'types': ['__Entity__', 'Carrier', 'Patients']},\n",
       " {'id': 'Percentage Of Activity',\n",
       "  'types': ['__Entity__', 'Health indicators']},\n",
       " {'id': 'Response To Lipid Therapy',\n",
       "  'types': ['__Entity__', 'Medical treatment']},\n",
       " {'id': 'Null Variants', 'types': ['__Entity__', 'Genetics', 'Mutation']},\n",
       " {'id': 'Defective Variants', 'types': ['__Entity__', 'Genetics']},\n",
       " {'id': 'Complete Loss Of Function',\n",
       "  'types': ['__Entity__', 'Health indicators']},\n",
       " {'id': 'Partial Loss Of Function',\n",
       "  'types': ['__Entity__', 'Health indicators']},\n",
       " {'id': 'Ld Cholesterol', 'types': ['__Entity__', 'Health indicators']},\n",
       " {'id': 'Response To Statin Therapy',\n",
       "  'types': ['__Entity__', 'Medical treatment']},\n",
       " {'id': 'Brazilian Cohorts', 'types': ['__Entity__', 'Groups']},\n",
       " {'id': 'Spanish Cohorts', 'types': ['__Entity__', 'Groups']},\n",
       " {'id': 'Patients’ Phenotype', 'types': ['__Entity__']},\n",
       " {'id': 'Brazilian Cohort', 'types': ['__Entity__', 'Cohort']},\n",
       " {'id': 'Spanish Cohort', 'types': ['__Entity__', 'Cohort']},\n",
       " {'id': 'Class I', 'types': ['__Entity__', 'Mutation classification']},\n",
       " {'id': 'Class Ii', 'types': ['__Entity__', 'Mutation classification']},\n",
       " {'id': 'Class Iii', 'types': ['__Entity__', 'Mutation classification']},\n",
       " {'id': 'Class Iv', 'types': ['__Entity__', 'Mutation classification']},\n",
       " {'id': 'Class V', 'types': ['__Entity__', 'Mutation classification']},\n",
       " {'id': 'P.(Met1Leu)',\n",
       "  'types': ['__Entity__', 'Amino acid', 'Mutation', 'Variant phenotype']},\n",
       " {'id': 'Mutation', 'types': ['__Entity__', 'Mutation']},\n",
       " {'id': 'Variant', 'types': ['__Entity__']},\n",
       " {'id': 'National Institute Of Health Ethics Committee',\n",
       "  'types': ['__Entity__', 'Committee']},\n",
       " {'id': 'National Data Protection Commission',\n",
       "  'types': ['__Entity__', 'Commission']},\n",
       " {'id': 'Participants', 'types': ['__Entity__', 'Individuals']},\n",
       " {'id': 'Fasting Blood Samples', 'types': ['__Entity__', 'Samples']},\n",
       " {'id': 'Cobas Integra 400 Plus', 'types': ['__Entity__', 'Instrument']},\n",
       " {'id': 'Roche', 'types': ['__Entity__', 'Company']},\n",
       " {'id': 'Healthy Individuals',\n",
       "  'types': ['Person', '__Entity__', 'Individuals']},\n",
       " {'id': 'Ldl', 'types': ['__Entity__', 'Substance', 'Lipoprotein']},\n",
       " {'id': 'Pcdna3', 'types': ['__Entity__', 'Plasmid']},\n",
       " {'id': 'Sv40 Promoter', 'types': ['__Entity__', 'Promoter']},\n",
       " {'id': 'Enhancer', 'types': ['__Entity__', 'Enhancer']},\n",
       " {'id': 'Pgl4.10 Reporter Plasmid', 'types': ['__Entity__', 'Plasmid']},\n",
       " {'id': 'Nzymutagenesis Kit', 'types': ['__Entity__', 'Kit']},\n",
       " {'id': 'Sanger Sequencing', 'types': ['__Entity__', 'Technique']},\n",
       " {'id': 'Ldlr-Deficient Cho-Ldla7 Cells',\n",
       "  'types': ['__Entity__', 'Cell line']},\n",
       " {'id': 'F-12 Nut Mix Medium', 'types': ['__Entity__', 'Cell culture medium']},\n",
       " {'id': 'Fetal Bovine Serum (Fbs)', 'types': ['__Entity__', 'Supplement']},\n",
       " {'id': 'Penicillin', 'types': ['__Entity__', 'Supplement']},\n",
       " {'id': 'Streptomycin', 'types': ['__Entity__', 'Supplement']},\n",
       " {'id': 'Plasmids', 'types': ['__Entity__', 'Dna']},\n",
       " {'id': 'Wild-Type Ldlr Variants', 'types': ['__Entity__', 'Protein']},\n",
       " {'id': 'Mutant Ldlr Variants', 'types': ['__Entity__', 'Protein']},\n",
       " {'id': 'Lipofectamine 2000 Transfection Reagent',\n",
       "  'types': ['__Entity__', 'Reagent']},\n",
       " {'id': 'Luminometry Assays', 'types': ['__Entity__', 'Experiment']},\n",
       " {'id': 'Transient Transfections', 'types': ['__Entity__', 'Method']},\n",
       " {'id': 'Cells', 'types': ['__Entity__', 'Cell', 'Cell culture']},\n",
       " {'id': 'Test Dna Construct', 'types': ['__Entity__', 'Dna']},\n",
       " {'id': 'Ldlr Pgl4-Wt Plasmid', 'types': ['__Entity__', 'Plasmid']},\n",
       " {'id': 'Prl-Tk Plasmid', 'types': ['__Entity__', 'Plasmid']},\n",
       " {'id': 'Renilla Luciferase (Rluc)', 'types': ['__Entity__', 'Enzyme']},\n",
       " {'id': 'Ldlr_Pgl4-Wt Plasmid', 'types': ['__Entity__']},\n",
       " {'id': 'Protein Expression',\n",
       "  'types': ['__Entity__', 'Process', 'Biological activity']},\n",
       " {'id': 'Whole-Cell Extracts', 'types': ['__Entity__', 'Material']},\n",
       " {'id': 'Nupage™ 4%–12% Bis-Tris Gel', 'types': ['__Entity__', 'Material']},\n",
       " {'id': 'Nupage™ Mops Sds Running Buffer',\n",
       "  'types': ['__Entity__', 'Material']},\n",
       " {'id': 'Semi-Quantitative Immunoblotting',\n",
       "  'types': ['__Entity__', 'Process']},\n",
       " {'id': 'Pvdf Membranes', 'types': ['__Entity__', 'Material']},\n",
       " {'id': 'Specific Rabbit Polyclonal Antibody',\n",
       "  'types': ['__Entity__', 'Material']},\n",
       " {'id': 'Human Ldl Receptor', 'types': ['__Entity__', 'Protein']},\n",
       " {'id': 'Monoclonal Anti-Α-Tubulin Antibody',\n",
       "  'types': ['__Entity__', 'Material']},\n",
       " {'id': 'Protein Loading Control', 'types': ['__Entity__', 'Process']},\n",
       " {'id': 'Appropriate Secondary Antibodies',\n",
       "  'types': ['__Entity__', 'Material']},\n",
       " {'id': 'Proteins', 'types': ['__Entity__', 'Material']},\n",
       " {'id': 'Chemiluminescence', 'types': ['__Entity__', 'Process']},\n",
       " {'id': 'Pierce™ Ecl Plus Western Blotting Substrate',\n",
       "  'types': ['__Entity__', 'Material']},\n",
       " {'id': 'Chemidoc', 'types': ['__Entity__', 'Equipment']},\n",
       " {'id': 'Relative Band Intensities', 'types': ['__Entity__', 'Property']},\n",
       " {'id': 'Mature (≈160 Kda) Forms Of Ldlr Protein',\n",
       "  'types': ['__Entity__', 'Protein']},\n",
       " {'id': 'Precursor (≈120 Kda) Forms Of Ldlr Protein',\n",
       "  'types': ['__Entity__', 'Protein']},\n",
       " {'id': 'Densitometric Analysis', 'types': ['__Entity__', 'Process']},\n",
       " {'id': 'Image Lab Software', 'types': ['__Entity__', 'Software']},\n",
       " {'id': 'Ldlr Protein', 'types': ['__Entity__', 'Protein']},\n",
       " {'id': 'Biorad', 'types': ['__Entity__', 'Company']},\n",
       " {'id': 'Hercules', 'types': ['__Entity__', 'Location']},\n",
       " {'id': 'Usa', 'types': ['Country', '__Entity__']},\n",
       " {'id': 'Plasma', 'types': ['__Entity__', 'Substance']},\n",
       " {'id': 'Lipoprotein', 'types': ['__Entity__', 'Substance']},\n",
       " {'id': 'Blood', 'types': ['__Entity__', 'Substance']},\n",
       " {'id': 'Potassium Bromide', 'types': ['__Entity__', 'Substance']},\n",
       " {'id': 'Pbs Buffer', 'types': ['__Entity__', 'Substance']},\n",
       " {'id': 'Tst 41–14 Rotor', 'types': ['__Entity__', 'Device']},\n",
       " {'id': 'Centrifugation', 'types': ['__Entity__', 'Process']},\n",
       " {'id': 'Ultracentrifugation', 'types': ['__Entity__', 'Process']},\n",
       " {'id': 'Orange Band', 'types': ['__Entity__', 'Substance']},\n",
       " {'id': 'Fluorescein Isothiocyanate', 'types': ['__Entity__', 'Substance']},\n",
       " {'id': 'Fitc', 'types': ['__Entity__', 'Substance', 'Dye']},\n",
       " {'id': 'Nahco3', 'types': ['__Entity__', 'Substance']},\n",
       " {'id': 'Sephadex G-25', 'types': ['__Entity__', 'Substance']},\n",
       " {'id': 'Dmso', 'types': ['__Entity__', 'Substance']},\n",
       " {'id': 'Pbs Edta-Free Buffer', 'types': ['__Entity__', 'Substance']},\n",
       " {'id': 'Pierce Bca Protein Assay', 'types': ['__Entity__', 'Substance']},\n",
       " {'id': 'Facs', 'types': ['__Entity__', 'Method', 'Technology']},\n",
       " {'id': 'Mouse Anti-Human-Ldlr', 'types': ['__Entity__', 'Antibody']},\n",
       " {'id': 'Alexa Fluor 488-Conjugated Goat Anti-Mouse Igg',\n",
       "  'types': ['__Entity__', 'Antibody']},\n",
       " {'id': 'Progen Biotechnik', 'types': ['__Entity__', 'Company']},\n",
       " {'id': 'Molecular Probes', 'types': ['__Entity__', 'Company']},\n",
       " {'id': 'Fitc-Ldl', 'types': ['__Entity__', 'Substance']},\n",
       " {'id': 'Trypan Blue Solution', 'types': ['__Entity__', 'Substance']},\n",
       " {'id': 'Facscalibur Flow Cytometer',\n",
       "  'types': ['__Entity__', 'Tool', 'Equipment']},\n",
       " {'id': 'Flow Cytometry', 'types': ['__Entity__', 'Tool']},\n",
       " {'id': 'Pbs-1% Bsa', 'types': ['__Entity__', 'Solution']},\n",
       " {'id': 'Luminometry Assay', 'types': ['__Entity__', 'Assay']},\n",
       " {'id': 'Passive Lysis Buffer', 'types': ['__Entity__', 'Buffer']},\n",
       " {'id': 'Fluc', 'types': ['__Entity__', 'Enzyme']},\n",
       " {'id': 'Rluc', 'types': ['__Entity__', 'Enzyme']},\n",
       " {'id': 'Dual-Luciferase Reporter Assay System',\n",
       "  'types': ['__Entity__', 'Assay system']},\n",
       " {'id': 'Glomax 96 Microplate Luminometer',\n",
       "  'types': ['__Entity__', 'Luminometer']},\n",
       " {'id': 'Luciferase Activity', 'types': ['__Entity__', 'Activity']},\n",
       " {'id': 'Sample', 'types': ['__Entity__', 'Sample']},\n",
       " {'id': 'Clinical Genome Resource', 'types': ['__Entity__', 'Resource']},\n",
       " {'id': 'Fh Variant Curation Expert Panel', 'types': ['__Entity__', 'Panel']},\n",
       " {'id': 'Acmg/Amp Variant Interpretation Guidelines',\n",
       "  'types': ['__Entity__', 'Guidelines']},\n",
       " {'id': 'Software Tools', 'types': ['__Entity__', 'Tool']},\n",
       " {'id': 'Polyphen2', 'types': ['__Entity__', 'Software']},\n",
       " {'id': 'Statistical Analysis',\n",
       "  'types': ['__Entity__', 'Concept', 'Analysis']},\n",
       " {'id': 'Acmg', 'types': ['__Entity__']},\n",
       " {'id': 'Mean', 'types': ['__Entity__', 'Concept']},\n",
       " {'id': 'Standard Deviation', 'types': ['__Entity__', 'Concept']},\n",
       " {'id': 'Student’S T-Test', 'types': ['__Entity__', 'Concept']},\n",
       " {'id': 'Statistical Significance', 'types': ['__Entity__']},\n",
       " {'id': 'P-Value', 'types': ['__Entity__']},\n",
       " {'id': 'Variants C.1A>T', 'types': ['__Entity__', 'Variant']},\n",
       " {'id': 'Variants C.1A>C', 'types': ['__Entity__', 'Variant']},\n",
       " {'id': 'Ldlr Variant C.1A>T', 'types': ['__Entity__', 'Variant']},\n",
       " {'id': 'Ldlr Variant C.1A>C', 'types': ['__Entity__', 'Variant']},\n",
       " {'id': 'Chora Et Al. (2021)', 'types': ['__Entity__', 'Researcher']},\n",
       " {'id': 'Variants', 'types': ['__Entity__', 'Genetic variant']},\n",
       " {'id': 'Constructs Pgl4-C.1A>T', 'types': ['__Entity__', 'Construct']},\n",
       " {'id': 'Constructs Pgl4-C.1A>C', 'types': ['__Entity__', 'Construct']},\n",
       " {'id': 'Reporter Gene', 'types': ['__Entity__', 'Gene']},\n",
       " {'id': 'Patients With Variant C.1A>C', 'types': ['__Entity__', 'Patient']},\n",
       " {'id': 'Families', 'types': ['__Entity__', 'Family']},\n",
       " {'id': 'Individuals', 'types': ['__Entity__', 'Individual']},\n",
       " {'id': 'Index Cases', 'types': ['__Entity__', 'Individual']},\n",
       " {'id': 'Relatives', 'types': ['__Entity__', 'Individual']},\n",
       " {'id': 'Methionine', 'types': ['__Entity__', 'Amino acid']},\n",
       " {'id': 'Leucine', 'types': ['__Entity__', 'Amino acid']},\n",
       " {'id': 'Uug', 'types': ['__Entity__', 'Codon', 'Entity']},\n",
       " {'id': 'Cug', 'types': ['__Entity__', 'Codon', 'Entity']},\n",
       " {'id': 'Translation Initiation',\n",
       "  'types': ['__Entity__',\n",
       "   'Entity',\n",
       "   'Initiation mechanism',\n",
       "   'Biological process']},\n",
       " {'id': 'Ribosome Profiling Technique', 'types': ['__Entity__', 'Technique']},\n",
       " {'id': 'Codon', 'types': ['__Entity__']},\n",
       " {'id': 'Uug Codon', 'types': ['__Entity__', 'Codon']},\n",
       " {'id': 'Cug Codon', 'types': ['__Entity__', 'Codon']},\n",
       " {'id': 'Leucine-Encoding Uug Codon', 'types': ['__Entity__', 'Codon']},\n",
       " {'id': 'Eukaryotes', 'types': ['__Entity__', 'Organism']},\n",
       " {'id': 'Initiating Codon', 'types': ['__Entity__', 'Codon']},\n",
       " {'id': 'Non-Aug Start Codon', 'types': ['__Entity__', 'Codon']},\n",
       " {'id': 'Upstream Open Reading Frames', 'types': ['__Entity__', 'Concept']},\n",
       " {'id': 'Key Eukaryotic Initiation Factor (Eif)',\n",
       "  'types': ['__Entity__', 'Protein']},\n",
       " {'id': 'Eif2', 'types': ['__Entity__', 'Protein']},\n",
       " {'id': 'Trnas', 'types': ['__Entity__', 'Molecule']},\n",
       " {'id': 'Met-Trnaimet', 'types': ['__Entity__', 'Molecule']},\n",
       " {'id': 'Eifs', 'types': ['__Entity__', 'Protein']},\n",
       " {'id': 'Eif2A', 'types': ['__Entity__', 'Protein']},\n",
       " {'id': 'Leu-Trnacug', 'types': ['__Entity__', 'Molecule']},\n",
       " {'id': 'Gtp', 'types': ['__Entity__', 'Molecule']},\n",
       " {'id': 'Global Protein Synthesis', 'types': ['__Entity__', 'Process']},\n",
       " {'id': 'Initiation', 'types': ['__Entity__']},\n",
       " {'id': 'Translation Initiation At Augs', 'types': ['__Entity__', 'Process']},\n",
       " {'id': 'Translation Initiation At Cug Or Uug Codons',\n",
       "  'types': ['__Entity__', 'Process']},\n",
       " {'id': 'Variant C.1A>C', 'types': ['__Entity__', 'Variant', 'Ldlr variant']},\n",
       " {'id': 'Ld Binding And Internalization Abilities',\n",
       "  'types': ['__Entity__', 'Phenotype']},\n",
       " {'id': 'Fluc-Based Reporter Constructs',\n",
       "  'types': ['__Entity__', 'Construct']},\n",
       " {'id': 'Ldlr Open Reading Frame (Orf)', 'types': ['__Entity__', 'Sequence']},\n",
       " {'id': 'Orf', 'types': ['__Entity__', 'Entity']},\n",
       " {'id': 'Rna Secondary Structures', 'types': ['__Entity__', 'Entity']},\n",
       " {'id': 'Start Codons', 'types': ['__Entity__', 'Entity']},\n",
       " {'id': 'Pcdna3 Constructs (Ldlr Orf)', 'types': ['__Entity__', 'Entity']},\n",
       " {'id': 'Pgl4 Constructs (Luciferase Orf)', 'types': ['__Entity__', 'Entity']},\n",
       " {'id': 'Non-Canonical Codons', 'types': ['__Entity__', 'Entity']},\n",
       " {'id': 'Scanning Ribosomes', 'types': ['__Entity__', 'Entity']},\n",
       " {'id': 'Gc-Rich Downstream Regions', 'types': ['__Entity__', 'Entity']},\n",
       " {'id': 'Hairpin-Like Structures', 'types': ['__Entity__', 'Entity']},\n",
       " {'id': 'Ribosomal Scanning Process', 'types': ['__Entity__', 'Entity']},\n",
       " {'id': 'Sub-Optimal Codons', 'types': ['__Entity__', 'Entity']},\n",
       " {'id': 'Mrna Secondary Structure', 'types': ['__Entity__', 'Entity']},\n",
       " {'id': 'Mfold', 'types': ['__Entity__', 'Tool', 'Entity']},\n",
       " {'id': 'Luciferase', 'types': ['__Entity__', 'Orf']},\n",
       " {'id': 'Ldlr Class I Mutation', 'types': ['__Entity__', 'Ldlr mutation']},\n",
       " {'id': 'Null Variant', 'types': ['__Entity__', 'Ldlr variant']},\n",
       " {'id': 'Ldlr Class Ii Mutations', 'types': ['__Entity__', 'Ldlr mutation']},\n",
       " {'id': 'Partial Retention Of Immature Protein',\n",
       "  'types': ['__Entity__', 'Ldlr mutation']},\n",
       " {'id': 'Allele Variant', 'types': ['__Entity__', 'Ldlr variant']},\n",
       " {'id': 'Fh Phenotype', 'types': ['__Entity__', 'Phenotype']},\n",
       " {'id': 'Carriers Of Null Allele Variant', 'types': ['__Entity__', 'Carrier']},\n",
       " {'id': 'Carriers Of Defective Allele Variant',\n",
       "  'types': ['__Entity__', 'Carrier']},\n",
       " {'id': 'Ldl Values', 'types': ['__Entity__', 'Value']},\n",
       " {'id': 'Rates Of Premature Chd', 'types': ['__Entity__', 'Rate']},\n",
       " {'id': 'Functional Characterization', 'types': ['__Entity__', 'Process']},\n",
       " {'id': 'Cardiovascular Risk Stratification',\n",
       "  'types': ['__Entity__', 'Process']},\n",
       " {'id': 'In Vitro Results', 'types': ['__Entity__', 'Result']},\n",
       " {'id': 'Severity Of Fh Phenotype', 'types': ['__Entity__', 'Phenotype']},\n",
       " {'id': 'Milder Phenotype', 'types': ['__Entity__', 'Phenotype']},\n",
       " {'id': 'Defective Allele Carrier', 'types': ['__Entity__']},\n",
       " {'id': 'Carriers Of Variant C.1A>C', 'types': ['__Entity__']},\n",
       " {'id': 'Acmg/Amp Guidelines', 'types': ['__Entity__', 'Guidelines']},\n",
       " {'id': 'Functional Study Results', 'types': ['__Entity__', 'Study results']},\n",
       " {'id': 'Protein', 'types': ['__Entity__', 'Protein']},\n",
       " {'id': 'Compound Heterozygous Patient', 'types': ['__Entity__', 'Patient']},\n",
       " {'id': 'Heterozygous Patient', 'types': ['__Entity__', 'Patient']},\n",
       " {'id': 'Fh Homozygous Individual', 'types': ['__Entity__', 'Individual']},\n",
       " {'id': 'First Degree Relatives', 'types': ['__Entity__', 'Relative']},\n",
       " {'id': 'Eight Carriers', 'types': ['__Entity__', 'Carrier']},\n",
       " {'id': 'Values Of Total And Ldl-C',\n",
       "  'types': ['__Entity__', 'Cholesterol value']},\n",
       " {'id': 'Phenotypes', 'types': ['__Entity__', 'Phenotype']},\n",
       " {'id': 'Cholesterol Modulators', 'types': ['__Entity__', 'Modulator']},\n",
       " {'id': 'Age', 'types': ['__Entity__', 'Factor']},\n",
       " {'id': 'Body Mass Index', 'types': ['__Entity__', 'Factor']},\n",
       " {'id': 'Diet', 'types': ['__Entity__', 'Factor']},\n",
       " {'id': 'Physical Exercise', 'types': ['__Entity__', 'Factor']},\n",
       " {'id': 'Other Disorders And Treatments', 'types': ['__Entity__', 'Factor']},\n",
       " {'id': 'Ldlr Translation Initiation Codon', 'types': ['__Entity__', 'Codon']},\n",
       " {'id': 'Non-Canonical Initiator', 'types': ['__Entity__', 'Initiator']},\n",
       " {'id': 'Factors Involved In Non-Canonical Translation Initiation',\n",
       "  'types': ['__Entity__', 'Factor']},\n",
       " {'id': 'Patients', 'types': ['__Entity__', 'Patient']},\n",
       " {'id': 'Statin Therapy', 'types': ['__Entity__', 'Therapy']},\n",
       " {'id': 'Ldl Levels', 'types': ['__Entity__', 'Levels']},\n",
       " {'id': 'Individual', 'types': ['Person', '__Entity__']},\n",
       " {'id': 'Total Cholesterol', 'types': ['__Entity__', 'Cholesterol']},\n",
       " {'id': 'Child', 'types': ['Person', '__Entity__']},\n",
       " {'id': 'Response To Treatment', 'types': ['__Entity__', 'Response']},\n",
       " {'id': 'Results', 'types': ['__Entity__', 'Results']},\n",
       " {'id': 'Mechanism Of Action', 'types': ['__Entity__', 'Mechanism']},\n",
       " {'id': 'Carriers Of Putative Null Variants',\n",
       "  'types': ['__Entity__', 'Carrier']},\n",
       " {'id': 'Variant With Partial Activity', 'types': ['__Entity__', 'Variant']},\n",
       " {'id': 'Statin', 'types': ['__Entity__', 'Medication']},\n",
       " {'id': 'Cholesterol', 'types': ['__Entity__', 'Biomolecule']},\n",
       " {'id': 'Missense Variants', 'types': ['__Entity__', 'Genetic variant']},\n",
       " {'id': 'Ldlr Activity', 'types': ['__Entity__', 'Biological activity']},\n",
       " {'id': 'Acmg Classification',\n",
       "  'types': ['__Entity__', 'Medical classification']},\n",
       " {'id': 'Patient Prognosis',\n",
       "  'types': ['__Entity__', 'Prognosis', 'Medical outcome']},\n",
       " {'id': 'Non-Canonical Initiation',\n",
       "  'types': ['__Entity__', 'Biological process']},\n",
       " {'id': 'Personalized Approach', 'types': ['__Entity__', 'Approach']},\n",
       " {'id': 'Evidence', 'types': ['__Entity__', 'Evidence']},\n",
       " {'id': 'Experiments', 'types': ['__Entity__', 'Experiments']},\n",
       " {'id': 'Mrna Translation Initiation',\n",
       "  'types': ['__Entity__', 'Translation mechanism']},\n",
       " {'id': 'Mdpi', 'types': ['__Entity__', 'Publisher']},\n",
       " {'id': 'Maps', 'types': ['__Entity__']},\n",
       " {'id': 'Institutional Affiliations', 'types': ['__Entity__']},\n",
       " {'id': 'L.R.', 'types': ['Person', '__Entity__']},\n",
       " {'id': 'M.B.', 'types': ['Person', '__Entity__']},\n",
       " {'id': 'R.G.', 'types': ['Person', '__Entity__']},\n",
       " {'id': 'R.F.', 'types': ['Person', '__Entity__']},\n",
       " {'id': 'A.C.A.', 'types': ['Person', '__Entity__']},\n",
       " {'id': 'J.M.', 'types': ['Person', '__Entity__']},\n",
       " {'id': 'Research', 'types': ['__Entity__', 'Research']},\n",
       " {'id': 'Institutional Review Board',\n",
       "  'types': ['__Entity__', 'Institutional review board']},\n",
       " {'id': 'Informed Consent', 'types': ['__Entity__', 'Informed consent']},\n",
       " {'id': 'Institutional_Review_Board', 'types': ['__Entity__']},\n",
       " {'id': 'Informed_Consent', 'types': ['__Entity__']},\n",
       " {'id': 'Data', 'types': ['__Entity__', 'Data']},\n",
       " {'id': 'Author', 'types': ['__Entity__', 'Author']}]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes = graph.query(\"MATCH (n) RETURN DISTINCT n.id AS id, labels(n) AS types\")\n",
    "nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "class Entities(BaseModel):\n",
    "    \"\"\"Identifying information about entities.\"\"\"\n",
    "    names: List[str] = Field()\n",
    "\n",
    "prompt_vector_rag = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are extracting entities from the text.\\n\",\n",
    "        ),\n",
    "        (\n",
    "            \"human\",\n",
    "            \"Use the given format to extract information from the following \"\n",
    "            \"input: {question}\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "entity_chain = prompt_vector_rag | llm.with_structured_output(Entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How can these findings help improve diagnosis and treatment for Familial Hypercholesterolemia?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Entities(names=['findings', 'diagnosis', 'treatment', 'Familial Hypercholesterolemia'])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entities = entity_chain.invoke({\"entities\": nodes, \"question\": prompts[2]})\n",
    "print(prompts[2])\n",
    "entities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.2. Search with Full Text Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.query(\"CREATE FULLTEXT INDEX entity IF NOT EXISTS FOR (e:__Entity__) ON EACH [e.id]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores.neo4j_vector import remove_lucene_chars\n",
    "\n",
    "def generate_full_text_query(input: str) -> str:\n",
    "    \"\"\"\n",
    "    Generate a full-text search query for a given input string.\n",
    "\n",
    "    This function constructs a query string suitable for a full-text search.\n",
    "    It processes the input string by splitting it into words and appending a\n",
    "    similarity threshold (~2 changed characters) to each word, then combines\n",
    "    them using the AND operator. Useful for mapping entities from user questions\n",
    "    to database values, and allows for some misspelings.\n",
    "    \"\"\"\n",
    "    full_text_query = \"\"\n",
    "    words = [el for el in remove_lucene_chars(input).split() if el]\n",
    "    for word in words[:-1]:\n",
    "        full_text_query += f\" {word}~2 AND\"\n",
    "    full_text_query += f\" {words[-1]}~2\"\n",
    "    return full_text_query.strip()\n",
    "\n",
    "# Fulltext index query\n",
    "def structured_retriever(question: str) -> str:\n",
    "    \"\"\"\n",
    "    Collects the neighborhood of entities mentioned\n",
    "    in the question\n",
    "    \"\"\"\n",
    "    result = \"\"\n",
    "    entities = entity_chain.invoke({\"question\": question})\n",
    "    for entity in entities.names:\n",
    "        response = graph.query(\n",
    "            \"\"\"CALL db.index.fulltext.queryNodes('entity', $query, {limit:2})\n",
    "            YIELD node,score\n",
    "            CALL {\n",
    "              WITH node\n",
    "              MATCH (node)-[r:!MENTIONS]->(neighbor)\n",
    "              RETURN node.id + ' - ' + type(r) + ' -> ' + neighbor.id AS output\n",
    "              UNION ALL\n",
    "              WITH node\n",
    "              MATCH (node)<-[r:!MENTIONS]-(neighbor)\n",
    "              RETURN neighbor.id + ' - ' + type(r) + ' -> ' +  node.id AS output\n",
    "            }\n",
    "            RETURN output LIMIT 50\n",
    "            \"\"\",\n",
    "            {\"query\": generate_full_text_query(entity)},\n",
    "        )\n",
    "        \n",
    "        result += \"\\n\".join([el['output'] for el in response])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Familial Hypercholesterolemia - AFFECTS -> Ldl Plasma Cholesterol\n",
      "Familial Hypercholesterolemia - LEADS_TO -> Atherosclerosis\n",
      "Familial Hypercholesterolemia - LEADS_TO -> Coronary Heart Disease\n",
      "Familial Hypercholesterolemia - ASSOCIATED_WITH -> Ldlr\n",
      "Familial Hypercholesterolemia - ASSOCIATED_WITH -> Apob\n",
      "Familial Hypercholesterolemia - ASSOCIATED_WITH -> Pcsk9\n",
      "Familial Hypercholesterolemia - ASSOCIATED_WITH -> Abcg5/8\n",
      "Familial Hypercholesterolemia - ASSOCIATED_WITH -> Apoe\n",
      "Familial Hypercholesterolemia - ASSOCIATED_WITH -> Ldlrap1\n",
      "Familial Hypercholesterolemia - ASSOCIATED_WITH -> Lipa\n",
      "Familial Hypercholesterolemia - PROMOTES -> Atherosclerosis\n",
      "Familial Hypercholesterolemia - PROMOTES -> Coronary Heart Disease\n",
      "Familial Hypercholesterolemia - GENETIC_IDENTIFICATION -> U.S. Health Care System\n",
      "Familial Hypercholesterolemia - MOLECULAR_GENETICS -> Ldl Receptor Gene\n",
      "Familial Hypercholesterolemia - GENOTYPE-PHENOTYPE_RELATION -> Safeheart Registry\n",
      "Familial Hypercholesterolemia - IDENTIFIED_AS -> Omim 143890\n",
      "Familial Hypercholesterolemia - CHARACTERIZED_BY -> Lipid Metabolism\n",
      "Familial Hypercholesterolemia - CHARACTERIZED_BY -> Plasma Cholesterol Levels\n",
      "Familial Hypercholesterolemia - CHARACTERIZED_BY -> Lipid Accumulation\n",
      "Familial Hypercholesterolemia - GENETIC_ANALYSIS -> Ldl Receptor Gene\n",
      "Familial Hypercholesterolemia - MUTATION_INFLUENCE -> Brazilian Patients\n",
      "Familial Hypercholesterolemia - ONE_OF_THE_MOST_COMMON -> Genetic Disorders\n",
      "Safeheart Registry - DIAGNOSTIC_SEQUENCING -> Familial Hypercholesterolemia\n",
      "Mutational Analysis Cohort - DIAGNOSES -> Familial Hypercholesterolemia\n",
      "Revel - PREDICTS -> Familial Hypercholesterolemia\n",
      "Portuguese Familial Hypercholesterolaemia Study - FOCUSES_ON -> Familial Hypercholesterolemia\n",
      "Molecular Genetics Of The Ldl Receptor Gene - FOCUSES_ON -> Familial Hypercholesterolemia\n",
      "Estudo Português De Hipercolesterolemia Familiar - FOCUSES_ON -> Familial Hypercholesterolemia\n",
      "Portuguese Familial Hypercholesterolaemia Study - STUDY_UPDATE -> Familial Hypercholesterolemia\n",
      "Mutationtaster - EVALUATES_POTENTIAL -> Familial Hypercholesterolemia\n",
      "Familial Hypercholesterolaemia Phenotype - DEFINES -> Genetics Of HypercholesterolaemiaGenetic Diagnosis - OF -> Homozygous Familial Hypercholesterolemia\n",
      "Mutational Analysis Cohort - IDENTIFIES -> Genetic Diagnosis ImprovementResponse To Treatment - SUPPORTS -> Results\n",
      "Mutation - MODULATES -> Response To Treatment\n",
      "Lipid-Lowering Treatment - IMPROVES -> Patients' Prognosis\n",
      "American College Of Medical Genetics (Acmg) - ALLOWS_CHOICE_OF -> Lipid-Lowering Treatment\n",
      "Acmg Classification - INFLUENCES -> Lipid-Lowering Treatment\n"
     ]
    }
   ],
   "source": [
    "print(structured_retriever(prompts[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.3. Custom Cypher generating chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "# Generate Cypher statement based on natural language input\n",
    "cypher_template = \"\"\"Based on the Neo4j graph schema below, write a Cypher query that would answer the user's question:\n",
    "{schema}\n",
    "Relationships in the question map to the following database values:\n",
    "{relationships_list}\n",
    "Question: {question}\n",
    "Cypher query:\"\"\"\n",
    "\n",
    "cypher_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"Given an input question, convert it to a simple Cypher query. Use available entities only. Else do not specify type or name or id, just use a generic node. No pre-amble. Use backticks to specify the type Do not specify the node type, just the id. Be concise and do not make more than one MATCH Return statement should always be: RETURN *\",\n",
    "        ),\n",
    "        (\"human\", cypher_template),\n",
    "    ]\n",
    ")\n",
    "\n",
    "cypher_chain = (\n",
    "    RunnablePassthrough.assign(names=entity_chain)\n",
    "    | RunnablePassthrough.assign(\n",
    "        relationships_list=lambda x: structured_retriever(x[\"names\"]),\n",
    "        schema=lambda _: graph.get_schema,\n",
    "    )\n",
    "    | cypher_prompt\n",
    "    | llm.bind(stop=[\"\\nCypherResult:\"])\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MATCH (g:Gene)-[:GENETICS]->(gd:Genetic disorder {id: \"Familial Hypercholesterolemia\"})-[:GENOTYPE-PHENOTYPE_RELATION]->(r:Registry)-[:TREATMENT_FOLLOW-UP]->(c:Cholesterol)\\nMATCH (gd)-[:GENETIC_IDENTIFICATION]->(h:Healthcare system {id: \"U.S. Health Care System\"})\\nMATCH (gd)-[:DIAGNOSTIC_SEQUENCING]->(ch:Cholesterol)\\nMATCH (gd)-[:IS_ASSOCIATED_WITH]->(g1:Gene)-[:IS_ASSOCIATED_WITH]->(g2:Protein)-[:IS_ASSOCIATED_WITH]->(g3:Coding sequence)\\nMATCH (gd)-[:HAS_OMIM_ID]->(o:Omim {id: \"143890\"})\\nMATCH (gd)-[:CAUSES]->(m:Metabolite)\\nMATCH (gd)-[:LEADS_TO]->(c1:Condition {id: \"Atherosclerosis\"})\\nMATCH (gd)-[:LEADS_TO]->(c2:Condition {id: \"Coronary Heart Disease\"})\\nRETURN *'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cypher_query = cypher_chain.invoke({\"question\": prompts[2]})\n",
    "cypher_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Error] Generated Cypher Statement is not valid\n",
      "{code: Neo.ClientError.Statement.SyntaxError} {message: Invalid input 'disorder': expected \")\", \"WHERE\", \"{\" or a parameter (line 1, column 41 (offset: 40))\n",
      "\"MATCH (g:Gene)-[:GENETICS]->(gd:Genetic disorder {id: \"Familial Hypercholesterolemia\"})-[:GENOTYPE-PHENOTYPE_RELATION]->(r:Registry)-[:TREATMENT_FOLLOW-UP]->(c:Cholesterol)\"\n",
      "                                         ^}\n",
      "[Error] Generated Cypher Statement is not valid\n",
      "{code: Neo.ClientError.Statement.SyntaxError} {message: Invalid input '-': expected\n",
      "  \"*\"\n",
      "  \"WHERE\"\n",
      "  \"]\"\n",
      "  \"{\"\n",
      "  a parameter (line 1, column 101 (offset: 100))\n",
      "\"MATCH (g:Gene)-[:GENETICS]->(gd:`Genetic disorder` {id: \"Familial Hypercholesterolemia\"})-[:GENOTYPE-PHENOTYPE_RELATION]->(r:Registry)-[:TREATMENT_FOLLOW-UP]->(c:Cholesterol)\"\n",
      "                                                                                                     ^}\n",
      "[Error] Generated Cypher Statement is not valid\n",
      "{code: Neo.ClientError.Statement.SyntaxError} {message: Invalid input '-': expected\n",
      "  \"*\"\n",
      "  \"WHERE\"\n",
      "  \"]\"\n",
      "  \"{\"\n",
      "  a parameter (line 1, column 101 (offset: 100))\n",
      "\"MATCH (g:Gene)-[:GENETICS]->(gd:`Genetic disorder` {id: \"Familial Hypercholesterolemia\"})-[:GENOTYPE-PHENOTYPE_RELATION]->(r:Registry)-[:TREATMENT_FOLLOW-UP]->(c:Cholesterol)\"\n",
      "                                                                                                     ^}\n",
      "[Error] Generated Cypher Statement is not valid\n",
      "{code: Neo.ClientError.Statement.SyntaxError} {message: Invalid input '-': expected\n",
      "  \"*\"\n",
      "  \"WHERE\"\n",
      "  \"]\"\n",
      "  \"{\"\n",
      "  a parameter (line 1, column 101 (offset: 100))\n",
      "\"MATCH (g:Gene)-[:GENETICS]->(gd:`Genetic disorder` {id: \"Familial Hypercholesterolemia\"})-[:GENOTYPE-PHENOTYPE_RELATION]->(r:Registry)-[:TREATMENT_FOLLOW-UP]->(c:Cholesterol)\"\n",
      "                                                                                                     ^}\n",
      "[Error] Generated Cypher Statement is not valid\n",
      "{code: Neo.ClientError.Statement.SyntaxError} {message: Invalid input '-': expected\n",
      "  \"*\"\n",
      "  \"WHERE\"\n",
      "  \"]\"\n",
      "  \"{\"\n",
      "  a parameter (line 1, column 101 (offset: 100))\n",
      "\"MATCH (g:Gene)-[:GENETICS]->(gd:`Genetic disorder` {id: \"Familial Hypercholesterolemia\"})-[:GENOTYPE-PHENOTYPE_RELATION]->(r:Registry)-[:TREATMENT_FOLLOW-UP]->(c:Cholesterol)\"\n",
      "                                                                                                     ^}\n",
      "[Error] Generated Cypher Statement is not valid\n",
      "{code: Neo.ClientError.Statement.SyntaxError} {message: Invalid input '-': expected\n",
      "  \"*\"\n",
      "  \"WHERE\"\n",
      "  \"]\"\n",
      "  \"{\"\n",
      "  a parameter (line 1, column 101 (offset: 100))\n",
      "\"MATCH (g:Gene)-[:GENETICS]->(gd:`Genetic disorder` {id: 'Familial Hypercholesterolemia'})-[:GENOTYPE-PHENOTYPE_RELATION]->(r:Registry)-[:TREATMENT_FOLLOW-UP]->(c:Cholesterol)\"\n",
      "                                                                                                     ^}\n",
      "MATCH (g:Gene)-[:GENETICS]->(gd:`Genetic disorder` {id: 'Familial Hypercholesterolemia'})-[:GENOTYPE_PHENOTYPE_RELATION]->(r:Registry)-[:TREATMENT_FOLLOW_UP]->(c:Cholesterol)\n",
      "RETURN g, gd, r, c\n",
      "=================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.agents import AgentExecutor\n",
    "from langchain.chains import GraphCypherQAChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Define prompts for Cypher execution and correction\n",
    "cypher_prompt = PromptTemplate(template=\"Write a Cypher query to answer the following question: {question}\", input_variables=['question'])\n",
    "correction_prompt = PromptTemplate(template=\"The Cypher query resulted in an error: {error}. Based on the error, give a corrected Cypher query. For types containing space, surround them with backticks, otherwise it would make an error you won't detect after. Make uses of Relationships at maximum. Remember to return a variable. Do not add comment, nor any other text, just the query.\", input_variables=['error'])\n",
    "chain_cypher_query = GraphCypherQAChain.from_llm(llm, graph=graph)\n",
    "chain_cypher_correct = llm | StrOutputParser()\n",
    "\n",
    "def validate_cypher(cypher_query):\n",
    "  try:\n",
    "    # Run the chain and capture the output/error\n",
    "    output = chain_cypher_query.invoke(cypher_query)\n",
    "    return output\n",
    "  except Exception as e:\n",
    "    print(\"[Error]\", e)\n",
    "    return f\"Error: {str(e)}\"\n",
    "\n",
    "def correct_cypher(error_message, original_query):\n",
    "  # Use LLM or rule-based system to suggest correction based on error message\n",
    "  corrected_query = chain_cypher_correct.invoke(correction_prompt.format(question=original_query, error=error_message))\n",
    "  return corrected_query\n",
    "\n",
    "def iterative_cypher_validation(initial_query):\n",
    "  current_query = initial_query\n",
    "  while True:\n",
    "    output = validate_cypher(current_query)\n",
    "    if isinstance(output, str) and output.startswith(\"Error\"):\n",
    "      correction = correct_cypher(output, current_query)\n",
    "      current_query = correction\n",
    "    else:\n",
    "      return output\n",
    "\n",
    "final_result = iterative_cypher_validation(cypher_query)\n",
    "print(final_result['query'])\n",
    "print(\"=================\")\n",
    "graph.query(final_result['query'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.4. Generating answers based on database results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.graph_qa.cypher_utils import CypherQueryCorrector, Schema\n",
    "\n",
    "# Cypher validation tool for relationship directions\n",
    "corrector_schema = [\n",
    "    Schema(el[\"start\"], el[\"type\"], el[\"end\"])\n",
    "    for el in graph.structured_schema.get(\"relationships\")\n",
    "]\n",
    "cypher_validation = CypherQueryCorrector(corrector_schema)\n",
    "\n",
    "def log_cypher_query(query):\n",
    "    print(f\"Generated Cypher Query: \\n{query}\")\n",
    "    return query\n",
    "\n",
    "# Generate natural language response based on database results\n",
    "response_template = \"\"\"Based on the the question, Cypher query, and Cypher response, write a natural language response:\n",
    "Question: {question}\n",
    "Cypher query: {query}\n",
    "Cypher Response: {response}\"\"\"  # noqa: E501\n",
    "\n",
    "response_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"Given an input question and Cypher response, convert it to a natural\"\n",
    "            \" language answer. No pre-amble.\",\n",
    "        ),\n",
    "        (\"human\", response_template),\n",
    "    ]\n",
    ")\n",
    "\n",
    "graph_rag_chain = (\n",
    "    RunnablePassthrough.assign(query=cypher_chain)\n",
    "    | RunnablePassthrough.assign(query=lambda x: log_cypher_query(x[\"query\"]))\n",
    "    | RunnablePassthrough.assign(query=lambda x: iterative_cypher_validation(x[\"query\"])[\"query\"])\n",
    "    | RunnablePassthrough.assign(response=lambda x: graph.query(x[\"query\"]))\n",
    "    | response_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Cypher Query: \n",
      "MATCH (f:Genetic disorder {id: \"Familial Hypercholesterolemia\"})-[:GENOTYPE-PHENOTYPE_RELATION]->(r:Registry),\n",
      "(f)-[:GENOTYPE-PHENOTYPE_RELATION]->(g:Gene),\n",
      "(f)-[:GENOTYPE-PHENOTYPE_RELATION]->(t:Treatment),\n",
      "(f)-[:GENOTYPE-PHENOTYPE_RELATION]->(m:Management)\n",
      "RETURN *\n",
      "[Error] Generated Cypher Statement is not valid\n",
      "{code: Neo.ClientError.Statement.SyntaxError} {message: Invalid input 'disorder': expected \")\", \"WHERE\", \"{\" or a parameter (line 1, column 18 (offset: 17))\n",
      "\"MATCH (f:Genetic disorder {id: \"Familial Hypercholesterolemia\"})-[:GENOTYPE-PHENOTYPE_RELATION]->(r:Registry),\"\n",
      "                  ^}\n",
      "[Error] Generated Cypher Statement is not valid\n",
      "{code: Neo.ClientError.Statement.SyntaxError} {message: Invalid input '-': expected\n",
      "  \"*\"\n",
      "  \"WHERE\"\n",
      "  \"]\"\n",
      "  \"{\"\n",
      "  a parameter (line 1, column 78 (offset: 77))\n",
      "\"MATCH (f:`Genetic disorder` {id: \"Familial Hypercholesterolemia\"})-[:GENOTYPE-PHENOTYPE_RELATION]->(r:Registry)\"\n",
      "                                                                              ^}\n",
      "[Error] Generated Cypher Statement is not valid\n",
      "{code: Neo.ClientError.Statement.SyntaxError} {message: Invalid input 'disorder': expected \")\", \"WHERE\", \"{\" or a parameter (line 1, column 18 (offset: 17))\n",
      "\"MATCH (f:Genetic disorder {id: \"Familial Hypercholesterolemia\"})-[:GENOTYPE-PHENOTYPE_RELATION]->(r:Registry)\"\n",
      "                  ^}\n",
      "[Error] Generated Cypher Statement is not valid\n",
      "{code: Neo.ClientError.Statement.SyntaxError} {message: Invalid input 'disorder': expected \")\", \"WHERE\", \"{\" or a parameter (line 1, column 18 (offset: 17))\n",
      "\"MATCH (f:Genetic disorder {id: \"Familial Hypercholesterolemia\"})-[:GENOTYPE-PHENOTYPE_RELATION]->(r:Registry)\"\n",
      "                  ^}\n",
      "[Error] Generated Cypher Statement is not valid\n",
      "{code: Neo.ClientError.Statement.SyntaxError} {message: Invalid input 'disorder': expected \")\", \"WHERE\", \"{\" or a parameter (line 1, column 18 (offset: 17))\n",
      "\"MATCH (f:Genetic disorder {id: \"Familial Hypercholesterolemia\"})-[:GENOTYPE-PHENOTYPE_RELATION]->(r:Registry)\"\n",
      "                  ^}\n",
      "[Error] Generated Cypher Statement is not valid\n",
      "{code: Neo.ClientError.Statement.SyntaxError} {message: Invalid input 'disorder': expected \")\", \"WHERE\", \"{\" or a parameter (line 1, column 18 (offset: 17))\n",
      "\"MATCH (f:Genetic disorder {id: \"Familial Hypercholesterolemia\"})-[:GENOTYPE-PHENOTYPE_RELATION]->(r:Registry)\"\n",
      "                  ^}\n",
      "[Error] Generated Cypher Statement is not valid\n",
      "{code: Neo.ClientError.Statement.SyntaxError} {message: Invalid input 'disorder': expected \")\", \"WHERE\", \"{\" or a parameter (line 1, column 18 (offset: 17))\n",
      "\"MATCH (f:Genetic disorder {id: \"Familial Hypercholesterolemia\"})-[:GENOTYPE-PHENOTYPE_RELATION]->(r:Registry)\"\n",
      "                  ^}\n",
      "[Error] Generated Cypher Statement is not valid\n",
      "{code: Neo.ClientError.Statement.SyntaxError} {message: Invalid input '-': expected\n",
      "  \"*\"\n",
      "  \"WHERE\"\n",
      "  \"]\"\n",
      "  \"{\"\n",
      "  a parameter (line 1, column 78 (offset: 77))\n",
      "\"MATCH (f:`Genetic disorder` {id: \"Familial Hypercholesterolemia\"})-[:GENOTYPE-PHENOTYPE_RELATION]->(r:`Registry`)\"\n",
      "                                                                              ^}\n",
      "[Error] Generated Cypher Statement is not valid\n",
      "{code: Neo.ClientError.Statement.SyntaxError} {message: Invalid input 'disorder': expected \")\", \"WHERE\", \"{\" or a parameter (line 1, column 18 (offset: 17))\n",
      "\"MATCH (f:Genetic disorder {id: \"Familial Hypercholesterolemia\"})-[:GENOTYPE-PHENOTYPE_RELATION]->(r:Registry)\"\n",
      "                  ^}\n",
      "[Error] Generated Cypher Statement is not valid\n",
      "{code: Neo.ClientError.Statement.SyntaxError} {message: Invalid input 'disorder': expected \")\", \"WHERE\", \"{\" or a parameter (line 1, column 18 (offset: 17))\n",
      "\"MATCH (f:Genetic disorder {id: \"Familial Hypercholesterolemia\"})-[:GENOTYPE-PHENOTYPE_RELATION]->(r:Registry)\"\n",
      "                  ^}\n",
      "[Error] Generated Cypher Statement is not valid\n",
      "{code: Neo.ClientError.Statement.SyntaxError} {message: Invalid input '-': expected\n",
      "  \"*\"\n",
      "  \"WHERE\"\n",
      "  \"]\"\n",
      "  \"{\"\n",
      "  a parameter (line 1, column 78 (offset: 77))\n",
      "\"MATCH (f:`Genetic disorder` {id: \"Familial Hypercholesterolemia\"})-[:GENOTYPE-PHENOTYPE_RELATION]->(r:`Registry`)\"\n",
      "                                                                              ^}\n",
      "[Error] Generated Cypher Statement is not valid\n",
      "{code: Neo.ClientError.Statement.SyntaxError} {message: Invalid input '-': expected\n",
      "  \"*\"\n",
      "  \"WHERE\"\n",
      "  \"]\"\n",
      "  \"{\"\n",
      "  a parameter (line 1, column 78 (offset: 77))\n",
      "\"MATCH (f:`Genetic disorder` {id: \"Familial Hypercholesterolemia\"})-[:GENOTYPE-PHENOTYPE_RELATION]->(r:`Registry`)\"\n",
      "                                                                              ^}\n",
      "[Error] Generated Cypher Statement is not valid\n",
      "{code: Neo.ClientError.Statement.SyntaxError} {message: Invalid input '-': expected\n",
      "  \"*\"\n",
      "  \"WHERE\"\n",
      "  \"]\"\n",
      "  \"{\"\n",
      "  a parameter (line 1, column 78 (offset: 77))\n",
      "\"MATCH (f:`Genetic disorder` {id: \"Familial Hypercholesterolemia\"})-[:GENOTYPE-PHENOTYPE_RELATION]->(r:`Registry`)\"\n",
      "                                                                              ^}\n",
      "[Error] Generated Cypher Statement is not valid\n",
      "{code: Neo.ClientError.Statement.SyntaxError} {message: Invalid input '-': expected\n",
      "  \"*\"\n",
      "  \"WHERE\"\n",
      "  \"]\"\n",
      "  \"{\"\n",
      "  a parameter (line 1, column 78 (offset: 77))\n",
      "\"MATCH (f:`Genetic disorder` {id: \"Familial Hypercholesterolemia\"})-[:GENOTYPE-PHENOTYPE_RELATION]->(r:`Registry`)\"\n",
      "                                                                              ^}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'These findings may not be able to help improve diagnosis and treatment for Familial Hypercholesterolemia as there were no results found in the database for this query.'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_rag_chain.invoke({\"question\": prompts[2]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hybrid RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-qa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
